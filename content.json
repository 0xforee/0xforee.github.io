{"posts":[{"title":"source build&#x2F;envsetup.sh 做了什么？","text":"Android 编译系统解析系列文档 编译系统入口envsetup.sh解析 source build/envsetup.sh 做了什么？ 解析lunch的执行过程以及make执行过程中include文件的顺序 Android编译系统分析之lunch分析 Android编译系统分析之make分析 关注一些make执行过程中的几个关键点 Android编译系统分析之几个关键点（一） Android编译系统分析之几个关键点（二） Android编译系统分析之几个关键点（三） 对一些独特的语法结构进行解析 PRODUCT_COPY_FILES语法解析 关于PRODUCT_PROPERTY_OVERRIDES属性的解析 我们用几个问题来解释这篇文章要讨论的内容 为什么用\\cd 而不用cd在android原代码的提交中，我们发现了这个解释： Use “\\cd” to disable alias temporarily. 使用\\cd 来临时屏蔽alias别名 具体作用如下示例： 12345678910111213function mycd(){ echo &quot;in mycd&quot; cd $@}alias cd='mycd'function cproj(){ pwd \\cd .. 或者 cd .. pwd} cproj() 我们执行这个脚本，前者将会打印： 12/home/foree/bin/home/foree 后者将会打印： 123/home/foree/binin mycd/home/foree android 如何定位TOP目录循环递归，查找build/core/envsetup.mk这个路径下文件是否存在 1234567891011121314151617181920212223242526function gettop{local TOPFILE=build/core/envsetup.mkif [ -n &quot;$TOP&quot; -a -f &quot;$TOP/$TOPFILE&quot; ] ; then # The following circumlocution ensures we remove symlinks from TOP. (cd $TOP; PWD= /bin/pwd)else if [ -f $TOPFILE ] ; then # The following circumlocution (repeated below as well) ensures # that we record the true directory name and not one that is # faked up with symlink names. PWD= /bin/pwd else local HERE=$PWD T= while [ \\( ! \\( -f $TOPFILE \\) \\) -a \\( $PWD != &quot;/&quot; \\) ]; do \\cd .. T=`PWD= /bin/pwd -P` done \\cd $HERE if [ -f &quot;$T/$TOPFILE&quot; ]; then echo $T fi fifi} 关于shell脚本中命令太长的多行写法123adb shell ps \\| tr -d '\\r' \\| sed -e 1d -e 's/^[^ ]* *\\([0-9]*\\).* \\([^ ]*\\)$/\\1 \\2/' 如何进入到指定关键字的目录，并选择符合条件中的一个1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253function godir () {if [[ -z &quot;$1&quot; ]]; then echo &quot;Usage: godir &lt;regex&gt;&quot; returnfiT=$(gettop)if [[ ! -f $T/filelist ]]; then echo -n &quot;Creating index...&quot; (\\cd $T; find . -wholename ./out -prune -o -wholename ./.repo -prune -o -type f &gt; filelist) echo &quot; Done&quot; echo &quot;&quot;filocal lineslines=($(\\grep &quot;$1&quot; $T/filelist | sed -e 's/\\/[^/]*$//' | sort | uniq))if [[ ${#lines[@]} = 0 ]]; then echo &quot;Not found&quot; returnfilocal pathnamelocal choiceif [[ ${#lines[@]} &gt; 1 ]]; then while [[ -z &quot;$pathname&quot; ]]; do local index=1 local line for line in ${lines[@]}; do printf &quot;%6s %s\\n&quot; &quot;[$index]&quot; $line index=$(($index + 1)) done echo echo -n &quot;Select one: &quot; unset choice read choice if [[ $choice -gt ${#lines[@]} || $choice -lt 1 ]]; then echo &quot;Invalid choice&quot; continue fi pathname=${lines[$(($choice-1))]} doneelse pathname=${lines[0]}fi\\cd $T/$pathname} envsetup.sh的作用export 一些函数，像如： 12345678910111213141516171819202122232425function lunch()function _lunch()function gettopfunction getdriver()function m()function findmakefile()function mm()function mmm()function mma()function mmma()function croot()function cproj()function pid() 以上这些就是咱们平时使用的croot，lunch，mm这些函数的来源， 然后在脚本的最后，需要判断一下当前环境的shell是否为bash，对于非bash来说，例如zsh，因为与bash的语法有微小差别，因此使用一些命令会出错，例如，lunch之后，如果直接选择数字，而不是类型，可能会导致lunch一个错误的机型 123456789if [ &quot;x$SHELL&quot; != &quot;x/bin/bash&quot; ]; thencase `ps -o command -p $$` inbash);;*)echo &quot;WARNING: Only bash is supported, use of other shell would lead to erroneous results&quot;;;esacfi 然后最后，再查找device和vendor目录下vendorsetup.sh文件，目录层级最深为4层，我们可以以vendor_device-TAG的方式加入变量，通过add_lunch_combo加到Lunch的选择项中。 1234567# Execute the contents of any vendorsetup.sh files we can find.for f in `test -d device &amp;&amp; find -L device -maxdepth 4 -name 'vendorsetup.sh' 2&gt; /dev/null` \\`test -d vendor &amp;&amp; find -L vendor -maxdepth 4 -name 'vendorsetup.sh' 2&gt; /dev/null`doecho &quot;including $f&quot;. $fdone 我们来看看通过lunch启动都干了些什么（可以通过cat build/envsetup.sh|sed -n ‘/function lunch/,/^}/p’ 打印函数） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071function lunch(){local answerif [ &quot;$1&quot; ] ; then answer=$1else print_lunch_menu echo -n &quot;Which would you like? [aosp_arm-eng] &quot; read answerfilocal selection=if [ -z &quot;$answer&quot; ]then selection=aosp_arm-engelif (echo -n $answer | grep -q -e &quot;^[0-9][0-9]*$&quot;)then if [ $answer -le ${#LUNCH_MENU_CHOICES[@]} ] then selection=${LUNCH_MENU_CHOICES[$(($answer-1))]} fielif (echo -n $answer | grep -q -e &quot;^[^\\-][^\\-]*-[^\\-][^\\-]*$&quot;)then selection=$answerfiif [ -z &quot;$selection&quot; ]then echo echo &quot;Invalid lunch combo: $answer&quot; return 1fiexport TARGET_BUILD_APPS=local product=$(echo -n $selection | sed -e &quot;s/-.*$//&quot;)check_product $productif [ $? -ne 0 ]then echo echo &quot;** Don't have a product spec for: '$product'&quot; echo &quot;** Do you have the right repo manifest?&quot; product=filocal variant=$(echo -n $selection | sed -e &quot;s/^[^\\-]*-//&quot;)check_variant $variantif [ $? -ne 0 ]then echo echo &quot;** Invalid variant: '$variant'&quot; echo &quot;** Must be one of ${VARIANT_CHOICES[@]}&quot; variant=fiif [ -z &quot;$product&quot; -o -z &quot;$variant&quot; ] then echo return 1fiexport TARGET_PRODUCT=$productexport TARGET_BUILD_VARIANT =$variantexport TARGET_BUILD_TYPE=releaseechoset_stuff_for_environmentprintconfig} 如上：主要关注点在于4个正则表达式 elif (echo -n $answer | grep -q -e “^[0-9][0-9]*$”) elif (echo -n $answer | grep -q -e “^[^-][^-]-[^-][^-]$”) local product=$(echo -n $selection | sed -e “s/-.*$//“) local variant=$(echo -n $selection | sed -e “s/^[^-]*-//“) 第一个是查找1-2位数的正则表达式第二个是匹配vendor_product-eng这样格式的选择项第三个用来提取-前边的关键字，例如meizu_m76-eng中的meizu_m76第四个用来提取variant变量，就是eng,userdebug,user这几个变量 我们从这里可以看出，vendorsetup.sh中写出符合标准格式的combo,然后在lunch的时候导出 接下来我们进入lunch的世界 Android编译系统之lunch分析","link":"/2015/11/05/android-build-system-envsetup/"},{"title":"Android编译系统分析之几个关键点（一）","text":"Android 编译系统解析系列文档 编译系统入口envsetup.sh解析 source build/envsetup.sh 做了什么？ 解析lunch的执行过程以及make执行过程中include文件的顺序 Android编译系统分析之lunch分析 Android编译系统分析之make分析 关注一些make执行过程中的几个关键点 Android编译系统分析之几个关键点（一） Android编译系统分析之几个关键点（二） Android编译系统分析之几个关键点（三） 对一些独特的语法结构进行解析 PRODUCT_COPY_FILES语法解析 关于PRODUCT_PROPERTY_OVERRIDES属性的解析 我们首先来看看今天的主角，以下这段代码就是解析AndroidProducts.mk以及其内容的关键代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970###################build/core/product_config.mk###################ifneq ($(strip $(TARGET_BUILD_APPS)),)# An unbundled app build needs only the core product makefiles.all_product_configs := $(call get-product-makefiles,\\ $(SRC_TARGET_DIR)/product/AndroidProducts.mk)else# Read in all of the product definitions specified by the AndroidProducts.mk# files in the tree.all_product_configs := $(get-all-product-makefiles)endif# Find the product config makefile for the current product.# all_product_configs consists items like:# &lt;product_name&gt;:&lt;path_to_the_product_makefile&gt;# or just &lt;path_to_the_product_makefile&gt; in case the product name is the# same as the base filename of the product config makefile.current_product_makefile :=all_product_makefiles :=$(foreach f, $(all_product_configs),\\ $(eval _cpm_words := $(subst :,$(space),$(f)))\\ $(eval _cpm_word1 := $(word 1,$(_cpm_words)))\\ $(eval _cpm_word2 := $(word 2,$(_cpm_words)))\\ $(if $(_cpm_word2),\\ $(eval all_product_makefiles += $(_cpm_word2))\\ $(if $(filter $(TARGET_PRODUCT),$(_cpm_word1)),\\ $(eval current_product_makefile += $(_cpm_word2)),),\\ $(eval all_product_makefiles += $(f))\\ $(if $(filter $(TARGET_PRODUCT),$(basename $(notdir $(f)))),\\ $(eval current_product_makefile += $(f)),)))_cpm_words :=_cpm_word1 :=_cpm_word2 :=current_product_makefile := $(strip $(current_product_makefile))all_product_makefiles := $(strip $(all_product_makefiles))ifneq (,$(filter product-graph dump-products, $(MAKECMDGOALS)))# Import all product makefiles.$(call import-products, $(all_product_makefiles))else# Import just the current product.ifndef current_product_makefile$(error Can not locate config makefile for product &quot;$(TARGET_PRODUCT)&quot;)endififneq (1,$(words $(current_product_makefile)))$(error Product &quot;$(TARGET_PRODUCT)&quot; ambiguous: matches $(current_product_makefile))endif$(call import-products, $(current_product_makefile))endif # Import all or just the current product makefile# Sanity check$(check-all-products)ifneq ($(filter dump-products, $(MAKECMDGOALS)),)$(dump-products)$(error done)endif# Convert a short name like &quot;sooner&quot; into the path to the product# file defining that product.#INTERNAL_PRODUCT := $(call resolve-short-product-name, $(TARGET_PRODUCT))ifneq ($(current_product_makefile),$(INTERNAL_PRODUCT))$(error PRODUCT_NAME inconsistent in $(current_product_makefile) and $(INTERNAL_PRODUCT))endifcurrent_product_makefile :=all_product_makefiles :=all_product_configs := 该加载哪里的AndroidProducts.mk文件？我们将之前的代码拆着来看，首先看AndroidProducts.mk文件是如何被加载到Android整个编译环境中的 12345678910111213###################build/core/product_config.mk###################ifneq ($(strip $(TARGET_BUILD_APPS)),)# An unbundled app build needs only the core product makefiles.all_product_configs := $(call get-product-makefiles,\\ $(SRC_TARGET_DIR)/product/AndroidProducts.mk)else# Read in all of the product definitions specified by the AndroidProducts.mk# files in the tree.all_product_configs := $(get-all-product-makefiles)endif 这里判断构建的目标是不是APP，对于独立APP的编译，只需要加载核心目录下（build/target/product）AndroidProducts.mk文件即可，如果是构建整个系统,那么需要加载所有的AndroidProducts.mk文件 TARGET_BUILD_APPS这个变量可以通过tapas命令指定（具体命令使用方式请参见envsetup.sh），也可以通过”APP-&lt;appname&gt;” 来指定 这个变量默认为空，也就是编译整个系统，我们可以在加载环境变量之后通过使用printconfig命令来查看我们是否设置过TARGET_BUILD_APPS变量 取得编译系统中所有的AndroidProducts.mkget-all-product-makefiles函数定义在build/core/product.mk文件中，是get-product-makefiles的一个简单的封装 123456789101112####################build/core/product.mk###################### Returns the sorted concatenation of all PRODUCT_MAKEFILES# variables set in all AndroidProducts.mk files.# $(call ) isn't necessary.#define get-all-product-makefiles$(call get-product-makefiles,$(_find-android-products-files))endef 其中的_find-android-products-files函数返回的是整个编译系统中所有AndroidProducts.mk的集合 12345678910111213####################build/core/product.mk###################### Returns the list of all AndroidProducts.mk files.# $(call ) isn't necessary.#define _find-android-products-files$(shell test -d device &amp;&amp; find device -maxdepth 6 -name AndroidProducts.mk) \\ $(shell test -d vendor &amp;&amp; find vendor -maxdepth 6 -name AndroidProducts.mk) \\ $(SRC_TARGET_DIR)/product/AndroidProducts.mkendef 如上：扫描device与vendor目录下6层深度的子目录下的所有AndroidProducts.mk文件，以及build/target/product/AndroidProducts.mk文件，从这里我们可以看出，这里的得到的最后结果带有相对于源码根目录的相对路径，类似以下格式： 1234567891011121314151617181920212223242526272829303132333435device/htc/flounder/AndroidProducts.mkdevice/meizu/m86/AndroidProducts.mkdevice/samsung/avl7420/AndroidProducts.mk....``` &gt; **注：**`SRC_TARGET_DIR=build/target` ### 处理AndroidProducts.mk接下来要对扫描出的AndroidProducts.mk文件进行处理```makefile?linenums=41####################build/core/product.mk###################### Returns the sorted concatenation of PRODUCT_MAKEFILES# variables set in the given AndroidProducts.mk files.# $(1): the list of AndroidProducts.mk files.#define get-product-makefiles$(sort \\ $(foreach f,$(1), \\ $(eval PRODUCT_MAKEFILES :=) \\ $(eval LOCAL_DIR := $(patsubst %/,%,$(dir $(f)))) \\ $(eval include $(f)) \\ $(PRODUCT_MAKEFILES) \\ ) \\ $(eval PRODUCT_MAKEFILES :=) \\ $(eval LOCAL_DIR :=) \\ )endef 我们注意到以上代码有一行是对LOCAL_DIR进行了定义，这个定义的原因是因为AndroidProducts.mk文件中定义的格式像下边这样： 123ifeq ($(TARGET_PRODUCT),meizu_m86) PRODUCT_MAKEFILES := $(LOCAL_DIR)/meizu_m86.mkendif 我们还记得上边扫描得出的所有AndroidProducts.mk的集合是带有相对路径的，所以我们这里可以通过dir获取路径，然后置换为下一行include对应AndroidProducts.mk中的LOCAL_DIR，这样我们就得到了我们真正要加载的makefile文件，就是我们配置一个device需要用到的文件（例：meizu_m86.mk） 这样在将所有的AndroidProducts.mk文件中的内容解析完毕之后，我们就得到了一份使用sort排序并去重的product_makefile文件列表 注意： 这里我们并未区分我们要编译的product_makefile，也就是说这是一个包含全部product_makefile的列表 取得current_makefile（当前lunch机型的配置文件）1234567891011121314151617181920212223242526###################build/core/product_config.mk###################current_product_makefile :=all_product_makefiles :=$(foreach f, $(all_product_configs),\\ $(eval _cpm_words := $(subst :,$(space),$(f)))\\ $(eval _cpm_word1 := $(word 1,$(_cpm_words)))\\ $(eval _cpm_word2 := $(word 2,$(_cpm_words)))\\ $(if $(_cpm_word2),\\ #then-1 $(eval all_product_makefiles += $(_cpm_word2))\\ $(if $(filter $(TARGET_PRODUCT),$(_cpm_word1)),\\ #then-2 $(eval current_product_makefile += $(_cpm_word2)),),\\ #else $(eval all_product_makefiles += $(f))\\ $(if $(filter $(TARGET_PRODUCT),$(basename $(notdir $(f)))),\\ #then-3 $(eval current_product_makefile += $(f)),)))_cpm_words :=_cpm_word1 :=_cpm_word2 :=current_product_makefile := $(strip $(current_product_makefile))all_product_makefiles := $(strip $(all_product_makefiles)) 关于makefile中IF的语法:$(if &lt;condition&gt;, &lt;then-part&gt;, &lt;else-part&gt; ) 从前边的代码我们可以知道all_product_configs是代表device以及vendor所有的AndroidProducts.mk文件中变量PRODUCT_MAKEFILES的值的集合，这个PRODUCT_MAKEFILES值包括两种情况 &lt;product_name&gt;:&lt;path_to_the_product_makefile&gt; &lt;path_to_the_product_makefile&gt; 也就是在上边代码中==then-1==做出判断，我们一般都是使用的第二种情况，所以我们就解析一下else的情况，else主要做了两步处理 将所有的product_makefile文件加入到all_product_makefiles变量中 通过TARGET_PRODUCT来解析出对应的product_makefile文件 通过以上两步，我们可以得到一个包含全部device，vendor下的product_makefile文件的变量all_product_makefiles以及当前我们需要编译的product_makefile的变量current_product_makeifle 以上的示例也提醒我们,AndroidProducts.mk文件内容中指向的product_makefile名称必须标准 导入PRODUCT变量123456789101112131415161718192021222324252627282930313233###################build/core/product_config.mk###################ifneq (,$(filter product-graph dump-products, $(MAKECMDGOALS)))# Import all product makefiles.$(call import-products, $(all_product_makefiles))else# Import just the current product.ifndef current_product_makefile$(error Can not locate config makefile for product &quot;$(TARGET_PRODUCT)&quot;)endififneq (1,$(words $(current_product_makefile)))$(error Product &quot;$(TARGET_PRODUCT)&quot; ambiguous: matches $(current_product_makefile))endif$(call import-products, $(current_product_makefile))endif # Import all or just the current product makefile# Sanity check$(check-all-products)ifneq ($(filter dump-products, $(MAKECMDGOALS)),)$(dump-products)$(error done)endif# Convert a short name like &quot;sooner&quot; into the path to the product# file defining that product.#INTERNAL_PRODUCT := $(call resolve-short-product-name, $(TARGET_PRODUCT))ifneq ($(current_product_makefile),$(INTERNAL_PRODUCT))$(error PRODUCT_NAME inconsistent in $(current_product_makefile) and $(INTERNAL_PRODUCT))endif 在上边所示的代码中，google也给出了调试product_makefile的方式： MAKECMDGOALS中如果包含dump-products，那么执行$(dump-products)命令打印所有的PRODUCT_XXXX变量，具体规则定义位于build/core/product.mk文件 MAKECMDGOALS中如果包含product-graph，那么google会在out目录生成一个pdf和svg文件，这两个文件内包含了所有的product_makefile文件之间的相互依赖关系，具体规则定义位于build/core/tasks/product-graph.mk 一般的编译来说，是调用import-products导入当前的我们要编译的机型配置，也就是这个current_product_makefile这个变量的值 注意：current_product_makefile这个值是唯一的，否则会报错 重要说明：对于各个目录下定义的PRODUCT_开头的相同的变量都会在import-products中得到处理（或者说展开），在处理完毕之后，对于各个变量的获取，我们都可以在如下格式的变量中获取到PRODUCTS.$(INTERNAL_PRODUCT).PRODUCT_XXXX 其中INTERNAL_PRODUCT值为上边current_product_makefile的值，类似device/meizu/m86/meizu_m86.mk PRODUCT_XXXXX表示PRODUCT_COPY_FILES，PRODUCT_LOCALES等变量 让我们接着来看看import-products干了什么 1234567####################build/core/product.mk####################define import-products $(call import-nodes,PRODUCTS,$(1),$(_product_var_list))endef 我们记录一下传入的参数：$(1) = $(current_product_makefile) 实际调用import-nodes导入传入的参数，这里的_product_var_list是以PRODUCT开头的一系列的变量的枚举 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061####################build/core/product.mk####################_product_var_list := \\ PRODUCT_NAME \\ PRODUCT_MODEL \\ PRODUCT_LOCALES \\ PRODUCT_AAPT_CONFIG \\ PRODUCT_AAPT_PREF_CONFIG \\ PRODUCT_AAPT_PREBUILT_DPI \\ PRODUCT_PACKAGES \\ PRODUCT_PACKAGES_DEBUG \\ PRODUCT_PACKAGES_ENG \\ PRODUCT_PACKAGES_TESTS \\ PRODUCT_DEVICE \\ PRODUCT_MANUFACTURER \\ PRODUCT_BRAND \\ PRODUCT_PROPERTY_OVERRIDES \\ PRODUCT_DEFAULT_PROPERTY_OVERRIDES \\ PRODUCT_CHARACTERISTICS \\ PRODUCT_COPY_FILES \\ PRODUCT_OTA_PUBLIC_KEYS \\ PRODUCT_EXTRA_RECOVERY_KEYS \\ PRODUCT_PACKAGE_OVERLAYS \\ DEVICE_PACKAGE_OVERLAYS \\ PRODUCT_TAGS \\ ......``` 我们再来看看`import-nodes`这个函数干了什么```makefile?linenums=241####################build/core/node_fns.mk###################### $(1): output list variable name, like &quot;PRODUCTS&quot; or &quot;DEVICES&quot;# $(2): list of makefiles representing nodes to import# $(3): list of node variable names#define import-nodes$(if \\ $(foreach _in,$(2), \\ $(eval _node_import_context := &gt;&gt;==_nic.$(1).[[$(_in)]]==&lt;&lt;) \\ # _node_import_context := _nic.PRODUCT.[[device/meizu/m86/meizu_m86.mk]]# $(if $(_include_stack),$(eval $(error ASSERTION FAILED: _include_stack \\ should be empty here: $(_include_stack))),) \\ $(eval _include_stack := ) \\ $(call &gt;&gt;==_import-nodes-inner,$(_node_import_context),$(_in),$(3)==&lt;&lt;) \\ $(call move-var-list,$(_node_import_context).$(_in),$(1).$(_in),$(3)) \\ $(eval _node_import_context :=) \\ $(eval $(1) := $($(1)) $(_in)) \\ $(if $(_include_stack),$(eval $(error ASSERTION FAILED: _include_stack \\ should be empty here: $(_include_stack))),) \\ ) \\,)endef import-nodes函数主要做了以下几件事： 以current_product_makefile定义了一个变量，这个变量的作用其实就是用来标示唯一性的，在后边的代码中会将这个变量当前缀使用 使用_import-nodes-inner函数做具体的解析工作 将上一步解析完毕的变量变换前缀 将解析过的current_product_makefile都添加到PRODUCTS变量中 重要提示move-var-list 用法很简单：$(call move-var-list,SRC,DST,A B)：变更A和B的前缀SRC到DST 我们之前提到过，在所有的PRODUCT_XXXX变量都展开之后，也就是import-products current_product_makefile之后，所有的PRODUCT_XXXX变量都会被集中到以PRODUCTS.$(INTERNAL_PRODUCT)为前缀的对应的变量中，这个操作就是使用move-var-list来完成的 下边是_import-nodes-innner函数中将要使用到的变量的列表表示： $(_node_import_context) $(_in) $(3) $(2) $(1) _nic.PRODUCTS.[[device/meizu/m86/meizu_m86.mk]] device/meizu/m86/meizu_m86.mk $(_product_var_list) device/meizu/m86/meizu_m86.mk PRODUCTS 重要提示 对于$(_node_import_context)所代表的内容为了方便叙述，我们定义为公有前缀，对于每次编译的目标，公有的前缀是唯一的 对于$(_in)或者$(2)中表示的内容，我们定义为私有前缀，对于同一编译目标不同makefile文件中的相同PRODUCT_XXX变量，我们都会使用公有前缀+私有前缀作为前缀来区分 我们继续来看 1234567891011121314151617181920212223####################build/core/node_fns.mk###################### $(1): context prefix# $(2): list of makefiles representing nodes to import# $(3): list of node variable names#define _import-nodes-inner $(foreach _in,$(2), \\ $(if $(wildcard $(_in)), \\ $(if &gt;&gt;==$($(1).$(_in).seen==&lt;&lt;), \\ $(eval ### &quot;skipping already-imported $(_in)&quot;) \\ , \\ $(eval $(1).$(_in).seen := true) \\ $(call &gt;&gt;==_import-node,$(1),$(strip $(_in)),$(3)==&lt;&lt;) \\ ) \\ , \\ $(error $(1): &quot;$(_in)&quot; does not exist) \\ ) \\ )endef 重要提示 wildcard是一个通配符的关键字，这里用来判断$(_in)文件是否存在 这里我们看到有一个foreach循环，这个在第一次的时候因为参数之后current_product_makefile，所以不会用到，后边我们在用到继承性的时候，因为会有继承多个product的情况发生，所以需要foreach这个函数来遍历 这里会有一个变量（$(1).$(_in).seen）来标示文件的内容是否已经导入，以86为例，变量以及内容分别为 $(1) $(_in) $(3) _nic.PRODUCTS.[[device/meizu/m86/meizu_m86.mk]] device/meizu/m86/meizu_m86.mk _product_var_list 很长很变态….. _import-nodes-inner函数只是来判断是否导入过文件，如果没有导入，使用_import_node来实际导入 12345678910111213141516171819202122232425262728293031####################build/core/node_fns.mk###################### $(1): context prefix# $(2): makefile representing this node# $(3): list of node variable names## _include_stack contains the list of included files, with the most recent files first.define _import-node $(eval _include_stack := $(2) $$(_include_stack)) $(call clear-var-list, $(3)) $(eval LOCAL_PATH := $(patsubst %/,%,$(dir $(2)))) $(eval MAKEFILE_LIST :=) $(eval &gt;&gt;==include $(2)==&lt;&lt;) $(eval _included := $(filter-out $(2),$(MAKEFILE_LIST))) $(eval MAKEFILE_LIST :=) $(eval LOCAL_PATH :=) $(call copy-var-list, $(1).$(2), $(3)) $(call clear-var-list, $(3)) $(eval $(1).$(2).inherited := \\ $(call &gt;&gt;==get-inherited-nodes,$(1).$(2),$(3))==&lt;&lt;) $(call &gt;&gt;==_import-nodes-inner,$(1),$($(1).$(2).inherited),$(3)==&lt;&lt;) $(call &gt;&gt;==_expand-inherited-values,$(1),$(2),$(3)==&lt;&lt;) $(eval $(1).$(2).inherited :=) $(eval _include_stack := $(wordlist 2,9999,$$(_include_stack)))endef 知识点MAKEFILE_LIST：这个变量内容包含，在环境变量中指定的，命令行中指定的，以及make指定makefile文件时，使用include包含进的文件，这三者所组成的列表 _import-node函数主要做了以下几件事： 将找到的最新文件入栈，此时栈应该是空的，也就是说meizu_m86.mk是第一个入栈的 清除所有的PRODUCT_开头的变量的值 include meizu_m86.mk meizu_m86.mk是整个机型的配置入口，此处开始处理 将处理过的文件添加到_included变量中 将第三步include进来的文件中的PRODUCT_开头的变量使用copy-var-list函数添加$(1).$(２)前缀，这里就是公有前缀+私有前缀 取得带有@inherit前缀的变量，然后去掉@inherit前缀，然后排序去重，获得继承第一层的makefile文件的列表，记录到公有前缀+私有前缀+inherited变量中 通过_import-nodes-inner来循环获取上一步得到的继承列表，将所有层次的继承的文j件都获取到，最后得到一个解除@inherit前缀的包含所有继承层次的makefile文件列表 _expand_-inherited-values展开上一步得到的这些文件中_product_var_list中变量的值 清空继承列表与_include_stack 这里第1步到第7部，以及加上前边的_import-nodes-inner一起构成了递归，我们在递归展开这些变量的最后一步时，会调用_expand-inherited-values来从最深层次的继承一直展开到最浅层次的继承，也就是第一层继承，要明白最深层次与之后浅层次的makefile中变量的关系，是最深覆盖最浅？还是最浅覆盖最深？或者二者叠加？我们就需要看_expand-inherited-values的具体内容 什么是inherit？在看最后一个函数的内容之前，我们还需要了解一个知识点，在第５步的时候，出现了一个新的概念inherit，也就是继承，我们经常会在product_makefile中看到inherit-product函数就是继承的一个典型的应用，我们先来看看它是怎么用的，然后再往下看具体的解析过程 123456789define inherit-product $(foreach v,$(_product_var_list), \\ $(eval $(v) := $($(v)) $(INHERIT_TAG)$(strip $(1)))) \\ $(eval inherit_var := \\ PRODUCTS.$(strip $(word 1,$(_include_stack))).INHERITS_FROM) \\ $(eval $(inherit_var) := $(sort $($(inherit_var)) $(strip $(1)))) \\ $(eval inherit_var:=) \\ $(eval ALL_PRODUCTS := $(sort $(ALL_PRODUCTS) $(word 1,$(_include_stack))))endef 这个函数在build/core/product.mk中定义，后边的参数都是跟一个makefile名称示例：$(call inherit-product, $(SRC_TARGET_DIR)/product/full_base.mk) 这个函数主要做了以下几件事： 为_product_var_list中所有变量挨个加上@inherit xxxmakefile的前缀，这个xxxmakfile就是传入的$(1)变量值 组织当前正被处理（include）的文件内容的继承列表，具体是这样的： 我们用PRODUCTS.当前makefile.INHERITS_FROM这个变量来存放当前makefile的继承列表 然后这个文件中的每一个使用inherit-product函数继承的makefile，都会被加到以上变量中这一步的具体过程就是以下:PRODUCTS.当前makefile.INHERITS_FORM :=$(sort $(PRODUCT.当前makefile.INHERITS_FROM) last_makefile ) 将当前正在处理（include）的makefile加入到变量ALL_PRODUCTS中 了解了这个背景知识之后，我们可以得出以下几点： 我们注意到之前分析的_import-node第三步有一个include product_makefile文件的操作，这里我们分析的inherit-product函数就在这个include的操作中被调用 include操作是发生在import-node函数中，因此include的makefile也会被加入到_include_stack中 _product_var_list中的每个变量也都加入了带有@inherit前缀的所继承的xxxmakefile inherit-product函数中还提供了一个INHERIT_FROM的变量，这个变量的相关用法，我们可以在build/core/tasks/product-graph.mk见到 由以上内容得知，在这里我们只需要明白调用inherit-product函数只是添加了@inherit:这个前缀就行，当然从这里我们也可以看出，如果一个makefile文件中inherit两次同一个makefile，也会被在这里去重 我们继续向下来看是如何解析加入@inherit前缀的这些变量 _get-inherited-nodes的内容也很简单 1234567define get-inherited-nodes$(sort \\ $(subst $(INHERIT_TAG),, \\ $(filter $(INHERIT_TAG)%, \\ $(foreach v,$(2),$($(1).$(v))) \\ )))endef 将_product_var_list中的变量挨个取出，这里的变量已经添加了前缀，因此要使用前缀取出，也就是类似_nic.PRODUCTS.[[device/meizu/m86/meizu_m86.mk]].device/meizu/m86/meizu_m86.mk所代表的product文件来取出var变量的值 过滤出带有@inherit前缀的变量值 将前缀去掉，然后排序去重，最后得到一份继承的makefile的list 这个函数有点复杂，我们在这里说明一下： for循环之后，在_product_var_list中的全部变量(PRODUCT_LOCALES，PRODUCT_FILES等）中带有@inheri前缀的内容都会被取出来，然后去掉前缀，排序去重，我们之前解析过使用@inherit前缀的函数inherit-product，知道调用函数之后，所有的PRODUCT_XXX都会继承@inherite标识后边加入的makefile，因此，这一块的内容其实只是将我们之前include的makefile文件中所继承的（也就是调用inherit-product后的参数）所有makefile做了一个集合，你调用了几个inherit-product，也就有几个继承，这个函数的返回值最后是要记录在公共前缀+私有前缀+inherited这个变量中的，来表示某个makefile文件的继承性的 经过以上3步之后，我们可以（filter过滤出了带＠inherit前缀的变量，故变量原本的值没有在这个列表中）去除@inherit前缀的继承的makefile列表的集合，并且此集合是排序去重过的，这个集合被赋值给了$(1).$(2).inherited 也就是之前我们说到的以makefile绝对路径来区分的前缀，然后又会重复调用_import-nodes-inner这个函数，这个函数我们已经解析过了，只是用来判断是否解析过传入的文件列表，实际将同样的参数传入了_import-node这个函数来进行解析 总的来说_import-node与_import-nodes-inner与get-inherited-nodes在不停的循环，将每次get-inherit-nodes得到的去除了@inherit的makefile重新放入循环中，然后解析出这个makefile文件的所有的_product_var_list所对应的继承关系，将其中_product_var_list中的变量的值都加上某一前缀，这个前缀就是_include_stack栈中最近的一个makefile，因此不需要担心不同的makefile文件中的同一变量会互相覆盖，他们都会以不同的makefile作为前缀来标示 也就是在_expand-inherited-values函数之前，我们都会得到相如以下类型的变量： 1_nic.PRODUCTS.[[device/meizu/m86/meizu_m86.mk]].last_makefile.PRODUCT_xxxx := aaa bbb @inherit xxxmakefile @inherit yyymakefile 展开继承的变量我们来看最后一个函数_expand-inherited-values，我们将传入_expand-inherited-values的参数列举出来，方便后边查看 $(1) $(2) $(3) _nic.PRODUCTS.[[device/meizu/m86/meizu_m86.mk]] last_makefile $(_product_var_list) 假设，我们这里的$(2)，也就是last_makefile，是example.txt举例的最深层次的makefile文件，也就是build/target/product/embedded.mk文件，这个文件内容中已经不包含继承关系，因此_get_inherited_nodes返回的内容为空，_import-node-inner也什么都不做，我们可以直接看_expand-inherited-values 仔细看传入的参数，其实就是传入_import_node的三个参数，其实就是公有前缀，私有前缀，以及一个PRODUCT_xxx的列表，我们可以用这三个参数组成我们调用_expand-inherited-values函数之前的那种类型的变量 接下来我们来实际解析这个函数 12345678910111213141516171819202122232425262728293031define _expand-inherited-values $(foreach v,$(3), \\ $(eval ### &quot;Shorthand for the name of the target variable&quot;) \\ $(eval _eiv_tv := $(1).$(2).$(v)) \\ $(eval ### &quot;Get the list of nodes that this variable inherits&quot;) \\ $(eval _eiv_i := \\ $(sort \\ $(patsubst $(INHERIT_TAG)%,%, \\ $(filter $(INHERIT_TAG)%, $($(_eiv_tv)) \\ )))) \\ $(foreach i,$(_eiv_i), \\ $(eval ### &quot;Make sure that this inherit appears only once&quot;) \\ $(eval $(_eiv_tv) := \\ $(call uniq-word,$($(_eiv_tv)),$(INHERIT_TAG)$(i))) \\ $(eval ### &quot;Expand the inherit tag&quot;) \\ $(eval $(_eiv_tv) := \\ $(strip \\ &gt;&gt;==$(patsubst $(INHERIT_TAG)$(i),$($(1).$(i).$(v)), \\ $($(_eiv_tv)))==&lt;&lt;)) \\ $(eval ### &quot;Clear the child so DAGs don't create duplicate entries&quot; ) \\ $(eval $(1).$(i).$(v) :=) \\ $(eval ### &quot;If we just inherited ourselves, it's a cycle.&quot;) \\ $(if $(filter $(INHERIT_TAG)$(2),$($(_eiv_tv))), \\ $(warning Cycle detected between &quot;$(2)&quot; and &quot;$(i)&quot; for context &quot;$(1)&quot;) \\ $(error import of &quot;$(2)&quot; failed) \\ ) \\ ) \\ ) \\ $(eval _eiv_tv :=) \\ $(eval _eiv_i :=)endef 这个函数做了以下几件事： _eiv_tv 将_product_var_list中的所有变量都添加了公有前缀＋私有前缀 _eiv_i 表示当前正在处理的makefile文件的继承关系makefile列表，是通过过滤@inherit这个前缀拿到的，显而易见，这个是从倒数第二深的makefile文件起作用，因为最深层次的makefile变量中不包含继承关系 使用uniq-word来确保只继承了一次，这种继承的检查发生在上层与紧挨着的下层之间 展开@inherit表示的变量，其实也就是使用比他深一层次的makefile文件的对应的PRODUCT_XXX变量替换@inherit这个标识符 检查是否循环继承（自己继承了自己） 我们接着看uniq-word这个函数的实现 1234567891011define uniq-word$(strip \\ $(if $(filter-out 0 1,$(words $(filter $(2),$(1)))), \\ $(eval h := |||$(subst $(space),|||,$(strip $(1)))|||) \\ $(eval h := $(subst |||$(strip $(2))|||,|||$(space)|||,$(h))) \\ $(eval h := $(word 1,$(h)) $(2) $(wordlist 2,9999,$(h))) \\ $(subst |||,$(space),$(h)) \\ , \\ $(1) \\ ))endef 代码比较简单，读者可以根据前边的内容来分析这个函数的实际作用，不再赘述 我们继续往下看，还记得之前我们通过不停的调用_import-node与_import-nodes-inner与get-inherited-nodes函数构建了所有有继承关系的makefile自己的变量的值的关系，所以我们在这里展开的时候，直接将@inherit:last_makefile替换为PRODUCT.last_makefile.PRODUCT_xxx的值，这里就简单的展开结束，因此我们最后得到就是所有继承变量的综合起来的内容 检查所有的product最后还剩下一点简单的代码，是用来解析出一个short-name后边来使用 123456789101112131415# Sanity check$(check-all-products)ifneq ($(filter dump-products, $(MAKECMDGOALS)),)$(dump-products)$(error done)endif# Convert a short name like &quot;sooner&quot; into the path to the product# file defining that product.#INTERNAL_PRODUCT := $(call resolve-short-product-name, $(TARGET_PRODUCT))ifneq ($(current_product_makefile),$(INTERNAL_PRODUCT))$(error PRODUCT_NAME inconsistent in $(current_product_makefile) and $(INTERNAL_PRODUCT))endif 首先，check-all-products来检查全部products 1234567891011121314151617181920212223242526272829define check-all-products$(if ,, \\ $(eval _cap_names :=) \\ $(foreach p,$(PRODUCTS), \\ $(eval pn := $(strip $(PRODUCTS.$(p).PRODUCT_NAME))) \\ $(if $(pn),,$(error $(p): PRODUCT_NAME must be defined.)) \\ $(if $(filter $(pn),$(_cap_names)), \\ $(error $(p): PRODUCT_NAME must be unique; &quot;$(pn)&quot; already used by $(strip \\ $(foreach \\ pp,$(PRODUCTS), $(if $(filter $(pn),$(PRODUCTS.$(pp).PRODUCT_NAME)), \\ $(pp) \\ ))) \\ ) \\ ) \\ $(eval _cap_names += $(pn)) \\ $(if $(call is-c-identifier,$(pn)),, \\ $(error $(p): PRODUCT_NAME must be a valid C identifier, not &quot;$(pn)&quot;) \\ ) \\ $(eval pb := $(strip $(PRODUCTS.$(p).PRODUCT_BRAND))) \\ $(if $(pb),,$(error $(p): PRODUCT_BRAND must be defined.)) \\ $(foreach cf,$(strip $(PRODUCTS.$(p).PRODUCT_COPY_FILES)), \\ $(if $(filter 2 3,$(words $(subst :,$(space),$(cf)))),, \\ $(error $(p): malformed COPY_FILE &quot;$(cf)&quot;) \\ ) \\ ) \\ ) \\)endef 这里简单调用了resolve-short-product-name的函数，然后将参数传入_resolve-short-product-name，我们直接来看 1234567891011121314151617181920define _resolve-short-product-name $(eval pn := $(strip $(1))) $(eval p := \\ $(foreach p,$(PRODUCTS), \\ $(if $(filter $(pn),$(PRODUCTS.$(p).PRODUCT_NAME)), \\ $(p) \\ )) \\ ) $(eval p := $(sort $(p))) $(if $(filter 1,$(words $(p))), \\ $(p), \\ $(if $(filter 0,$(words $(p))), \\ $(error No matches for product &quot;$(pn)&quot;), \\ $(error Product &quot;$(pn)&quot; ambiguous: matches $(p)) \\ ) \\ )endefdefine resolve-short-product-name$(strip $(call _resolve-short-product-name,$(1)))endef 以上代码也很简单，就是针对对应的product_makefile来获取对应的PRODUCT_NAME，然后定义为短product_name 至此，我们关于AndroidProduct.mk文件的关键点的解析已经完成．","link":"/2015/12/22/android-build-system-keypoint-first/"},{"title":"Android编译系统分析之几个关键点（二）","text":"Android 编译系统解析系列文档 编译系统入口envsetup.sh解析 source build/envsetup.sh 做了什么？ 解析lunch的执行过程以及make执行过程中include文件的顺序 Android编译系统分析之lunch分析 Android编译系统分析之make分析 关注一些make执行过程中的几个关键点 Android编译系统分析之几个关键点（一） Android编译系统分析之几个关键点（二） Android编译系统分析之几个关键点（三） 对一些独特的语法结构进行解析 PRODUCT_COPY_FILES语法解析 关于PRODUCT_PROPERTY_OVERRIDES属性的解析 这篇文章的主要内容我们来分析关于BoardConfig.mk的一些关键的知识点 BoardConfig概览BoardConfig 顾名思义，主要是配置一些Board（平台级）相关的东西，大致涉及的内容有arch架构（32还是64位），CPU的类型，Bootloader，Kernel，RadioImage等是否定义预编译，还有内核的一些page大小，固定的地址偏移等内容,总的来说，这个文件的主要内容就是定义一些与硬件相关的配置 使用方法BoardConfig.mk文件的使用方法很简单，只需要在Android编译系统指定的三个位置创建BoardConfig.mk这个名称的文件即可 使用范围BoardConfig.mk文件的使用位置有三个build, device, vendor，不过文件的存在需要唯一，为什么是这三个位置，我们在稍后的解析中就可以看到 BoardConfig解析关于BoardConfig.mk文件的解析的代码很短，所有代码只有20行多一点 12345678910111213141516171819202122# Boards may be defined under $(SRC_TARGET_DIR)/board/$(TARGET_DEVICE)# or under vendor/*/$(TARGET_DEVICE). Search in both places, but# make sure only one exists.# Real boards should always be associated with an OEM vendor.board_config_mk := \\ $(strip $(wildcard \\ $(SRC_TARGET_DIR)/board/$(TARGET_DEVICE)/BoardConfig.mk \\ $(shell test -d device &amp;&amp; find device -maxdepth 4 -path '*/$(TARGET_DEVICE)/BoardConfig.mk') \\ $(shell test -d vendor &amp;&amp; find vendor -maxdepth 4 -path '*/$(TARGET_DEVICE)/BoardConfig.mk') \\ ))ifeq ($(board_config_mk),) $(error No config file found for TARGET_DEVICE $(TARGET_DEVICE))endififneq ($(words $(board_config_mk)),1) $(error Multiple board config files for TARGET_DEVICE $(TARGET_DEVICE): $(board_config_mk))endifinclude $(board_config_mk)ifeq ($(TARGET_ARCH),) $(error TARGET_ARCH not defined by board config: $(board_config_mk))endifTARGET_DEVICE_DIR := $(patsubst %/,%,$(dir $(board_config_mk)))board_config_mk := 从解析前的注释中，我们能简单的看出BoardConfig文件的存放位置：$(SRC_TARGET_DIR)/board/$(TARGET_DEVICE) 其中SRC_TARGET_DIR在config.mk文件中已经定义，指向build/target 也就是说Android编译系统允许的BoardConfig.mk存在的位置有三个 build/target/board/$(TARGET_DEVICE) vendor/*/$(TARGET_DEVICE) device/*/$(TARGET_DEVICE) 这三个位置除了固定深度4层之外，还指定了TARGET_DEVICE的限制，这个TARGET_DEVICE的内容是什么，如果你看过之前关于lunch的解析，你应该明白，这个值就是我们自己在product_makefile文件中定义的PRODUCT_DEVICE这个值 Android编译系统要求这个文件是唯一的，所以在获取这三个位置的BoardConfig.mk之后，我们需要告诉使用者只需要一个BoardConfig.mk文件，然后加载这个BoardConfig.mk文件即可 当然，从代码实现的角度来说，实现多个BoardConfig.mk文件同时加载也没有问题，但是从代码维护的角度来说，这样不利于这部分配置文件的维护，所以还是放在一个文件内比较好 在加载完这个文件之后，我们还通过这个文件定义了一个变量TARGET_DEVICE_DIR，我们将BoardConfig.mk文件存在的位置作为了我们后边要加载其他内容的目录，主要是用来作为kernel预编译以及一些信息的文件 至此，关于BoardConfig.mk文件的加载我们也已经解析完了 总结 BoardConfig.mk文件的定义远远没有AndroidProduct.mk文件复杂，毕竟一个成型的Product，平台级别的配置基本已经定型了，我们无需要再做复杂的配置 我们可以看到对于一个Product可以有三个可选的位置放BoardConfig.mk文件，所以对于无法确定目标机型在哪个位置存放了这个配置文件，我们可以通过输出TARGET_DEVICE_DIR的值来判断","link":"/2015/12/28/android-build-system-keypoint-second/"},{"title":"Android编译系统分析之lunch分析","text":"Android 编译系统解析系列文档 编译系统入口envsetup.sh解析 source build/envsetup.sh 做了什么？ 解析lunch的执行过程以及make执行过程中include文件的顺序 Android编译系统分析之lunch分析 Android编译系统分析之make分析 关注一些make执行过程中的几个关键点 Android编译系统分析之几个关键点（一） Android编译系统分析之几个关键点（二） Android编译系统分析之几个关键点（三） 对一些独特的语法结构进行解析 PRODUCT_COPY_FILES语法解析 关于PRODUCT_PROPERTY_OVERRIDES属性的解析 编译一个android Project，我们需要使用到makefile文件，通过makefile文件的规则我们来构建整个Project的编译过程，那么在make之前,首先我们会执行以下命令: 123source build/envsetup.shlunch project_namemake -j32 ( SHOW_COMMANDS=true ) envsetup.sh脚本我们先来看一下source build/envsetup.sh做了什么? 定义函数在envsetup.sh中定义了很多函数，函数列表大致如下： 12345678910111213141516171819202122232425262728293031323334function hmm()function get_abs_build_var()function get_build_var()function check_product()function check_variant()function printconfig()function choosecombo()function add_lunch_combo()function print_lunch_menu()function lunch()function gettopfunction m()function findmakefile()function mm()function mmm()function mma()function mmma()function croot()function ggrep()function jgrep()function cgrep()function resgrep()function mangrep()function sepgrep()function getprebuiltfunction smoketest()function runtest()function godir()function make() 这些中有我们熟悉的m,mm,mmm,lunch,add_lunch_combo,mma,croot,print_lunch_menu,findmakefile,jgrep等等, envsetup.sh做的第一个工作就是定义了许多函数，方便开发者在编译的过程中调用 添加编译参数定义这些函数之后，在脚本的最后，envsetup.sh会遍历源码下device以及vendor目录，查找vendorsetup.sh，找到之后将这些文件include（source vendorsetup.sh) 到当前位置，而这些vendorsetup.sh中都是使用函数add_lunch_combo定义了一些需要编译的Project 123456789101112131415function axxxxxx()function bxxxxxx()...... # Execute the contents of any vendorsetup.sh files we can find. for f in `test -d device &amp;&amp; find -L device -maxdepth 4 -name 'vendorsetup.sh' 2&gt; /dev/null` \\ `test -d vendor &amp;&amp; find -L vendor -maxdepth 4 -name 'vendorsetup.sh' 2&gt; /dev/null` do echo &quot;including $f&quot; . $f done LUNCH_MENU_CHOICES[@] add_lunch_combo实现很简单，就是将其所带的参数添加到LUNCH_MENU_CHOICES数组中 因为前边使用for循环遍历了device和vendor下的vendorsetup.sh文件，所以各个project的编译选项最后都通过add_lunch_combo被添加进了编译系统中 因此如果要想让你新加的project被android编译系统检测到，你需要在vendorsetup.sh中使用add_lunch_combo()添加编译参数，至于编译参数的详细格式，我们后边会有讲到 至此，source build/envsetup.sh的工作就完成了，我们接下来看看lunch 详解lunchlunch的使用方法lunch的使用方法 带参数使用方法lunch 后边可以直接带参，例如lunch meizu_m76-eng，这个meizu_m76-eng参数就是之前add_lunch_combo添加的参数，像这样的在vendorsetup.sh中定义的类似的参数我们可以直接指定 不带参数使用方法如果后边不带参数,直接使用lunch，会在屏幕上打印出一个列表，列出了之前扫描到的所有vendorsetup.sh中设置的project，然后选择即可 不管带不带参数，lunch都会读取project的名称，然后检查project的命名是否符合xxxx-xxx_xxxx这样的格式然后提取出其中的product 和 varient 检查是否合法 检查project的编译参数格式是否符合xxxx-xxxx_xxx，是通过一个正则表达式来验证的 1(echo -n $answer | grep -q -e &quot;^[^\\-][^\\-]*-[^\\-][^\\-]*$&quot;) 包括后边对product 以及varient的提取也是使用sed的正则表达，检查提取出来的变量值是否合法，使用函数check_product()和check_varient() 检查product是否合法我们先来看check_product 1234567891011121314function check_product(){ T=$(gettop) if [ ! &quot;$T&quot; ]; then echo &quot;Couldn't locate the top of the tree. Try setting TOP.&quot; &gt;&amp;2 return fi TARGET_PRODUCT=$1 \\ TARGET_BUILD_VARIANT= \\ TARGET_BUILD_TYPE= \\ TARGET_BUILD_APPS= \\ get_build_var TARGET_DEVICE &gt; dev/null # hide successful answers, but allow the errors to show} 在解析envsetup.sh时，经常会遇到gettop()函数，这个函数的主要作用就是取得源码的根目录的位置，具体实现内容就是依次向上查找包含 build/core/envsetup.mk 文件的目录，然后使用pwd获取当前目录即可 在check_product()函数中，TARGET_PRODUCT将被赋值为之前提取出的product ,例如meizu_m76接着通过 get_build_var() 来获取一些变量的值 注意这里传入的是 TARGET_DEVICE 这个变量,这个时候变量的内容为空 接下来是get_build_var函数 12345678910function get_build_var(){ T=$(gettop) if [ ! &quot;$T&quot; ]; then echo &quot;Couldn't locate the top of the tree. Try setting TOP.&quot; &gt;&amp;2 return fi (\\cd $T; CALLED_FROM_SETUP=true BUILD_SYSTEM=build/core \\ command make --no-print-directory -f build/core/config.mk dumpvar-$1)} 定义了两个变量的值, 12CALLED_FROM_SETUP=true BUILD_SYSTEM=build/core 然后使用了command make命令传入一个指定的文件 build/core/config.mk ，带了参数 dumpvar-TARGET_DEVICE这里需要注意一下，command命令后边跟着的是指内置的shell命令，而不是系统命令，你可以在envsetup.sh脚本的最后找到android封装过的make函数，这里调用的其实就是那个封装过的函数，函数中增加了编译校验以及时间戳的标记方便用户查看 另外，这里也是bash脚本与makefile文件交互的位置，从这一函数开始，我们接下来的主要工作就需要用到makefile文件了，所以我们暂时先跳过这部分，接着来看bash脚本相关的内容 检查variant是否合法检查完product 之后，需要check_variant，这个比较简单，只需要查找是否在已经预定义好的VARIANT_CHOICES数组中即可 1234567891011function check_variant(){ for v in ${VARIANT_CHOICES[@]} do if [ &quot;$v&quot; = &quot;$1&quot; ] then return 0 fi done return 1} 设置环境变量然后还有最后的几步工作要做 123456export TARGET_PRODUCT=$productexport TARGET_BUILD_VARIANT=$variantexport TARGET_BUILD_TYPE=releaseset_stuff_for_environmentprintconfig 将刚刚获取并且检查过的变量export，然后设置环境变量，并打印一些字段的值 我们注意到这里也使用到了get_build_var()函数，而这次传入的参数是report_config，这个具体执行过程我们在最后一起分析，至此，我们导入环境变量，并lunch product_name 的整个过程就结束了 其他注意事项另外还有一点需要注意，envsetup.sh中导出了一些环境变量,因为envsetup.sh大多数都是local,所以为了之后操作的方便,使用export导出了如下这些环境变量 1234567891011121314151617181920212223242526ANDROID_BUILD_PATHS=$(get_build_var ANDROID_BUILD_PATHS):$ANDROID_TOOLCHAIN:$ANDROID_TOOLCHAIN_2ND_ARCH:$ANDROID_KERNEL_TOOLCHAIN_PATH$ANDROID_DEV_SCRIPTS:ANDROID_BUILD_TOP=$(gettop)ANDROID_DEV_SCRIPTS=$T/core/envdevelopment/core/envscripts:$T/core/envprebuilts/core/envdevtools/core/envtoolsANDROID_EMULATOR_PREBUILTSANDROID_HOST_OUT=$(get_abs_build_var HOST_OUT)ANDROID_JAVA_TOOLCHAIN=$JAVA_HOME/core/envbinANDROID_PRE_BUILD_PATHS=$ANDROID_JAVA_TOOLCHAIN:ANDROID_PRODUCT_OUT=$(get_abs_build_var PRODUCT_OUT)ANDROID_SET_JAVA_HOME=trueANDROID_TOOLCHAIN_2ND_ARCH=$gccprebuiltdir/core/env$toolchaindir2ANDROID_TOOLCHAIN=$gccprebuiltdir/core/env$toolchaindirARM_EABI_TOOLCHAIN=&quot;$gccprebuiltdir/core/env$toolchaindir&quot;BUILD_ENV_SEQUENCE_NUMBER=10GCC_COLORS='error=01;31:warning=01;35:note=01;36:caret=01;32:locus=01:quote=01'HOST_EXTRACFLAGS=&quot;-I &quot;$T/core/envsystem/core/envkernel_headers/core/envhost_includeJAVA_HOME=/core/envusr/core/envlib/core/envjvm/core/envjava-7-openjdk-amd64OUT=$ANDROID_PRODUCT_OUTPATH=$ANDROID_PRE_BUILD_PATHS$PATHPROMPT_COMMAND=&quot;echo -ne \\&quot;\\033]0;[${arch}-${product}-${variant}] ${USER}@${HOSTNAME}: ${PWD}\\007\\&quot;&quot;TARGET_BUILD_APPS=$appsTARGET_BUILD_DENSITY=$densityTARGET_BUILD_TYPE=TARGET_BUILD_TYPE=releaseTARGET_BUILD_VARIANT=TARGET_GCC_VERSION=$targetgccversionTARGET_PRODUCT= 进入makefile的世界之前我们在分析envsetup.sh脚本的时候遇到了get_build_var()函数，这个函数指定了一个makefile文件，并传入dumpvar-$1参数，我们可以很轻易的找到对于dumpvar-$1类似参数出现的地方只有一个，就是dumpvar.mk文件，而我们在config.mk的尾行找到这样一句include dumpvar.mk所以我们直接来关注dumpvar.mk文件 dumpvar.mk文件的作用是打印出一些基本的变量 我们来看看具体干了什么 12dumpvar_goals := \\ $(strip $(patsubst dumpvar-%,%,$(filter dumpvar-%,$(MAKECMDGOALS)))) 这个dumpvar_goals的目标就是前边的传进来的，经过替换 dumpvar_goals := TARGET_DEVICE 12345678910111213absolute_dumpvar := $(strip $(filter abs-%,$(dumpvar_goals))) ifdef absolute_dumpvar dumpvar_goals := $(patsubst abs-%,%,$(dumpvar_goals)) ifneq ($(filter /core/env%,$($(dumpvar_goals))),) DUMPVAR_VALUE := $($(dumpvar_goals)) else DUMPVAR_VALUE := $(PWD)/core/env$($(dumpvar_goals)) endif dumpvar_target := dumpvar-abs-$(dumpvar_goals) else DUMPVAR_VALUE := $($(dumpvar_goals)) dumpvar_target := dumpvar-$(dumpvar_goals) endif 如果之前追加的变量是dumpvar-abs-VARNAME, 那就返回一个参数,我们直接lunch的时候，传入一个dumpvar-VARNAME，因此直接来看11,12行的代码那么 DUMPVAR_VALUE := $(TARGET_DEVICE) dumpvar_target := dumpvar-TARGET_DEVICE 那么这个TARGET_DEVICE的值是从哪里来的呢? 我们前边只是知道了product的值(meizu_m76),它和device的值有什么关系吗? 我们来看看相关makefile的include的关系 123456789101112131415161718config.mk ( ...... 151:include envsetup.mk ( ...... 0:include version_defaults.mk 138:include product_config.mk( ...... 178:include node_fns.mk 179:include product.mk 180:include device.mk ...... ) ...... ) ...... $:include dumpvar.mk( )) 通过以上这个include的顺序图，我们可以看到lunch的过程中，make构建规则依赖的就是include 这些文件而组成的一个大的Makefile文件 而AndroidProduct.mk的相关的定义是在product_config.mk中的这句： all_product_configs := $(get-all-product-makefiles) 取所有的AndroidProduct.mk中定义的product_makefile 12345678910111213141516171819202122232425262728293031define _find-android-products-files $(shell test -d device &amp;&amp; find device -maxdepth 6 -name AndroidProducts.mk) \\ $(shell test -d vendor &amp;&amp; find vendor -maxdepth 6 -name AndroidProducts.mk) \\ $(SRC_TARGET_DIR)/core/product/core/AndroidProducts.mkendef......define get-product-makefiles$(sort \\ $(foreach f,$(1), \\ $(eval PRODUCT_MAKEFILES :=) \\ # 去掉 f 定义的路径,然后include 文件到这里,取出PRODUCT_MAKEFILES的值,将其排序 $(eval LOCAL_DIR := $(patsubst %/core/env,%,$(dir $(f)))) \\ $(eval include $(f)) \\ $(PRODUCT_MAKEFILES) \\ ) \\ $(eval PRODUCT_MAKEFILES :=) \\ $(eval LOCAL_DIR :=) \\ )endef # # Returns the sorted concatenation of all PRODUCT_MAKEFILES # variables set in all AndroidProducts.mk files. # $(call ) isn't necessary. # define get-all-product-makefiles $(call get-product-makefiles,$(_find-android-products-files)) endef 其中AndroidProduct.mk查找的范围为 device 和 vendor 目录下6级深度以内以及 SRC_TARGET_DIR 下的所有文件 SRC_TARGET_DIR := $(TOPDIR)build/core/target 翻译一下也就是build/core/target/目录中的AndroidProduct.mk那么最后all_product_configs的值就是所有xxxxx_product.mk的集合 注意:这里有一个关键点TARGET_BUILD_APPS如果构建的是APP的话,我们可以只需要加载核心product makefiles就可以,在这里我们是编译系统,所以这个值为空 123456789ifneq ($(strip $(TARGET_BUILD_APPS)),) # An unbundled app build needs only the core product makefiles. all_product_configs := $(call get-product-makefiles,\\ $(SRC_TARGET_DIR)/core/product/core/AndroidProducts.mk)else # Read in all of the product definitions specified by the AndroidProducts.mk # files in the tree. all_product_configs := $(get-all-product-makefiles)endif 这里有对PRODUCT_MAKEFILES的格式的定义,如果product_name 和文件名称一样,那么可以省略例如：product_name为meizu_m76,如果product的makefile文件为meizu_m76.mk,那么product_name这个前缀就可以省略不写 12345Format of PRODUCT_MAKEFILES: # &lt;product_name&gt;:&lt;path_to_the_product_makefile&gt; # If the &lt;product_name&gt; is the same as the base file name (without dir # and the .mk suffix) of the product makefile, &quot;&lt;product_name&gt;:&quot; can be # omitted. 搞清楚了这一点,我们来看一下如何找到current_product_makefile 123456789101112131415161718current_product_makefile := all_product_makefiles := $(foreach f, $(all_product_configs),\\ $(eval _cpm_words := $(subst :,$(space),$(f)))\\ $(eval _cpm_word1 := $(word 1,$(_cpm_words)))\\ $(eval _cpm_word2 := $(word 2,$(_cpm_words)))\\ $(if $(_cpm_word2),\\ $(eval all_product_makefiles += $(_cpm_word2))\\ $(if $(filter $(TARGET_PRODUCT),$(_cpm_word1)),\\ $(eval current_product_makefile += $(_cpm_word2)),),\\ $(eval all_product_makefiles += $(f))\\ $(if $(filter $(TARGET_PRODUCT),$(basename $(notdir $(f)))),\\ $(eval current_product_makefile += $(f)),))) _cpm_words := _cpm_word1 := _cpm_word2 := current_product_makefile := $(strip $(current_product_makefile)) all_product_makefiles := $(strip $(all_product_makefiles)) 根据定义,我们可以使用简写,那么_cpm_word2为空,我们只需将与TARGET_PRODUCT相等的makefile加进去就可以了,这里使用的是+=, 表示可以定义多个product_makefile,current_product_makefile 则是我们定义的TARGET_PRODUCT过滤出来的文件,all_product_makefiles 则是之前找到的全部的product文件 product_config.mk文件还定义了我们之前一直苦苦寻找的TARGET_DEVICE 12# Find the device that this product maps to.TARGET_DEVICE := $(PRODUCTS.$(INTERNAL_PRODUCT).PRODUCT_DEVICE) 这个INTERNAL_PRODUCT值通过在product.mk中定义的resolve-short-product-name函数,返回product所对应的makefile的路径 INTERNAL_PRODUCT := $(call resolve-short-product-name, $(TARGET_PRODUCT)) google使用INTERNAL_PRODUCT这个变量的作用是为了区分例如PRODUCT_COPY_FILES这些变量在不同地方定义无法区分的问题,通过使用这样的定义就可以区分不同文件的相同的定义了这里TARGET_DEVICE的值是product makefile中的PRODUCT_DEVICE字段,如果是meizu_m76 我们定义的就是m76 知道了TARGET_DEVICE的值,我们继续回到dumpvar.mk中看看之后做了什么 123.PHONY: $(dumpvar_target)$(dumpvar_target): @echo $(DUMPVAR_VALUE) 定义了一个target 就是dumpvar-TARGET_DEVICE,然后打印了TARGET_DEVICE变量的值这样就check_product完毕(打印了这个值就是执行成功,如果执行失败就会直接报错,也就是检查失败) 在dumpvar.mk文件的末尾，打印解析出来的一些product的字段","link":"/2015/12/01/android-build-system-lunch/"},{"title":"Android编译系统分析之make分析","text":"Android 编译系统解析系列文档 编译系统入口envsetup.sh解析 source build/envsetup.sh 做了什么？ 解析lunch的执行过程以及make执行过程中include文件的顺序 Android编译系统分析之lunch分析 Android编译系统分析之make分析 关注一些make执行过程中的几个关键点 Android编译系统分析之几个关键点（一） Android编译系统分析之几个关键点（二） Android编译系统分析之几个关键点（三） 对一些独特的语法结构进行解析 PRODUCT_COPY_FILES语法解析 关于PRODUCT_PROPERTY_OVERRIDES属性的解析 概览Android编译系统概览 makefile语法的简要说明Makefile文件的include顺序main.mk文件中include的各文件职责 config.mk文件中include的各文件职责 Android编译系统流程的简要总结 正文编译android的源代码时我们要经历三个阶段 123source build/envsetup.shlunch project_namemake (SHOW_COMMANDS) 关于前两阶段的具体内容请参见另一篇文章 android 编译系统之lunch分析这一章节我们主要来看看整个android编译系统的整体框架 Android编译系统概览makefile语法的简要说明12target ... : prerequisites ...[tab] command 这是makefile基本语法 target 就是目标文件，可以是一个object，也可以是一个可执行文件，还可以是一个label（伪目标） prerequisites 就是要生成target所依赖的文件或者目标 command 也就是make要执行的命令（任意的shell命令） 注意，command命令必须要使用[tab]键开头，否则make无法识别 明白了语法规则，来看看执行规则：target 这一个或者多个目标的文件依赖于prerequistites中的文件，其生成规则在command中，这其中的依赖规则判断是：如果prerequisites中有一个或以上文件比target新（判断modification times)，那么就执行command所定义的命令 默认情况下执行make命令会在当前目录下依次寻找GNUMakefile(GNU独有)、makefile、Makefile这三个文件,然后执行文件中声明的第一个目标所以我们在源码根目录执行make文件时,会默认执行Makefile，而这个文件内容只有一行 1include build/core/main.mk 我们直接来看main.mk文件干了什么 Makefile文件的include顺序通过解析main.mk文件,我们可以大致看到include的文件的顺序 # 以下为执行make与lunch时，include文件顺序以及行号 #执行make时,会include build/core/main.mk main.mk ( 89:include help.mk 93:include config.mk 99:include cleanbuild.mk 260:include definitions.mk 263:include dex_preopt.mk 297:include pdk_config.mk 487:include $(ONE_SHOT_MAKEFILE)(如果变量不为空,则include) 525:include post_clean.mk 531:include legacy_prebuilts.mk 797:include Makefile ) #执行lunch时候,会直接make -f build/core/config.mk # config.mk ( 60:include pathmap.mk 151:include envsetup.mk ( 10:include version_defaults.mk ( 34:include build_id.mk ) 138:include product_config.mk ( 178:include node_fns.mk 179:include product.mk 180:include device.mk ) 162:include $(board_config_mk) (BoardConfig.mk, device和vendor目录,保证其only one) ) 226:include combo/select.mk 342:include combo/javac.mk 576:include clang/config.mk $:include dumpvar.mk ) main.mk文件中include的各文件职责core/help.mk Targets that provide quick help on the build system目的是为了在构建系统的时候提供快捷的帮助 core/help.mk文件中只定义了一个伪目标help，用来打印make命令的一些target提示 core/config.mk Set up various standard variables based on configuration and host information目的是基于用户的配置和编译主机的环境信息来配置一些基本的变量（这些功能又由include的一些文件来承担） core/config.mk文件通过收集用户定义的机型信息（在device以及vendor目录下的机型文件）以及定义一些基本的变量例如我们在编写模块编译文件也就是Android.mk文件时，经常要include一个变量CLEAR_VARS，这个变量实际的值就是build/core/clear_vars.mk文件，还有其他一些BUILD_STATIC_LIBRARY,BUILD_SHARED_LIBRARY也都是通过include对应的mk文件来添加一些定义项，这个文件还会指定一些编译工具的目录，方便后边的使用，也会收集一些主机编译环境来判断是否符合android编译的要求。从上一篇lunch的分析中，我们得知，lunch时，直接执行config.mk文件make -f build/core/config.mk因此这个文件以及其中include的那些文件是加载各种配置文件的核心文件，这个文件以及其中include的那些文件我们稍后集中分析，我们继续往下看 core/cleanbuild.mk This allows us to force a clean build - included after the config.mkenvironment setup is done, but before we generate any dependencies. Thisfile does the rm -rf inline so the deps which are all done below willbe generated correctly 允许我们进行强制的清理-包括在config.mk环境变量设置之后,在我们产生任何依赖之前这个文件内部执行rm -rf ,因此后边完成的这些依赖可以被正确的产生,文件定义了一个installclean的伪目标 我们可以在make user或make all之间切换的时候执行make installclean，这样的好处在于只会清理build type相关的内容，而不会全清，节省编译时间。这个文件还定义了一个previous_build_config.mk文件，在每次编译的时候，将会写入下边的变量的值$(TARGET_PRODUCT)-$(TARGET_BUILD_VARIANT)-{$(aapt_config_list)}如果与和上一次不同，就会强制进行installclean操作，来避免不同build type切换时产生的影响 Tips：这个文件的内容可以帮助我们快速确认当前编译的机型，编译类型，还有语言配置和aapt的配置 core/definitions.mk Bring in standard build system definitions加入标准的通用编译系统的一些函数以及变量的定义 这个文件会定义一些通用的函数，比如我们很熟悉的all-subdir-makefile，all-java-files-under，copy-file-to-target等，这些函数的定义大大提升了我们在编写自己的机型以及模块mk文件的便捷性 core/dex_preopt.mk 加入dexprepopt的支持 这个文件通常用来在构建user版的时候执行dexopt(优化dalvik)或者dex2oat(优化ART)，来为jar和apk做优化 core/pdk_config.mk The pdk (Platform Development Kit) build PDK的配置文件，pdk是google引入的一套机制，方便手机硬件制造商在源代码版本开放之前取得android版本，从而更快的跟上google更新android的步伐，减少android的碎片化 $(ONE_SHOT_MAKEFILE) 顾名思义,ONE_SHOT一次使用,主要用来include编译所需要的各个模块的Android.mk文件 这个变量在使用mm 与 mmm命令的时候被定义,也就是在编译某个模块的时候会被赋值,这种情况下只需要include需要的Android.mk文件就行,如果不是单编,并且make的目标是一些不需要依赖的目标的话,例如snod,clean,systemimage-nodeps等,那么什么都不干,直接生成目标就行,除这两种情况,也就是在全编的情况下,需要include所有模块的Android.mk文件 core/post_clean.mk 在所有文件都加载完成之后,做一个clean或者check的工作 这个文件是在include 所有的makefile文件之后，因此overlay和aidl文件肯可能会有变化,这个文件的作用就是check是否发生变化，然后决定是否要重新生成 legacy_prebuilts.mk 这是对一些预编译的文件的处理 之前使用的是ALL_PREBUILT这个变量来定义，在新版中使用PRODUCT_COPY_FILE来代替，这里的主要作用是检查ALL_PREBUILT变量中是否含有legacy_prebuild.mk所包含的预编译文件，如果有就会报错，提示你要将这些文件使用PRODUCT_COPY_FILE来预编译 Makefile 核心编译文件，定义了版本固件的最终生成文件 这个文件算是android编译系统的核心文件了，之前include的所有的文件，定义的变量，用户的配置，都是为了这个文件服务，这个文件会先check预编译的文件的合法性(也就是检查PRODUCT_COPY_FILE变量)，然后去构建build.prop，接着定义了systemimg，bootimage，ramdisk，otapackage等编译系统要生成的最终目标，也就是在这个文件加载之后，系统内所有的需要编译的mk文件都会汇合成一个大的makefile文件，然后按序执行 config.mk文件中include的各文件职责core/pathmap.mk central place to define mappings to paths, to avoid hard-coding them in Android.mk files.定义匹配路径的地方,避免在Android.mk中硬编码这些位置 将一些经常用到的路径定义为固定的宏，方便开发者编写Makefile文件时引用，主要是一些头文件的路径 core/envsetup.mk 顾名思义，是一些环境变量的初始化 设置一些HOST主机以及TARGET目标的基本的环境变量，例如out,system,等的目录的宏定义，还有区分目标架构x86与64，HOST类型linux与windows，以及各个类型的生成文件该放置到目录的定义，例如bin,etc,jar等文件，除此之外还解析了BoardConfig.mk以及AndroidProduct.mk文件，并对其中的BOARD_xxx以及PRODUCT_xxx变量进行check和处理 core/version_defaults.mk 定义一些BUILD环境的基本变量 PLATFORM_VERSION := 5.1.1，android版本号PLATFORM_SDK_VERSION := 22，定义了目标SDK的版本，软件中最小的版本号不能超出这个值PLATFORM_VERSION_CODENAME := REL 一个版本名称，如果是最后一个版本，可以简单的使用RELDEFAULT_APP_TARGET_SDK := $(PLATFORM_VERSION_CODENAME) APP的默认的版本号，如果是最后发布版，则使用PLATFORM_SDK_VERSION的值BUILD_ID := 通常用于usr版中显示的版本号BUILD_NUMBER := eng.$(USER).$(shell date +%Y%m%d.%H%M%S) build的数字，默认是以工程版格式命名，用日期来区分 core/build_id.mk导出BUILD_ID的变量的值，通常用于user版中的版本号，如果没有，就是UNKNOWN core/product_config.mk 关于product的一些用户设置的处理 主要内容有三点：1.android提供了一种方法可以直接指定要编译的product而不需要初始化环境变量来选择,只需要你在make的时候指定格式”PRODUCT–”，以76为例，我们可以直接make PRODUCT-meizu_m76-eng来编译76 eng的版本，只不过这样的话，你就无法使用croot,godir等函数了．与此类似的还有独立app的编译格式”APP-“２.对product以及device等变量（PRODUCT_xxxx,TARGET_xxx,DEVICE_xxx,BOARD_xxx)的处理函数的定义3.对device以及vendor目录下定义的PRODUCT_变量的处理 core/node_fns.mk 编译系统对product相关变量(PRODUCT_xxx,DEVICE_xxx)处理的函数的定义 实际上这个文件的内容主要是对inherit这种继承的方式做了定义，是后边定义的product.mk与device.mk中使用到的一些函数的公共定义说明，主要使用的方式是inherit-product与inherit-device core/product.mk product相关变量的使用的帮助函数 这个文件提供了PRODUCT_xxx变量的处理方法，以及PRODCUT_xxx,TARGET_xxxx,BOARD_xxx等变量的声明，后边会使用这几个列表来过滤出相关的定义，然后做出处理，主要的内容是inherit-product的定义，这可以使得我们可以很方便的使用google提供的一些预定义的变量来初始化我们自己的product core/device.mk device相关变量的使用帮助函数 定义了DEVICE_xxx函数列表，以及同样的inherit-device来继承已有的变量定义 $(board_config_mk) 对BOARD_xxx打头的变量的处理，也就是对BoardConfig.mk文件的处理 扫描device以及vendor目录下４层深度以内的BoardConfig.mk文件，并include combo/select.mk 对C/C++编译器参数做一些设置 combo/javac.mk 对java编译器的选择和一些参数的设置 core/dumpvar.mk 打印一些变量的值 这个mk文件的主要作用就是当我们lunch了一个机型之后，会以一个规范的格式打印相关变量的值 Android编译系统流程的简要总结在了解了以上的include顺序之后,我们总结一下Android的编译系统: 首先通过来检查一些系统编译环境的各个软件版本是否符合要求,并定义一些基本宏来表示不同的目录与基本的环境变量,参与文件： help.mk,pathmap.mk,version_defaults.mk,pathmap.mk,build_id.mk 然后读取产品层ProductConfig的设置,这其中就包含了对以PRODUCT_xxxx，TARGET_xxxx，BOARD_xxxx等开头一系列变量(包括PRODUCT_LOCALES,PRODUCT_COPY_FILES等)的处理,参与文件：变量product_config.mk所包括的值(AndroidProduct.mk以及其中定义的类似device.mk的makefile文件) 然后读取一些硬件层BoardConfig的设置,参与文件：变量board_config_mk所表示的值(BoardConfig.mk) 然后根据当前编译的类型(mm还是mmm还是clean还是全编)来决定包含哪些模块,参与文件：Android.mk 然后打印出一些已经配置好的变量的值,可以通过printconfig命令来查看,参与文件：dump-var.mk 然后定义一些基本的函数方便开发者在编写makefile文件的时候使用,参与文件：definitions.mk 然后对之前所作的操作做一些检查,参与文件：post_clean.mk 最后定义最终的编译目标(systemiamge,bootimage,ramdisk等) 以及他们之间依赖的文件,参与文件:Makefile","link":"/2015/12/08/android-build-system-make/"},{"title":"PRODUCT_COPY_FILES语法解析","text":"Android 编译系统解析系列文档 编译系统入口envsetup.sh解析 source build/envsetup.sh 做了什么？ 解析lunch的执行过程以及make执行过程中include文件的顺序 Android编译系统分析之lunch分析 Android编译系统分析之make分析 关注一些make执行过程中的几个关键点 Android编译系统分析之几个关键点（一） Android编译系统分析之几个关键点（二） Android编译系统分析之几个关键点（三） 对一些独特的语法结构进行解析 PRODUCT_COPY_FILES语法解析 关于PRODUCT_PROPERTY_OVERRIDES属性的解析 PRODUCT_COPY_FILES变量很常用，但是这个变量的作用方式却又与一般的定义符号作用不一样，所以单独提出来说说 解析PRODUCT_COPY_FILES变量作用的函数,位于build/core/Makefile 1234567891011121314151617181920212223242526272829303132# -----------------------------------------------------------------# Define rules to copy PRODUCT_COPY_FILES defined by the product.# PRODUCT_COPY_FILES contains words like &lt;source file&gt;:&lt;dest file&gt;[:&lt;owner&gt;].# &lt;dest file&gt; is relative to $(PRODUCT_OUT), so it should look like,# e.g., &quot;system/etc/file.xml&quot;.# The filter part means &quot;only eval the copy-one-file rule if this# src:dest pair is the first one to match the same dest&quot;#$(1): the src:dest pairdefine check-product-copy-files$(if $(filter %.apk, $(call word-colon, 2, $(1))),$(error \\ Prebuilt apk found in PRODUCT_COPY_FILES: $(1), use BUILD_PREBUILT instead!))endef# filter out the duplicate &lt;source file&gt;:&lt;dest file&gt; pairs.unique_product_copy_files_pairs :=$(foreach cf,$(PRODUCT_COPY_FILES), \\ $(if $(filter $(unique_product_copy_files_pairs),$(cf)),,\\ $(eval unique_product_copy_files_pairs += $(cf))))unique_product_copy_files_destinations :=$(foreach cf,$(unique_product_copy_files_pairs), \\ $(eval _src := $(call word-colon,1,$(cf))) \\ $(eval _dest := $(call word-colon,2,$(cf))) \\ $(call check-product-copy-files,$(cf)) \\ $(if $(filter $(unique_product_copy_files_destinations),$(_dest)), \\ $(info PRODUCT_COPY_FILES $(cf) ignored.), \\ $(eval _fulldest := $(call append-path,$(PRODUCT_OUT),$(_dest))) \\ $(if $(filter %.xml,$(_dest)),\\ $(eval $(call copy-xml-file-checked,$(_src),$(_fulldest))),\\ $(eval $(call copy-one-file,$(_src),$(_fulldest)))) \\ $(eval ALL_DEFAULT_INSTALLED_MODULES += $(_fulldest)) \\ $(eval unique_product_copy_files_destinations += $(_dest))))unique_product_copy_files_pairs :=unique_product_copy_files_destinations := 我们来看这里使用了两个变量unique_product_copy_files_pairsunique_product_copy_files_destinations从名字上来说，我们也能发现，这两个变量是分别用来处理copy对以及copy目标的，我们挨个儿解析，先去掉重复对（pairs）的，也就是source:dest 定义重复的 12345unique_product_copy_files_pairs :=$(foreach cf,$(PRODUCT_COPY_FILES), \\ $(if $(filter $(unique_product_copy_files_pairs),$(cf)),,\\ $(eval unique_product_copy_files_pairs += $(cf)))) 然后开始处理destination重复定义的 从之前去重的copy对中挨个提取_src，_dest，word-colon只是用来分离:前后字段的一个封装 使用check-product-copy-files检查apk混了进来，那么就报错，因为apk是使用BUILD_PREBUILT方式来处理的 然后以dest文件为目标过滤重复，保留出现的第一个，去掉后边重复的（dest file重复),然后对过滤出的文件追加out的路径(out/target/product/xxxxx/) 这里第三步比较关键，我们来分析一下:这里用到一个if判断，如果检测到重复了，那么将这个pair打印出来，否则就做以下这些操作: 为dest追加out的路径，因为编译系统默认的路径都在源码根目录，所以拷贝的时候需要添加out目录前缀 对于xml文件来说，使用xmllint来验证格式是否正确，如果没问题，那么执行copy操作，对于其他文件直接copy(实际使用copy-file-to-target执行) 追加到ALL_DEFAULT_INSTALLED_MODULES 这个变量中，表示已经安装过了这个文件 以及加入到unique_product_copy_files_destinations变量表示已经执行拷贝操作了，下次遇到就要过滤 对于这样的实现方式，不是很符合我们的直觉，因为我们直觉是后边拷贝的文件会覆盖前边拷贝的文件，所以我们通过追查build/core/Makefile的提交历史，找到了这样一条提交518ce5753a95355eccf396f8ed9c36960c83274b 额，提交前的实现方式是直接覆盖，提交之后就变成拷贝第一个了，提交信息也比较含糊…没有办法看出这样做的原因是什么坑：对于PRODUCT_COPY_FILES，dest目标都是使用字符串匹配形式的，所以对于/system/system/这属于两个字符串，不会被过滤","link":"/2016/02/24/android-build-system-parse-PRODUCT_COPY_FILES/"},{"title":"关于PRODUCT_PROPERTY_OVERRIDES属性的解析","text":"Android 编译系统解析系列文档 编译系统入口envsetup.sh解析 source build/envsetup.sh 做了什么？ 解析lunch的执行过程以及make执行过程中include文件的顺序 Android编译系统分析之lunch分析 Android编译系统分析之make分析 关注一些make执行过程中的几个关键点 Android编译系统分析之几个关键点（一） Android编译系统分析之几个关键点（二） Android编译系统分析之几个关键点（三） 对一些独特的语法结构进行解析 PRODUCT_COPY_FILES语法解析 关于PRODUCT_PROPERTY_OVERRIDES属性的解析 这个属性我们可以直接搜索源代码找到对应的位置 123456789101112131415######product_config.mk####### A list of property assignments, like &quot;key = value&quot;, with zero or more# whitespace characters on either side of the '='.PRODUCT_PROPERTY_OVERRIDES := \\ $(strip $(PRODUCTS.$(INTERNAL_PRODUCT).PRODUCT_PROPERTY_OVERRIDES))......# Add the product-defined properties to the build properties.ADDITIONAL_BUILD_PROPERTIES := \\ $(ADDITIONAL_BUILD_PROPERTIES) \\ $(PRODUCT_PROPERTY_OVERRIDES) 从之前的继承系列的文章我们可以直到，PRODUCT_*系列的变量都有继承的功能，所以我们的PRODUCT_PROPERTY_OVERRIDES最终的取值就是$(PRODUCTS.$(INTERNAL_PRODUCT).PRODUCT_PROPERTY_OVERRIDES),其中INTERNAL_PRODUCT对应的是当前编译机型配置目录相对于源码根目录的相对路径 接着，将这个属性赋予ADDITIONAL_BUILD_PROPERTIES这个变量 这块代码高亮部分显示的ADDITIONAL_BUILD_PROPERTIES宏的值已经在这个文件之前的部分处理过了，是这块代码 12345678# build.propINSTALLED_BUILD_PROP_TARGET := $(TARGET_OUT)/build.propALL_DEFAULT_INSTALLED_MODULES += $(INSTALLED_BUILD_PROP_TARGET)ADDITIONAL_BUILD_PROPERTIES := \\ $(call collapse-pairs, $(ADDITIONAL_BUILD_PROPERTIES))ADDITIONAL_BUILD_PROPERTIES := $(call uniq-pairs-by-first-component, \\ $(ADDITIONAL_BUILD_PROPERTIES),=) 这里同样有两个函数处理这个变量collapse-pairs与uniq-pairs-by-first-component我们来看这两个函数 1234567891011121314151617181920define collapse-pairs$(eval _cpSEP := $(strip $(if $(2),$(2),=)))\\$(subst $(space)$(_cpSEP)$(space),$(_cpSEP),$(strip \\ $(subst $(_cpSEP), $(_cpSEP) ,$(1))))endef############################################################# Given a list of pairs, if multiple pairs have the same## first components, keep only the first pair.#### $(1): list of pairs## $(2): the separator word, such as &quot;:&quot;, &quot;=&quot;, etc.define uniq-pairs-by-first-component$(eval _upbfc_fc_set :=)\\$(strip $(foreach w,$(1), $(eval _first := $(word 1,$(subst $(2),$(space),$(w))))\\ $(if $(filter $(_upbfc_fc_set),$(_first)),,$(w)\\ $(eval _upbfc_fc_set += $(_first)))))\\$(eval _upbfc_fc_set :=)\\$(eval _first:=)endef collapse-pairs函数是用来格式化赋值语句的，去掉=两边的空格，例如a = b或a =b，都会格式化为a=b uniq-pairs-by-first-component函数是用来剔除这些赋值语句中多次重复对一个属性进行赋值的语句，规则为我们根据第二个参数来过滤第一个参数中重复的list示例如下： 12ro.mm.ffmpeg=1ro.mm.ffmpeg=0 对于以上的两个属性，后一条属性会被过滤掉，只保留前一条属性，这个规则和PRODUCT_COPY_FILES是一样的 最终在Makefile中处理已经过滤完毕的属性，具体是在生成build.prop文件的时候，下边是主要的代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162$(INSTALLED_BUILD_PROP_TARGET): $(BUILDINFO_SH) $(INTERNAL_BUILD_ID_MAKEFILE) $(BUILD_SYSTEM)/version_defaults.mk $(system_prop_file) @echo Target buildinfo: $@ @mkdir -p $(dir $@) $(hide) echo &gt; $@ifneq ($(PRODUCTS.$(INTERNAL_PRODUCT).PRODUCT_OEM_PROPERTIES),) $(hide) echo &quot;#&quot; &gt;&gt; $@; \\ echo &quot;# PRODUCT_OEM_PROPERTIES&quot; &gt;&gt; $@; \\ echo &quot;#&quot; &gt;&gt; $@; $(hide) $(foreach prop,$(PRODUCTS.$(INTERNAL_PRODUCT).PRODUCT_OEM_PROPERTIES), \\ echo &quot;import /oem/oem.prop $(prop)&quot; &gt;&gt; $@;)endif $(hide) TARGET_BUILD_TYPE=&quot;$(TARGET_BUILD_VARIANT)&quot; \\ TARGET_BUILD_FLAVOR=&quot;$(TARGET_PRODUCT)-$(TARGET_BUILD_VARIANT)&quot; \\ TARGET_DEVICE=&quot;$(TARGET_DEVICE)&quot; \\ PRODUCT_NAME=&quot;$(TARGET_PRODUCT)&quot; \\ PRODUCT_BRAND=&quot;$(PRODUCT_BRAND)&quot; \\ PRODUCT_DEFAULT_LANGUAGE=&quot;$(call default-locale-language,$(PRODUCT_LOCALES))&quot; \\ PRODUCT_DEFAULT_REGION=&quot;$(call default-locale-region,$(PRODUCT_LOCALES))&quot; \\ PRODUCT_DEFAULT_WIFI_CHANNELS=&quot;$(PRODUCT_DEFAULT_WIFI_CHANNELS)&quot; \\ PRODUCT_MODEL=&quot;$(PRODUCT_MODEL)&quot; \\ PRODUCT_MANUFACTURER=&quot;$(PRODUCT_MANUFACTURER)&quot; \\ PRIVATE_BUILD_DESC=&quot;$(PRIVATE_BUILD_DESC)&quot; \\ BUILD_ID=&quot;$(BUILD_ID)&quot; \\ BUILD_DISPLAY_ID=&quot;$(BUILD_DISPLAY_ID)&quot; \\ BUILD_DISPLAY_ID_MASK=&quot;$(BUILD_DISPLAY_ID_MASK)&quot; \\ BUILD_INSIDE_ID_MASK=&quot;$(BUILD_INSIDE_ID_MASK)&quot; \\ BUILD_NUMBER=&quot;$(BUILD_NUMBER)&quot; \\ PLATFORM_VERSION=&quot;$(PLATFORM_VERSION)&quot; \\ PLATFORM_SDK_VERSION=&quot;$(PLATFORM_SDK_VERSION)&quot; \\ PLATFORM_VERSION_CODENAME=&quot;$(PLATFORM_VERSION_CODENAME)&quot; \\ PLATFORM_VERSION_ALL_CODENAMES=&quot;$(PLATFORM_VERSION_ALL_CODENAMES)&quot; \\ BUILD_VERSION_TAGS=&quot;$(BUILD_VERSION_TAGS)&quot; \\ TARGET_BOOTLOADER_BOARD_NAME=&quot;$(TARGET_BOOTLOADER_BOARD_NAME)&quot; \\ BUILD_FINGERPRINT=&quot;$(BUILD_FINGERPRINT)&quot; \\ $(if $(OEM_THUMBPRINT_PROPERTIES),BUILD_THUMBPRINT=&quot;$(BUILD_THUMBPRINT)&quot;) \\ TARGET_BOARD_PLATFORM=&quot;$(TARGET_BOARD_PLATFORM)&quot; \\ TARGET_CPU_ABI_LIST=&quot;$(TARGET_CPU_ABI_LIST)&quot; \\ TARGET_CPU_ABI_LIST_32_BIT=&quot;$(TARGET_CPU_ABI_LIST_32_BIT)&quot; \\ TARGET_CPU_ABI_LIST_64_BIT=&quot;$(TARGET_CPU_ABI_LIST_64_BIT)&quot; \\ TARGET_CPU_ABI=&quot;$(TARGET_CPU_ABI)&quot; \\ TARGET_CPU_ABI2=&quot;$(TARGET_CPU_ABI2)&quot; \\ TARGET_AAPT_CHARACTERISTICS=&quot;$(TARGET_AAPT_CHARACTERISTICS)&quot; \\ bash $(BUILDINFO_SH) &gt;&gt; $@ $(hide) $(foreach file,$(system_prop_file), \\ if [ -f &quot;$(file)&quot; ]; then \\ echo &quot;#&quot; &gt;&gt; $@; \\ echo Target buildinfo from: &quot;$(file)&quot;; \\ echo &quot;# from $(file)&quot; &gt;&gt; $@; \\ echo &quot;#&quot; &gt;&gt; $@; \\ cat $(file) &gt;&gt; $@; \\ fi;) &gt;&gt;==$(ADDITIONAL_BUILD_PROPERTIES), \\ $(hide) echo &gt;&gt; $@; \\ echo &quot;#&quot; &gt;&gt; $@; \\ echo &quot;# ADDITIONAL_BUILD_PROPERTIES&quot; &gt;&gt; $@; \\ echo &quot;#&quot; &gt;&gt; $@; ) $(hide) $(foreach line,$(ADDITIONAL_BUILD_PROPERTIES), \\ echo &quot;$(line)&quot; &gt;&gt; $@;) $(hide) build/tools/post_process_props.py $@ $(PRODUCTS.$(INTERNAL_PRODUCT).PRODUCT_SYSTEM_PROPERTY_BLACKLIST)==&lt;&lt;build_desc := 至此，关于PRODUCT_PROPERTY_OVERRIDES相关的内容就解析完毕","link":"/2016/03/29/android-build-system-parse-PRODUCT_PROPERTY_OVERRIDES/"},{"title":"Android编译系统分析之几个关键点（三）","text":"Android 编译系统解析系列文档 编译系统入口envsetup.sh解析 source build/envsetup.sh 做了什么？ 解析lunch的执行过程以及make执行过程中include文件的顺序 Android编译系统分析之lunch分析 Android编译系统分析之make分析 关注一些make执行过程中的几个关键点 Android编译系统分析之几个关键点（一） Android编译系统分析之几个关键点（二） Android编译系统分析之几个关键点（三） 对一些独特的语法结构进行解析 PRODUCT_COPY_FILES语法解析 关于PRODUCT_PROPERTY_OVERRIDES属性的解析 这篇文章的主要内容我们来分析关于模块配置文件Android.mk加载的一些关键的知识点 躲不开的背景知识”mm”与”mmm”在分析模块配置文件Android.mk文件的加载过程之前，我们需要先了解一段背景知识，那就是Android.mk的使用情景是什么样的？ 还记得我们在前边分析lunch的时候提到的源码的全编与模块编译吗？ 控制全编与模块编译的命令就在envsetup.sh文件中定义，其中全编直接运行make，模块单编需要用到mm与mmm两条命令，定义如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455function findmakefile(){ TOPFILE=build/core/envsetup.mk local HERE=$PWD T= while [ \\( ! \\( -f $TOPFILE \\) \\) -a \\( $PWD != &quot;/&quot; \\) ]; do T=`PWD= /bin/pwd` if [ -f &quot;$T/Android.mk&quot; ]; then echo $T/Android.mk \\cd $HERE return fi \\cd .. done \\cd $HERE}function mm(){ local T=$(gettop) local DRV=$(getdriver $T) # If we're sitting in the root of the build tree, just do a # normal make. if [ -f build/core/envsetup.mk -a -f Makefile ]; then $DRV make $@ else # Find the closest Android.mk file. local M=$(findmakefile) local MODULES= local GET_INSTALL_PATH= local ARGS= # Remove the path to top as the makefilepath needs to be relative local M=`echo $M|sed 's:'$T'/::'` if [ ! &quot;$T&quot; ]; then echo &quot;Couldn't locate the top of the tree. Try setting TOP.&quot; elif [ ! &quot;$M&quot; ]; then echo &quot;Couldn't locate a makefile from the current directory.&quot; else for ARG in $@; do case $ARG in GET-INSTALL-PATH) GET_INSTALL_PATH=$ARG;; esac done if [ -n &quot;$GET_INSTALL_PATH&quot; ]; then MODULES= ARGS=GET-INSTALL-PATH else MODULES=all_modules ARGS=$@ fi ONE_SHOT_MAKEFILE=$M $DRV make -C $T -f build/core/main.mk $MODULES $ARGS fi fi} 先看mm命令，如果运行这条命令的路径为TOP目录，那么就等价于直接使用make命令如果不是，我们就以当前目录为基点，递归向上查找距离最近的Android.mk文件，这个查找的过程在findmakefile()函数中定义 Android编译系统在使用mm命令的时候为我们提供了一个参数，可以方便我们打印出所要编译模块的最终安装路径，这个参数就是GET-INSTALL-PATH， 如果编译系统在检查到正在使用mm时加了这个参数，我们就不执行编译的操作，只打印这个参数的值 这个逻辑的实现其实只是将GET-INSTALL-PATH定义为了一个target，我们使用mm时，会将这个target传进去，从而调用到这个target定义的命令，我们后边遇到模块解析代码的时候就会看到这个target相关代码 如果没有这个参数，我们就指定编译全部的模块(all_modules)，然后将mm后边的参数全部作为MAKEGOALS传入 以上就是mm执行的全部过程，有三点需要注意： $DRV，这个变量的作用是加一些静态分析的选项以及路径 ARG参数的添加可以让我们使用-B这样的make自带的参数 ONE_SHOT_MAKEFILE是区别全编与模块编译的关键变量 对于mmm函数，使用方法为直接指定Android.mk所在的文件夹，除此之外最终调用的命令与mm是一样的，有兴趣的读者可以自己来试着解析 了解了使用方法之后，mm在调用的时候会传入ONE_SHOT_MAKEFILE参数，这个参数是区别全编和模块编译的重点，接下来我们来具体看看这个参数带来的实质的影响 模块文件加载解析过程如果读过我之前make解析文章的同学一定还记得include的顺序，没错，Android.mk文件的解析的主要代码是在build/core/main.mk文件中，附代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# Before we go and include all of the module makefiles, stash away# the PRODUCT_* values so that later we can verify they are not modified.stash_product_vars:=trueifeq ($(stash_product_vars),true) $(call stash-product-vars, __STASHED)endififneq ($(ONE_SHOT_MAKEFILE),)# We've probably been invoked by the &quot;mm&quot; shell function# with a subdirectory's makefile.include $(ONE_SHOT_MAKEFILE)# Change CUSTOM_MODULES to include only modules that were# defined by this makefile; this will install all of those# modules as a side-effect. Do this after including ONE_SHOT_MAKEFILE# so that the modules will be installed in the same place they# would have been with a normal make.CUSTOM_MODULES := $(sort $(call get-tagged-modules,$(ALL_MODULE_TAGS)))FULL_BUILD :=# Stub out the notice targets, which probably aren't defined# when using ONE_SHOT_MAKEFILE.NOTICE-HOST-%: ;NOTICE-TARGET-%: ;# A helper goal printing out install paths.PHONY: GET-INSTALL-PATHGET-INSTALL-PATH: @$(foreach m, $(ALL_MODULES), $(if $(ALL_MODULES.$(m).INSTALLED), \\ echo 'INSTALL-PATH: $(m) $(ALL_MODULES.$(m).INSTALLED)';))else # ONE_SHOT_MAKEFILEifneq ($(dont_bother),true)## Include all of the makefiles in the system## Can't use first-makefiles-under here because# --mindepth=2 makes the prunes not work.subdir_makefiles := \\ $(shell build/tools/findleaves.py --prune=$(OUT_DIR) --prune=.repo --prune=.git $(subdirs) Android.mk)$(foreach mk, $(subdir_makefiles), $(info including $(mk) ...)$(eval include $(mk)))endif # dont_botherendif # ONE_SHOT_MAKEFILE# Now with all Android.mks loaded we can do post cleaning steps.include $(BUILD_SYSTEM)/post_clean.mkifeq ($(stash_product_vars),true) $(call assert-product-vars, __STASHED)endif 在真正的调用ONE_SHOT_MAKEFILE变量判断全编还是模块编译之前，我们还有一件事需要做： 暂存PRODUCT_*系列变量(stash-product-vars) 这项操作的用意很明显，我们对于Product级的配置已经结束，接下来加载的模块级别的配置是不能影响干扰到Product的相关配置，所以我们需要暂存变量，来方便后边比对是否修改了这些变量(assert-product-vars) 从这个操作我们也可以看出，Android编译系统对于Product配置在加载模块配置文件Android.mk文件之前就已经结束，从include文件顺序表中我们可以看到也就是在lunch的全部声明周期做完了Product的配置的加载，这里我们之所以不说是完成配置，而是完成加载，是因为对于PRODUCT_COPY_FILES这个变量我们还有操作需要处理，这块内容我们会在后序的文章中说明 接下来我们又遇到一个新的关键字TAG，如果编写过模块代码，那么对这个TAG应该不陌生，常用的定义有user,eng,tests,optional等，你可以指定对应的TAG，使得它在指定的编译类型中生效 这里使用一个get-tagged-modules函数来根据我们当前的编译的varient来挑选出合适的模块加入待编译列表 了解这个函数之前，我们需要知道传入的参数ALL_MODULE_TAGS的作用是什么 我们之前在解析各编译文件的作用时曾经提到过，envsetup.mk的作用主要是定义一些编译系统需要用到的宏，而definitions.mk文件则是用来定义一些公有的函数，这些公有函数主要用在模块编译规则文件Android.mk的编写，所以在遇到ALL_MODULE_TAGS这个变量，我们首先想到的就是去definitions.mk文件中查看，我们发现definitions.mk中定义了ALL_MODULE_TAGS以及操作这个变量的相关函数，但是真正的为这个变量赋值的操作发生在base_rules.mk中，那么这个base_rules.mk与definitions.mk之间是什么关系呢？ 一个Android.mk的示例我们选择一个Android.mk来看看include之后发生了什么示例Android.mk文件内容： 12345678910111213141516LOCAL_PATH:= $(call my-dir)include $(CLEAR_VARS)LOCAL_MODULE_TAGS := optionalLOCAL_SRC_FILES := \\ $(call all-java-files-under, src)LOCAL_PACKAGE_NAME := NfcLOCAL_JNI_SHARED_LIBRARIES := libnfc_mt6605_jni libmtknfc_dynamic_load_jniLOCAL_PROGUARD_ENABLED := disabledinclude $(BUILD_PACKAGE) 以上文件是一个NFC模块的Android.mk文件，我们从前边运行mm的流程可以得知，如果我们在NFC模块规则文件Android.mk文件所在的目录下运行mm，实际执行的操作是找到这个Android.mk文件，并将这个文件赋值给ONE_SHOT_MAKEFILE，然后在main.mk文件中加载进来，也就是我们会在main.mk文件中依次执行以上文件的内容： 使用$(CLEAR_VARS)清零各变量 定义几个以LOCAL_*开头的变量 加载一个对应的编译规则文件$(BUILD_PACKAGE) 我们就以这个文件为例，来解析一下一般Android.mk文件加载的流程：首先$(CLEAR_VARS)对应的是一个makefile文件clear_vars.mk，内容是对各个LOCAL_*变量的清零操作，这个宏的定义是在config.mk文件中，也就是在加载模块规则文件Android.mk文件之前 然后$(BUILD_PACKAGE)也是一个makefile文件package.mk，内容是关于对一个package编译的规则，Android编译系统定义了一系列的宏来将编译各种类型模块的规则打包，我们只需要在每个模块定义的最后引用就可以 了解以上两点，我们就可以使用之前分析make命令运行流程的方法来分析这个示例文件被include到main.mk之后的执行过程，以下是include Android.mk文件之后的include文件顺序： 123456789101112131415161718192021222324252627282930#模块编译时的include顺序,以package.mk为例config.mk ( 62-97: BUILD_SYSTEM_INTERNAL_FILE ( CLEAR_VARS:clear_vars.mk ...... BUILD_STATIC_LIBRARY:static_library.mk BUILD_SHARED_LIBRARY:shared_library.mk BUILD_PACKAGE:package.mk ( 6:include multilib.mk 53:include module_arch_supported.mk 55:include package_internal.mk ( 204:include android_manifest.mk 207:include java.mk ( 307:include base_rules.mk ( 165:include configure_module_stem.mk 688:include $(BUILD_NOTICE_FILE) ) 314:include dex_preopt_odex_install.mk ) 356:include install_jni_libs.mk ( 81:include install_jni_libs_internal.mk ) ) ) BUILD_PHONY_PACKAGE:phone_package.mk ...... BUILD_PREBUILT:prebuilt.mk ...... )) 从以上的include顺序图中，我们可以很清晰的发现base_rulse.mk的身影，这里我们只关心ALL_MODULE_TAGS，所以直接来看base_rules.mk文件中对这个变量的处理： 12345678910111213141516171819202122232425262728my_module_tags := $(LOCAL_MODULE_TAGS)LOCAL_UNINSTALLABLE_MODULE := $(strip $(LOCAL_UNINSTALLABLE_MODULE))my_module_tags := $(sort $(my_module_tags))ifeq (,$(my_module_tags)) my_module_tags := optionalendif# User tags are not allowed anymore. Fail early because it will not be installed# like it used to be.ifneq ($(filter $(my_module_tags),user),) $(warning *** Module name: $(LOCAL_MODULE)) $(warning *** Makefile location: $(LOCAL_MODULE_MAKEFILE)) $(warning * ) $(warning * Module is attempting to use the 'user' tag. This) $(warning * used to cause the module to be installed automatically.) $(warning * Now, the module must be listed in the PRODUCT_PACKAGES) $(warning * section of a product makefile to have it installed.) $(warning * ) $(error user tag detected on module.)endif# Only the tags mentioned in this test are expected to be set by module# makefiles. Anything else is either a typo or a source of unexpected# behaviors.ifneq ($(filter-out debug eng tests optional samples,$(my_module_tags)),)$(warning unusual tags $(my_module_tags) on $(LOCAL_MODULE) at $(LOCAL_PATH))endif 从上到下，依次说明了这几件事： 如果LOCAL_MODULE_TAG未定义，那么默认使用optional user这个TAG已经废弃，如果需要定义这个TAG，可以将其加入到PRODUCT_PACKAGES变量中 TAG只能是debug，eng，tests，optional，samples这几个 我们在这里拿到tag之后，就需要对其进行处理： 12345678910# Keep track of all the tags we've seen.ALL_MODULE_TAGS := $(sort $(ALL_MODULE_TAGS) $(my_module_tags))# Add this module to the tag list of each specified tag.# Don't use &quot;+=&quot;. If the variable hasn't been set with &quot;:=&quot;,# it will default to recursive expansion.$(foreach tag,$(my_module_tags),\\ $(eval ALL_MODULE_TAGS.$(tag) := \\ $(ALL_MODULE_TAGS.$(tag)) \\ $(LOCAL_INSTALLED_MODULE))) 这个示例中Android.mk只定义了一个模块，所以这里的ALL_MODULE_TAGS就是Android.mk定义的LOCAL_MODULTE_TAG，如果是多个模块，这里就是多个模块的综合然后使用不同的TAG后缀，将对应TAG的模块赋值给ALL_MODULE_TAGS.$(tag)，这里模块只有一个，所以其值也是唯一，这样对应TAG的模块我们就可以拿到了 我们回过头继续看CUSTOM_MODULE的值是需要get-tagged-modules取出来的，我们来看这个函数： 123456789101112131415161718192021222324define modules-for-tag-list$(sort $(foreach tag,$(1),$(ALL_MODULE_TAGS.$(tag))))endef# Same as modules-for-tag-list, but operates on# ALL_MODULE_NAME_TAGS.# $(1): tag listdefine module-names-for-tag-list$(sort $(foreach tag,$(1),$(ALL_MODULE_NAME_TAGS.$(tag))))endef# Given an accept and reject list, find the matching# set of targets. If a target has multiple tags and# any of them are rejected, the target is rejected.# Reject overrides accept.# $(1): list of tags to accept# $(2): list of tags to reject#TODO(dbort): do $(if $(strip $(1)),$(1),$(ALL_MODULE_TAGS))#TODO(jbq): as of 20100106 nobody uses the second parameterdefine get-tagged-modules$(filter-out \\ $(call modules-for-tag-list,$(2)), \\ $(call modules-for-tag-list,$(1)))endef get-tagged-modules有两个参数，第一个参数对应的是我们想要取出的模块的tag，第二个参数对应我们不想取出的模块对应的tag，获取CUSTOM_MODULE时，只传入了我们想要取出的模块tag，所以我们我们看到，对于传入的要取出的对应tag的模块，我们只是从ALL_MODULE_TAGS对应tag后缀中取出即可 虽然一个简单的模块编译规则绕了这么一大圈，但是这只是对于单个模块而言，这套模块编译系统的强大之处对于多个模块编译才能真正体现出来，也就是我们进行全编的时候才会见识到它真正的威力 ALL_DEFAULT_INSTALLED_MODULES挑选完模块之后，我们就看到前边解析mm时要到的打印目标模块安装路径的那个target，然后模块的单编也就完成了参数的传入 回过头来我们看看全编过程对Android.mk文件的处理，当include全部的Android.mk之后，我们会发现所有的模块文件都各自被这两条语句包括着： 1234567include $(CLEAR_VARS)......include $(BUILD_PACKAGE) 我们前边已经讲到过CLEAR_VARS就是一个全部LOCAL_*变量的清零操作的mk合集，而BUILD_*这类型的文件定义了各种类型的模块的编译规则 这里还有一个dont_bother的问题，dont_bother的出现，是因为Android编译系统定义了一些特殊的目标，在编译这些目标时，不需要加载Android.mk文件，具体的定义在build/core/main.mk 123456789101112131415# These goals don't need to collect and include Android.mks/CleanSpec.mks# in the source tree.dont_bother_goals := clean clobber dataclean installclean \\ help out \\ snod systemimage-nodeps \\ stnod systemtarball-nodeps \\ userdataimage-nodeps userdatatarball-nodeps \\ cacheimage-nodeps \\ vendorimage-nodeps \\ ramdisk-nodeps \\ bootimage-nodepsifneq ($(filter $(dont_bother_goals), $(MAKECMDGOALS)),)dont_bother := trueendif 包括clean, help, 以及一些image的打包等，这些目标都是独立的，不需要依赖，因此对于代码相关的模块是不需要参与编译的 找到系统所有的Android.mk对于全编过程中所有模块文件的加载我们用到了findleaves.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576import osimport sysdef perform_find(mindepth, prune, dirlist, filename): result = [] pruneleaves = set(map(lambda x: os.path.split(x)[1], prune)) for rootdir in dirlist: rootdepth = rootdir.count(&quot;/&quot;) for root, dirs, files in os.walk(rootdir, followlinks=True): # prune check_prune = False for d in dirs: if d in pruneleaves: check_prune = True break if check_prune: i = 0 while i &lt; len(dirs): if dirs[i] in prune: del dirs[i] else: i += 1 # mindepth if mindepth &gt; 0: depth = 1 + root.count(&quot;/&quot;) - rootdepth if depth &lt; mindepth: continue # match if filename in files: result.append(os.path.join(root, filename)) del dirs[:] return resultdef usage(): sys.stderr.write(&quot;&quot;&quot;Usage: %(progName)s [&lt;options&gt;] &lt;dirlist&gt; &lt;filename&gt;Options: --mindepth=&lt;mindepth&gt; Both behave in the same way as their find(1) equivalents. --prune=&lt;dirname&gt; Avoids returning results from inside any directory called &lt;dirname&gt; (e.g., &quot;*/out/*&quot;). May be used multiple times.&quot;&quot;&quot; % { &quot;progName&quot;: os.path.split(sys.argv[0])[1], }) sys.exit(1)def main(argv): mindepth = -1 prune = [] i=1 while i&lt;len(argv) and len(argv[i])&gt;2 and argv[i][0:2] == &quot;--&quot;: arg = argv[i] if arg.startswith(&quot;--mindepth=&quot;): try: mindepth = int(arg[len(&quot;--mindepth=&quot;):]) except ValueError: usage() elif arg.startswith(&quot;--prune=&quot;): p = arg[len(&quot;--prune=&quot;):] if len(p) == 0: usage() prune.append(p) else: usage() i += 1 if len(argv)-i &lt; 2: # need both &lt;dirlist&gt; and &lt;filename&gt; usage() dirlist = argv[i:-1] filename = argv[-1] results = list(set(perform_find(mindepth, prune, dirlist, filename))) results.sort() for r in results: print rif __name__ == &quot;__main__&quot;: main(sys.argv) 虽然函数内容很少，但是我们可以从中看出一些细节实现，所以我们在这里简单分析一下：首先来看使用方法，就是定义的函数usage()，我们从 Usage: %(progName)s [&lt;options&gt;] &lt;dirlist&gt; &lt;filename&gt; 可以看出函数后加两个可选参数和两个不可省略参数，我们分开来看他们的规则 可选参数 –mindepth：相对于查找目录的最浅深度，如果没有达到，不会查找filename，可以有多个参数，取最后一个定义 –prune：略过查找的目录，可以定义多个目录 不可省略参数 dirlist：要执行查找操作的目录列表，需要有１个或多个参数 filename：参数唯一，需要执行查找的文件名 Android编译系统在这里使用的命令是 build/tools/findleaves.py --prune=$(OUT_DIR) --prune=.repo --prune=.git $(subdirs) Android.mk 也就是排除了out，.repo，.git三个目录，在根目录下查找Android.mk文件 main函数为入口函数，在perform_find函数之前主要是对参数进行处理，将需要排除的目录放入prune数组中，执行实际查找的函数主要在perform_find中，我们来看 def perform_find(mindepth, prune, dirlist, filename): result = [] pruneleaves = set(map(lambda x: os.path.split(x)[1], prune)) for rootdir in dirlist: rootdepth = rootdir.count(&quot;/&quot;) for root, dirs, files in os.walk(rootdir, followlinks=True): # prune check_prune = False for d in dirs: if d in pruneleaves: check_prune = True break if check_prune: i = 0 while i &lt; len(dirs): if dirs[i] in prune: del dirs[i] else: i += 1 # mindepth if mindepth &gt; 0: depth = 1 + root.count(&quot;/&quot;) - rootdepth if depth &lt; mindepth: continue # match if filename in files: result.append(os.path.join(root, filename)) del dirs[:] return result 这个函数主要做了以下几件事： 首先记录了目录深度，用于在后边判断是否达到最浅目录深度(mindepth) 然后遍历传入的目录，也就是源码根目录 检查是否需要在当前目录略过指定的目录（加快搜索速度） 如果检查到需要略过的目录，删掉当前目录下的子目录中所有指定的目录 判断是否达到最浅的搜索深度 如果文件名匹配，将它放到reslut数组中 返回查找到的所有的Android.mk 函数很简单，但是需要注意两点： 如果最小目录深度mindepth没有达到，那么不会匹配当前目录的文件，直到达到目录深度才会执行开始匹配 如果当前文件夹下匹配到了Android.mk，那么就清空子目录列表，也就是停止继续向下查找 以上两点是很重要的，第一点可以让我们可以自由的控制从哪个目录深度开始查找，第二点可以让我们自由的拓展目录的深度与广度，可以自由的控制深度目录下的模块的编译与否，Android编译系统提供了两个函数来搭配这种查找方式all-makefiles-under与first-makefiles-under 一个小插曲脚本解析完了，这里还有一个小插曲说明一下：findleaves.py是一个python脚本，这点我们已经了解，你可能会想到为什么不是一个shell脚本，额，没错，你想的没错，这之前确实是一个bash脚本，09年的８月份被替换掉了，google支持python的时间还真是久远，原因是因为可以大大缩短解析的时间 下边作者当初的提交，让我们来看看来究竟比bash强大在什么地方 作者在提交里说明，使用python重写的原因有两个 可以使用多重prune来排除目录 有效的缩短查找时间 确实，从作者的提交记录来看，从30秒缩减到不到1秒，确实提升很多，我们看到这里已对python顶礼膜拜，敬仰之情滔滔不绝 然并xxx 其实shell脚本该实现的也都已经实现，并且在搜索性能上不仅不差python，还更胜一筹，下图是实际的对比结果 作者当初选择python重写，一者可能是因为喜爱python，另一个原因可能是他根本不会用那个shell脚本…. 好了，小插曲过后，我们回过头来继续研究，我们读了两个脚本之后，也明白了Android.mk文件的搜寻条件，简而言之：从$(subdirs)也就是源码根目录开始搜索，排除.repo，out和.git目录，搜索各个目录下的Android.mk并打印，关于其中的查找规则，前边已经说明，我们不再赘述 结束语至此，关于Android.mk相关的内容也已经解析完毕，对于模块编译的内容的解析可能不是那么深，因为模块编译有单独的一套规则，且相对独立，在一般的系统开发中的出问题的可能性比较小，所以对于这方面待日后遇到问题再来详细补充","link":"/2016/01/08/android-build-systemui-keypoint-third/"},{"title":"一篇写给 Android 刚入门小伙伴的 JSBridge 文章","text":"复杂的程序都需要分层表达 正文这篇文章写给那些经常在 JAVA 层 “扑腾”，几乎没有接触过 H5 相关技术的小伙伴。我会在文章中解释 JSBridge 是什么？JSBridge 的技术定位是什么？理清 JSBridge 出现是要解决什么问题，最后讲一下对于实现 JSBridge 的一些技术方案思考。 整篇文章，不贴过多的代码，只讲清原理和设计思路，因为只有理解了思路，才能更加灵活的做方案取舍。 注：这里的 H5 泛指前端，不仅仅是 HTML5 的含义。 背景在一切开始之前，我们需要先搞明白 JSBridge 在客户端技术栈中所处的位置，有助于对 JSBrige 所能发挥的作用做一个整体的认知，也能从一个客户端技术演进的角度来理解 JSBridge 的重要性。 JSBridge 的思想其实对一直做 Native 的客户端开发者来说，是很陌生的，这是由其客户端的业务属性所决定的，但是只要涉及到一些运营属性，那么接触 JSBridge 就是不可以避免的。所以在这样的业务属性下，客户端的技术演进，肯定都是要经历以下的过程 Native -&gt; Native + H5 -&gt; Native + JSBridge -&gt; Native + RN（Flutter） 各个阶段如下： Native：在客户端初期，人力不足，只使用 Native 的能力实现一些重要的需求 Native + H5：在后续的发展过程中，会使用 H5 简单的处理一些静态的页面，无论是从排版来说，还是从开发成本来说，一些静态页面，例如隐私声明，协议约定等大段落文本，H5 在实时更新和发布成本来说都优于 Native Native + JSBridge：再到后边，整个团队对业务方向的摸索过程中，H5 因为高的更新的频次和可快速迭代发版的特性，会成为整个阶段的技术首选，客户端的角色就是提供对应的基本能力，这个时候就需要有一个成本不高，但是足够用的方案，Native + JSBridge ，易上手，方案简单，且维护成本较低。 Native + RN：但是 JSBridge 的方案太过简单，且性能上不去，而继续往后的客户端发展过程中，必然会对性能，视觉，交互有着更大的要求，原生的 WebView 的方案就会被放弃，那么 Native + RN 的方案就会脱颖而出，这套方案可以支撑更大的业务要求，对性能也提升很大，但是对技术要求和学习成本要求也更多，因为有新的语言要学习，新的框架要接入。 Native + Flutter：如果往更大的开放平台走，类似于支付宝和微信的平台式APP，那么使用 Flutter 这样自带渲染引擎的方案，或者自己开发定制一套方案是更好的选择 注：在方案的选取过程中，其实对于跨平台性也是一个很重要的因素，因为不涉及到方案比较，这里就不过多提及 理解了 JSBridge 在客户端演进过程中的作用后，接下来我们就来解开 JSBridge 的神秘面纱。 JSBridge在了解了 JSBridge 的前后背景，我们从在这节内容开始直面 JSBridge。 这里我们先给 JSBridge 下一个简单的定义，从抽象的层面或者更大的角度来理解 JSBridge 的整个定位，至于对 JSBridge 直观的，可以触摸的理解，你在后边的实现方案中会看到。 JSBridge，简单来说，是一种协议，是一种思想，同时也是一类问题的一个通用解决方案。 JSBridge 是和 DHCP 协议，P2P 协议同样的解决问题的方案。 DHCP 协议用来解决 IP 静态分配导致的效率问题P2P 协议用来解决单一服务器难以承受巨大的带宽压力问题而 JSBridge 协议解决的是 H5 端和 Native 端的通信问题 但是给出 JSBridge 是一种协议这个结论来说未免太过简单抽象了一点，说它可以解决 H5 端和 Native 端通信的问题，许多人估计也是一头雾水，别着急，我们一步步来，先来看一下如果不使用 JSBridge，使用原生提供的解决方案是怎么样的。 原生解决方案Google 在 API level 1 就已经提供了 addJavascriptInterface(Object object, String name) 来作为 JS 访问 Native 代码的入口，原理是：将 Java 对象注入成为 JS 中 window 对象的一个属性，我们都知道 window 对象是浏览器中的顶级对象，名下的属性和方法可以在全局直接引用，所以 Java 对象的方法就被映射到了 window 的一个属性下了。 相应的，在 API level 1 也提供了 loadUrl(String url) 来加载 Url 或者 JS 代码 但是，这两个接口都有各自的问题 addJavascriptInterface(Object object, String name) 在 Android 4.2 之前有安全问题，Google 在 4.2 之后将其限制为加了 @JavascriptInterface 的注解才可以被访问到。 而 loadUrl(String url) 加载 JS，是没有返回值的，对于想要接收 JS 回调的情况来说，只能通过其他方式解决，在 Android4.4 之后，Google 提供了 evaluateJavascript(String script, ValueCallback&lt;String&gt; resultCallback) 方法来加载 JS 方法并且可以接到回调。 但是不管是后续版本新增的接口也好，原有的接口也好，原生提供的方式都有一些很明显的弊端： 高低版本接口不一致，有兼容性要处理 低版本有安全漏洞，方案无法统一 JS 调用 Native 没有回调，接口也不友好 无法实现自由的双端通信 因为以上的弊端，那么急需找出一种可以兼容高低版本，又没有安全漏洞，且实现统一的方案，这就是 JSBridge。 如何实现 JSBridge？终于来到最重要的章节了 双端通信（更像是 C/S 端），其实就是 告诉对方我想要你做什么 想要对方做什么，可以换句话说，想要对方的什么资源，既然请求需要对方的每个资源，那么就需要标明要哪个资源，这种标定对方资源的请求听起来是不是有点耳熟，没错，就是 URI （Uniform Resource Identifier），唯一资源定位符 A Uniform Resource Identifier (URI) is a string of characters that unambiguously identifies a particular resource. To guarantee uniformity, all URIs follow a predefined set of syntax rules, but also maintain extensibility through a separately defined hierarchical naming scheme (e.g. http://).– from Wikipedia 结合到我们的实际场景中来看，JS 端通过 URI 的消息格式从 Native 端获取某些资源，然后返回给 JS 端，这就是 JSBridge 要做的全部的事情。 以上内容，我们再细分为 定义 URI 格式（解决 JS 向 Native 请求数据的问题） 定义回调格式 （解决 Native 向 JS 回传数据的问题） 定义 URI 格式翻译成人话，就是约定 scheme 头部，标明协议类型，比如可以是 bridge约定调用的类名，例如 JSMethod约定调用的本次请求的唯一标识，例如 123（当前生命周期唯一标识即可）约定调用的方法名，例如 getLocationInfo约定调用的参数，例如 realtime=ture 将以上的内容使用 URI 协议拼接起来就是bridge://JSMethod:123/getLocationInfo?realtime=true 定义回调Native 在收到 JS 的请求之后，就需要对这次请求作出响应，提供 JS 端想要的数据，那么对 JS 端来说，我发起的 N 多请求，如何标明 Native 的返回的数据就是对应我刚刚发出的请求呢，我们在之前的 URI 中，针对本次的请求已经设计了一个唯一标识符，那么让 Native 回调时带上这个唯一标识符，JS 就可以和之前的请求一一对应起来了，至于如何回调的问题，我们可以约定一个回调函数 onResponse(int identiy, String jsonData) 将数据放入其中返回既可。 备注：有些人可能直接想到的是 Java 中的 Callback 回调，但是有一点需要明确，Java 中可以使用回调是因为通信的双方都是 jvm 虚拟机可以识别的 object 对象，但是对于 JS 和 Java 这两个通信者来说，就需要找一个双方都可以识别的类型来完成回调类型的定义，对于 Android 的 WebView 内核来说，这个类型就是基本类型 String 字符串。 找到了方法标识想要的资源，那么就剩下解决如何告诉的问题了，在 HTTP 协议中，告知对方使用的是 IP 协议负责定位，TCP/UDP 协议负责传输，但是针对 Android 端与 H5 端的通信，我们互相通信的双方其实就是当前窗口生命周期内的二者，没有第三方，那么我们要做的就是只是找到可以让双方通信的”入口“即可。 通信入口我们先来找 Native 端向 JS 端发送消息的办法，目前通用的解决方案有两种： loadUrl(String url) evaluateJavascript(String script, ValueCallback&lt;String&gt; resultCallback) 这两个方案的利弊和使用限制，我们在上边已经解释过了，这里就不再多说。 接下来就是 JS 端向 Native 端发送消息的办法，目前通用的解决方案有四种：1.可以在 shouldOverrideUrl() 中拦截Url，在 url 中带参数过来，参数预先和 Native 协商好 这是 WebViewClient 的一个可以复写的方法，目的是在当前 WebView 加载 Url 时给应用程序一个控制的机会，控制什么，控制要不要加载这个 url，一般来说页面内部的重定向都会走这个函数，我们可以决定要不要拦截一些跳转，当然，我们也可以和 H5 约定在链接中加入参数来调用 Native 的某些资源 2.也可以在 onJsPrompt()，onJsConfirm()，onJsAlert()，中传入参数过来，同样和 Native 协商好就可以 这三个方法分别对应 JS 中的 window.prompt()，window.confirm()，window.alert()，同样，在 WebViewClient 中可以复写这三个方法接收消息 3.还有第三种方案，使用 onConsoleMessage(ConsoleMessage consoleMessage) 方案这个方法对应 js 中的 console.log()，同样，可以在 WebViewClient 中复写接收消息 4.原生的注入方法，使用 addJavascriptInterface(Object object, String name)，这个方案的利弊也已经在上边解释过了 总结在定义好协议，找到通信入口之后，我们就可以在 JS 中使用定义好的协议请求 Native 的代码了，然后在自定义的回调中获取 Native 回传的内容，这部分内容可以参考 github 中的实现，原理都是相同的。 参考：稍后补上，尽请期待，（ https://github.com/0xforee ） 结尾这一期简单介绍了 JSBridge 的一些实现方案和思路，但是如果要写一个合格稳定可用的 JSBridge 除了要定好协议，基本实现出来，还需要一些额外的调优工作，我们在接下来的一期中继续探索这方面的内容。","link":"/2019/11/11/android-jsbridge/"},{"title":"低电量提醒","text":"概览PowerUI继承于SystemUI，用于电源管理，目前承载了电量提醒和温度提醒的业务内容： 电量提醒目前有三个阶段，android使用了bucket（木桶）的概念，来表示当前处于哪个阶段。当然这三个阶段的具体范围，我们可以自由定制，可以从用户自定义获取（Settings数据库），也可以使用默认的参数（res资源） 确认了这三个阶段之后，在电量变化的时候我们会获取当前电池信息，来判别到达哪个阶段，然后做对应的处理简单来说： 电量低于7，弹对话框警示 电量低于10，弹通知提示（区分正常模式和游戏模式） 当然在实际的过程中，我们还会考虑一些交互细节去做更细致的处理，例如充电过程不提醒，超级省电模式不提醒，插入充电器要取消通知，游戏模式不打扰用吐司替换通知等等，这里不再细讲。 温度提醒很简单，接收触发的广播，弹框通知，OVER 正文UI处理电量处理涉及两个类： 12com.android.systemui.power.PowerUIcom.android.systemui.power.PowerNotificationWarnings#PowerNotificationWarnings 处理UI更新的是com.android.systemui.power.PowerUI.WarningUI只有一个实现类com.android.systemui.power.PowerNotificationWarnings，负责以下功能： 1234567891011public interface WarningsUI { void update(int batteryLevel, int bucket, long screenOffTime); void dismissLowBatteryWarning(); void showLowBatteryWarning(boolean playSound/* flyme extends */, boolean showToast); void dismissInvalidChargerWarning(); void showInvalidChargerWarning(); void updateLowBatteryWarning(); boolean isInvalidChargerWarningShowing(); void dump(PrintWriter pw); void userSwitched();} Bucket接下来我们看一下bucket的概念 android定义了bucket木桶的概念，用来表示当前处于哪个状态，具体定义如下： 12345678910111213141516171819202122232425262728/** * Buckets the battery level. * * The code in this function is a little weird because I couldn't comprehend * the bucket going up when the battery level was going down. --joeo * * 1 means that the battery is &quot;ok&quot; * 0 means that the battery is between &quot;ok&quot; and what we should warn about. * less than 0 means that the battery is low */ private int findBatteryLevelBucket(int level) { if (level &gt;= mLowBatteryAlertCloseLevel) { return 1; } if (level &gt; mLowBatteryReminderLevels[0]) { return 0; } final int N = mLowBatteryReminderLevels.length; // 为啥要倒着循环，-2，,1 // 因为要比较小的话，大范围会包含小范围，所以从小到大确认 // 当电池电量越来越低，木桶也越来越小，不同的电量临界，代表切换不同的木桶，也就是切换模式 for (int i=N-1; i&gt;=0; i--) { if (level &lt;= mLowBatteryReminderLevels[i]) { return -1-i; } } throw new RuntimeException(&quot;not possible!&quot;); } 不同的状态就是我们之前说的不同阶段，其中，这几个阶段Android原生是可以定义的，flyme直接配置了相关的值, 见以下内容 123456789101112int warnLevel = mContext.getResources().getInteger(R.integer.config_mz_lowBatteryWarningLevel) - 1; int critLevel = mContext.getResources().getInteger(R.integer.config_mz_criticalBatteryWarningLevel) - 1; mLowBatteryReminderLevels[0] = warnLevel; mLowBatteryReminderLevels[1] = critLevel; mLowBatteryAlertCloseLevel = mLowBatteryReminderLevels[0] + mContext.getResources().getInteger( com.android.internal.R.integer.config_lowBatteryCloseWarningBump);// 警告电量30-1=29int warnLevel = mContext.getResources().getInteger(R.integer.config_mz_lowBatteryWarningLevel) - 1;// 危险电量10-1=9int critLevel = mContext.getResources().getInteger(R.integer.config_mz_criticalBatteryWarningLevel) - 1; mLowBatteryAlertCloseLevel 表示接近warnLevel，我们将这个阈值在warnLeve基础上提高了5 mLowBatteryReminderLevels[0] ，warnLevel，30-1 = 29 mLowBatteryReminderLevels[1]，critLeve，10-1 = 9 知晓了这几个阈值，对应上边的findBatteryLevelBucket()方法，我们可以发现bucket是用来干嘛的 level &gt;= 35，返回1，表示ok level &gt; 29， 返回0，表示应该警告 level &lt;= 29，返回-1，表示到达低电量 level &lt;= 9，返回-2，表示达到警示电量 弄清楚这几个阶段后就可以去看代码中对应的逻辑处理了。 这里翻译一下最复杂的那个判断条件： 123456789101112131415!plugged&amp;&amp; (!isPowerSaver || bucket &lt; -1)&amp;&amp; !superPowerSaveEnabled&amp;&amp; (bucket &lt; oldBucket || oldPlugged)&amp;&amp; mBatteryStatus != BatteryManager.BATTERY_STATUS_UNKNOWN&amp;&amp; bucket &lt; mNotifyBucket)/*如果当前不在充电状态且 非省电模式或者处于警告电量木桶且 非极限省电模式且 木桶降低或者原来在充电且 电池状态良好且 当前处于警告危险电量*/ 广播信息电量提醒很大一部分内容都是在监听广播获取信息然后触发对应的操作以下是要监听的广播： 12345678910111213141516filter.addAction(Intent.ACTION_BATTERY_CHANGED); // 电量变化广播 filter.addAction(Intent.ACTION_SCREEN_OFF); // filter.addAction(Intent.ACTION_SCREEN_ON); filter.addAction(Intent.ACTION_USER_SWITCHED); filter.addAction(PowerManager.ACTION_POWER_SAVE_MODE_CHANGING); filter.addAction(PowerManager.ACTION_POWER_SAVE_MODE_CHANGED); // Flyme Shi.Yingchun@shell,add for Flyme {@ filter.addAction(Intent.ACTION_POWER_CONNECTED); //archermind:mengxuan.diao[#565728] modified{@ filter.addAction(MZ_ACTION_BATTERY_LOW_WRANING_DIALOG); //@} filter.addAction(Intent.ACTION_BATTERY_OKAY); // @} //Flyme:chenjianbo@SHELL.Feature.UsbChargeTemperatureAlert filter.addAction(mzAlertIntentAction); ACTION_BATTERY_CHANGED，电池信息广播电量变化广播：ACTION_BATTERY_CHANGED = &quot;android.intent.action.BATTERY_CHANGED&quot;这个广播可以附带15个字段，报告当前电池的一些信息，具体请看android.os.BatteryManager，我们只来分析我们用到的这5个 EXTRA_LEVEL：level，电池电量，int值，可取值为从0到EXTRA_SCALE EXTRA_STATUS：status，电池状态，int值，可取值为unknown，charging，discharging，not_charging，full(android.os.BatteryManager#BATTERY_STATUS_UNKNOWN) EXTRA_PLUGGED：plugged，当前使用哪种电源，0电池，1Ac，2USb，3无线 EXTRA_INVALID_CHARGER：invalid_charger，非0值表示不被支持的充电器 EXTRA_SCALE：scale，integer containing the maximum battery level.表示最大电量是多少，和leve的比例作为当前电量的显示接收到这个广播会处理以上状态，然后使用WarningUI来更新UI ACTION_SCREEN_OFF | ACTION_SCREEN_ON，灭屏|亮屏广播记录当前灭屏的时间点，有两个用途 如果灭屏持续时间太长，就不播放声音打扰用户。LOW_BATTERY_SOUND_TIMEOUT记录默认的阈值，超过阈值不打扰用户 如果温控弹框弹出，灭屏会关掉弹框 ACTION_USER_SWITCHED，用户切换广播切换用户，使用WarningUI更新通知 ACTION_POWER_SAVE_MODE_CHANGING | ACTION_POWER_SAVE_MODE_CHANGED 省电模式正在切换|切换完成广播暂未使用 MZ_ACTION_BATTERY_LOW_WRANING_DIALOG，低电量（小于8%）对话框广播电量小于8，会弹出对话框，强打扰模式 ACTION_POWER_CONNECTED，在电源插入的时候触发，只有这种条件会触发播放声音，并关闭低电量对话框 ACTION_BATTERY_OKAY，在进入低电量然后恢复回来的时候发送关闭低电量对话框 mzAlertIntentAction，温控弹框是否到达温控限制，播放alram声音，并弹框 声音PowerUI会在合适的时间播放声音，总有三种类型的声音：LOW_BATTERY_SOUND，PLUDIN_SOUND，CHARGED_SOUND 如果当前状态status为满电，之前非满电，且当前为电源插入状态，播放充满电声音然后更新view的一些参数（View为PowerNotificationWarnings.java）","link":"/2017/08/07/android-powerui/"},{"title":"MeasureSpec 与 LayoutParams 不得不说的二三事","text":"MesureSpec，测量规格 前言MeasureSpec 这个话题往大了说，关系到整个 Android 测量体系的设定，往小了说，只是一个封装了位运算的内部静态类而已。当然我们不会仅仅满足于后者，所以我们就借 MeasureSpec 来简单窥探一下 Android 的测量体系。 正文MeasureSpec，Android 给出的解释是封装了从父视图传递给子视图的布局要求。 A MeasureSpec encapsulates the layout requirements passed from parent to child. 这句话其实已经讲得足够清晰了，但对于从未接触过 MeasureSpec 的初学者来说，还是有点太过简单。 在 Android 的视图系统中，屏幕资源是被整个 View 树一层层消费的，这个 View 树中，往上是父 View，往下是子 View，子 View 的资源都是直接来自父 View，所以在测量的过程中，子 View 并不能不受限制的获取屏幕资源，也要受限于父 View 所给的布局要求，这个要求就是通过 MeasureSpec 这个类来传递的。 先来讲一讲 LayoutParams为什么在这里会讲到 LayoutParams，因为要确定子 View 自身的测量状态，除了知道父 View 的限制之外，还需要知道子 View 自身对尺寸的期望，而 View 自身的期望在代码中就是通过 LayoutParams 来封装的。 所以，可以这么说， LayoutParams 就是影响测量过程另一大因素。 LayoutParams are used by views to tell their parents how they want to be laid out. LayoutParams 是 ViewGroup 的一个内部类，被用于来告诉父视图，子视图想怎么样被布局。另外，每个父视图都有继承 ViewGroup.LayoutParams 自己的内部实现，所以对于不同的布局，我们可使用的 LayoutParams 参数也不一样，这个我们后边会详细说明 我们知道，一般的创建一个 View 有两种方式，一种是通过 Java 的方式 new 一个 View 对象，另一种就是通过 Android 的方式 Inflate 一个 View 对象。这两种方式的差别之处在于，new 一个对象是需要手动设置大量的参数，而 Inflate 一个对象，只需要在 xml 布局文件中写好就OK，系统帮我们做了大量的准备工作而已，效率高了不少。除此之外，其实是没有区别的。 那么在写 xml 布局的时候，会发现每个 View 有两个参数是必不可少的，layout_width 和 layout_height ，对应于 View 的宽和高，这两个 xml 属性，其实对应的就是 LayoutParams 中的 width 和 height 相对应的： margin 相关的参数，可以在 android.view.ViewGroup.MarginLayoutParams 中找到 RelativeLayout 相关的参数，可以在 android.widget.RelativeLayout.LayoutParams 中找到 weight 相关的参数，可以在 android.widget.LinearLayout.LayoutParams 中找到 …… 这里附上一个 Android 中 LayoutParams 的类图，感兴趣的可以详细查询 以上这些内容理解之后就可以解释很多初学者的一些疑惑： 我们将获取到的 LayoutParams 強转为 ViewGroup.LayoutParams 会导致 margin 丢失，是因为 margin 是 ViewGroup.MarginLayoutParams 才有的属性 RelativeLayout 不支持 layout_gravity 的属性，LinearLayout 不支持 alignInParent 的属性，是因为他们互相不关联，相同之处在于只是都是继承自 MarginLayoutParams 我们获取的控件的 LayoutParams 是父视图的 LayoutParams 的内部实现类，而不是子视图自己的，因为设置给子视图的 LayoutParams 是被父视图拿来测量用的，而不是自己使用 注意：因为 padding 是占用 View 内部空间的属性，会干预自身空间内 content 中的显示，并不会影响子 View 在父 view 中所占用的尺寸，所以并没有放在 LayoutParmas 中，而是在给子 View 分配空间，或者绘制自己的 content 的时候才会用到，在后边解析 FrameLayout 的时候也会提到这一点 MeasureSpec 类的解析理解了 LayoutParams 之后，接下来看一下 MeasureSpec 类的具体内容，因为对于后边涉及到的 MeasureSpec 的转换，这里的内容是必不可少的。 按照惯例，我们先来看类的注释 A MeasureSpec encapsulates the layout requirements passed from parent to child. 123456789/** * * Each MeasureSpec represents a requirement for either the width or the height. * A MeasureSpec is comprised of a size and a mode. * * MeasureSpecs are implemented as ints to reduce object allocation. This class * is provided to pack and unpack the &amp;lt;size, mode&amp;gt; tuple into the int. */ A MeasureSpec is comprised of a size and a mode. MeasureSpec 是通过 int 值的位运算来实现的，目的是减少对象的内存分配。将32位 int 值的前两位作为 mode（将 int 值左位运算30位），将后30位作为 size，如下 12345private static final int MODE_SHIFT = 30; private static final int MODE_MASK = 0x3 &lt;&lt; MODE_SHIFT; public static final int UNSPECIFIED = 0 &lt;&lt; MODE_SHIFT; public static final int EXACTLY = 1 &lt;&lt; MODE_SHIFT; public static final int AT_MOST = 2 &lt;&lt; MODE_SHIFT; MeasureSpec 中还带了一些方法，提供 mode 和 size 的打包和解包，方便 MeasureSpec 到 size 和 mode 的互相转换，这里我们不再细说，可以参看 MeasureSpec 的具体内容。 MeasureSpec 模式每个 MeasureSpec 代表一个宽或者高的要求。一个 MeasureSpec 由尺寸 size 和模式 mode 组成。其中 size 表示当前 View 已经确定的尺寸，模式表示要对子 View 限定的模式。 可以这么说，MeasureSpec 主要是对子 View 起作用，如果当前 View 已经是最后一层 View，那么 最后确定的 MeasureSpec 是没有多大意义的 接下来，简单讲一下 MeasureSpec 表示的几种模式 123456789101112131415/** There are three possible modes: * * UNSPECIFIED * The parent has not imposed any constraint on the child. It can be whatever size * it wants. * * EXACTLY * The parent has determined an exact size for the child. The child is going to be * given those bounds regardless of how big it wants to be. * * AT_MOST * The child can be as large as it wants up to the specified size. * * / 我们来看一下有哪些模式 UNSPECIFIED 父 View 没有施加任何限制给子 View，可以是子 View 想要的任何尺寸 EXACTLY 父 View 已经限定了子 View 的精确尺寸，子 View 必须是这个尺寸，无论他自己想要多大的尺寸 AT_MOST 子 View 可以是不超过某个特定的值任意大小 直接看到这些模式可能有点懵，各种要求和被要求，没有关系，我们先对这些模式有个大概的认识，在后续转换的过程中，我们再回来参考就可以 注意：Android 的类的注释往往言简意赅，理解一个类之前，读注释会带来很大的帮助，要养成读类注释的习惯很多人遇到一个函数不理解时，下意识的跑去 Google, Baidu，但其实对于 Android 来说，函数的使用说明都已经放到了源码注释中，直接读注释会比搜索工具来的更快，也更准确。 MeasureSpec 的使用解析能找到这篇文文章并看到这里的童鞋，一定是已经了解过 Android 的整个绘制流程，这里我们简单的提及就可。没有看过的同学，可以通过之前的 invalidate 系列文章 来了解这部分内容 MeasureSpec 的具体含义，我们在前边已经讲过了，接下来进行的 MeasureSpec 的解析，我们需要弄明白两个问题： MeasureSpec 是起始自哪里？ MeasureSpec 是怎么从父 View 传递给子 View 的，这其中做了哪些处理？ 我们先来看第一个问题 MeasureSpec 的起始通过前面的说明我们已经知道，MeasureSpec 是辅助父 View 测量子 View 的一个工具，所以测量过程中子 View 的 MeasureSpec 都是来自于父 View ，父 View 的 MeasureSpec 又来自于父 View 的父 View，那么最开始的 MeasureSpec 是来自哪里的呢，我们接下来就跟着 View 测量的起源来分析一下最开始的 MeasureSpec 12345678910111213# android.view.ViewRootImpl#performTraversals() private void performTraversals() { ....... int childWidthMeasureSpec = getRootMeasureSpec(mWidth, lp.width); int childHeightMeasureSpec = getRootMeasureSpec(mHeight, lp.height); // Ask host how big it wants to be performMeasure(childWidthMeasureSpec, childHeightMeasureSpec); ....... } performTraversals 是每一次屏幕进行测量布局绘制的入口，performMeasure 是真正测量的开始，而在performMeasure 之前的 getRootMeasureSpec 显然就是 MeasureSpec 的起始 12345678910111213141516171819202122232425262728293031323334# android.view.ViewRootImpl#getRootMeasureSpec() /** * Figures out the measure spec for the root view in a window based on it's * layout params. * * @param windowSize * The available width or height of the window * * @param rootDimension * The layout params for one dimension (width or height) of the * window. * * @return The measure spec to use to measure the root view. */ private static int getRootMeasureSpec(int windowSize, int rootDimension) { int measureSpec; switch (rootDimension) { case ViewGroup.LayoutParams.MATCH_PARENT: // Window can't resize. Force root view to be windowSize. measureSpec = MeasureSpec.makeMeasureSpec(windowSize, MeasureSpec.EXACTLY); break; case ViewGroup.LayoutParams.WRAP_CONTENT: // Window can resize. Set max size for root view. measureSpec = MeasureSpec.makeMeasureSpec(windowSize, MeasureSpec.AT_MOST); break; default: // Window wants to be an exact size. Force root view to be that size. measureSpec = MeasureSpec.makeMeasureSpec(rootDimension, MeasureSpec.EXACTLY); break; } return measureSpec; } 传入的参数有两个：第一个是 Window 的尺寸，每个 View 都会依附一个 Window 存在，所以 Window 大小直接会影响 Window 内的 View 测量。第二个是 View期望的大小，也就是我们设置的 LayoutParams 中的 width 或 height，在 Window 的 addView 中会传入，如果不传入会获得一个默认值 我们来看一下转换规则 MATCH_PARENT，如果子 View 期望和父 View 一样大，当前 Window 的尺寸已经确定了，那么也就可以说子 View 的尺寸精确了，所以构建一个 MeasureSpec 传给子 View，标识自己的尺寸和模式，尺寸就是 Window 的尺寸，模式就是精确模式 WRAP_CONTENT，如果子 View 期望自己的大小包裹内容就OK，那么父 View 表示没啥问题，只要这个大小不超过我的大小就OK，所以构建一个 MeasureSpec，大小为 Window 尺寸，模式表示最大模式，也就是最大不超过 Window 尺寸 其他，这个其他其实也就是固定的尺寸，也就是子 View 期望自己决定自己的尺寸，父 View 表示OK，给你期望的精确的尺寸，构建一个 MeasureSpec，大小为子 View 想要的尺寸，模式为精确 经过以上解析，相信大家对 MeasureSpec 是经由父 View 和子 View 共同决定然后传递到子 View 有了更深的认识 这个最初构建的 MeasureSpec 会从 View 树的顶端，经过每一个子节点的共同结果，继续向下传递，直到到达叶子节点，这样一轮遍历过后，每个 View 都拿到了属于自己的最终的 MeasureSpec，也就相当于确定了自己的最后的尺寸 因为 MeasureSpec 是由父 View 和子 View 共同决定的，所以是在 ViewGroup，而不是 View 中存在 Measurespec的转换过程 所以我们就以一个 ViewGroup 的视角来看 ViewGoup 与 View 之间的转换过程 但是所有的 View 包括 ViewGroup 都是继承自 View 这个类，需要覆写 onMeasureSpec 来实现自己的测量方法，而 ViewGroup 没有实现自己的 onMeasure 方法，所以无法看到 ViewGroup 这一类父控件在测量过程中对子 View 施加的测量工作，所以我们选一个常见的 FrameLayout 来解析 FrameLayout 的测量转换我们就以 FrameLayout 作为示例，来分析一下 ViewGroup 和 View 之间的转换规则 FrameLayout 的测量12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970# android.widget.FrameLayout#onMeasure() @Override protected void onMeasure(int widthMeasureSpec, int heightMeasureSpec) { // 第一部分 int count = getChildCount(); final boolean measureMatchParentChildren = MeasureSpec.getMode(widthMeasureSpec) != MeasureSpec.EXACTLY || MeasureSpec.getMode(heightMeasureSpec) != MeasureSpec.EXACTLY; mMatchParentChildren.clear(); for (int i = 0; i &lt; count; i++) { final View child = getChildAt(i); if (mMeasureAllChildren || child.getVisibility() != GONE) { measureChildWithMargins(child, widthMeasureSpec, 0, heightMeasureSpec, 0); final LayoutParams lp = (LayoutParams) child.getLayoutParams(); maxWidth = Math.max(maxWidth, child.getMeasuredWidth() + lp.leftMargin + lp.rightMargin); maxHeight = Math.max(maxHeight, child.getMeasuredHeight() + lp.topMargin + lp.bottomMargin); childState = combineMeasuredStates(childState, child.getMeasuredState()); if (measureMatchParentChildren) { if (lp.width == LayoutParams.MATCH_PARENT || lp.height == LayoutParams.MATCH_PARENT) { mMatchParentChildren.add(child); } } } } ......// 第二部分 setMeasuredDimension(resolveSizeAndState(maxWidth, widthMeasureSpec, childState), resolveSizeAndState(maxHeight, heightMeasureSpec, childState &lt;&lt; MEASURED_HEIGHT_STATE_SHIFT)); // 第三部分 count = mMatchParentChildren.size(); if (count &gt; 1) { for (int i = 0; i &lt; count; i++) { final View child = mMatchParentChildren.get(i); final MarginLayoutParams lp = (MarginLayoutParams) child.getLayoutParams(); final int childWidthMeasureSpec; if (lp.width == LayoutParams.MATCH_PARENT) { final int width = Math.max(0, getMeasuredWidth() - getPaddingLeftWithForeground() - getPaddingRightWithForeground() - lp.leftMargin - lp.rightMargin); childWidthMeasureSpec = MeasureSpec.makeMeasureSpec( width, MeasureSpec.EXACTLY); } else { childWidthMeasureSpec = getChildMeasureSpec(widthMeasureSpec, getPaddingLeftWithForeground() + getPaddingRightWithForeground() + lp.leftMargin + lp.rightMargin, lp.width); final int childHeightMeasureSpec; if (lp.height == LayoutParams.MATCH_PARENT) { final int height = Math.max(0, getMeasuredHeight() - getPaddingTopWithForeground() - getPaddingBottomWithForeground() - lp.topMargin - lp.bottomMargin); childHeightMeasureSpec = MeasureSpec.makeMeasureSpec( height, MeasureSpec.EXACTLY); } else { childHeightMeasureSpec = getChildMeasureSpec(heightMeasureSpec, getPaddingTopWithForeground() + getPaddingBottomWithForeground() + lp.topMargin + lp.bottomMargin, lp.height); } child.measure(childWidthMeasureSpec, childHeightMeasureSpec); } } } 我们来看 FrameLayout 的主流程的代码其中分三个部分： 第一部分按照正常流程，遍历测量所有子 View 的大小 第二部分设定 FrameLayout 的宽高，这里需要区分两点，如果 FrameLayout 要 MATCH_PARENT，其实高度在父 View 中计算 MeasureSpec 就已经可以确定下来了，如果 FrameLayout 要 WRAP_CONTENT，那么顾名思义，需要根据测量的子 View 的宽高来计算 第三部分第三部分的测量有个条件 123final boolean measureMatchParentChildren = MeasureSpec.getMode(widthMeasureSpec) != MeasureSpec.EXACTLY || MeasureSpec.getMode(heightMeasureSpec) != MeasureSpec.EXACTLY; 这个其实表示，父 View 限定给当前 View 的测量模式是 AT_MOST，（至于为什么是 AT_MOST，在文章最后的表中可以推算出来），那么表示当前父 View 的高度是没有确定的，需要先测量子 View 的宽高之后才能知道自己的宽高，那么对于那些想要 MATCH_PARENT 的子View来说，只有父 View 宽高确定，才能知道自己的宽高，所以在第二部分设定完成 FrameLayou t的宽高之后，这里需要对这些 MATCH_PARENT 的子 View 再来测量一遍 三个部分中，其实第一部分是我们所关心的，所以我们着重来看一下第一部分 测量模式转换递归测量子view，需要考虑 Margin 的影响，因为 Margin 是 View 之间的间隔，不包含在 View 的宽高内 1234567891011121314# android.view.ViewGroup#measureChildWithMargins() protected void measureChildWithMargins(View child, int parentWidthMeasureSpec, int widthUsed, int parentHeightMeasureSpec, int heightUsed) { final MarginLayoutParams lp = (MarginLayoutParams) child.getLayoutParams(); final int childWidthMeasureSpec = getChildMeasureSpec(parentWidthMeasureSpec, mPaddingLeft + mPaddingRight + lp.leftMargin + lp.rightMargin + widthUsed, lp.width); final int childHeightMeasureSpec = getChildMeasureSpec(parentHeightMeasureSpec, mPaddingTop + mPaddingBottom + lp.topMargin + lp.bottomMargin + heightUsed, lp.height); child.measure(childWidthMeasureSpec, childHeightMeasureSpec); } 这里有个 widthUsed 和 heightUsed，分别表示宽度和高度上已经被消费的大小。因为父 View 可能存在多个子 View，所以分析当前 View 可使用的父 View 空间时，要去掉已经分配给其他子 View 的空间。 比如 LinearLayout 水平布局时，从左到右测量时，这个已经被使用的宽度会越来越小，而对于 FrameLayout 的覆盖式布局传入的都是0 这个函数会先根据父View的 MeasureSpec 和 LayoutParams 转换为子 View 的 LayoutParams，然后交给子View 的 measure 方法继续往下测量。 我们来看具体的转换细节 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889# android.view.ViewGroup#getChildMeasureSpec() /** * Does the hard part of measureChildren: figuring out the MeasureSpec to * pass to a particular child. This method figures out the right MeasureSpec * for one dimension (height or width) of one child view. * * The goal is to combine information from our MeasureSpec with the * LayoutParams of the child to get the best possible results. For example, * if the this view knows its size (because its MeasureSpec has a mode of * EXACTLY), and the child has indicated in its LayoutParams that it wants * to be the same size as the parent, the parent should ask the child to * layout given an exact size. * * @param spec The requirements for this view * @param padding The padding of this view for the current dimension and * margins, if applicable * @param childDimension How big the child wants to be in the current * dimension * @return a MeasureSpec integer for the child */ public static int getChildMeasureSpec(int spec, int padding, int childDimension) { int specMode = MeasureSpec.getMode(spec); int specSize = MeasureSpec.getSize(spec); int size = Math.max(0, specSize - padding); int resultSize = 0; int resultMode = 0; switch (specMode) { // Parent has imposed an exact size on us case MeasureSpec.EXACTLY: if (childDimension &gt;= 0) { resultSize = childDimension; resultMode = MeasureSpec.EXACTLY; } else if (childDimension == LayoutParams.MATCH_PARENT) { // Child wants to be our size. So be it. resultSize = size; resultMode = MeasureSpec.EXACTLY; } else if (childDimension == LayoutParams.WRAP_CONTENT) { // Child wants to determine its own size. It can't be // bigger than us. resultSize = size; resultMode = MeasureSpec.AT_MOST; } break; // Parent has imposed a maximum size on us case MeasureSpec.AT_MOST: if (childDimension &gt;= 0) { // Child wants a specific size... so be it resultSize = childDimension; resultMode = MeasureSpec.EXACTLY; } else if (childDimension == LayoutParams.MATCH_PARENT) { // Child wants to be our size, but our size is not fixed. // Constrain child to not be bigger than us. resultSize = size; resultMode = MeasureSpec.AT_MOST; } else if (childDimension == LayoutParams.WRAP_CONTENT) { // Child wants to determine its own size. It can't be // bigger than us. resultSize = size; resultMode = MeasureSpec.AT_MOST; } break; // Parent asked to see how big we want to be case MeasureSpec.UNSPECIFIED: if (childDimension &gt;= 0) { // Child wants a specific size... let him have it resultSize = childDimension; resultMode = MeasureSpec.EXACTLY; } else if (childDimension == LayoutParams.MATCH_PARENT) { // Child wants to be our size... find out how big it should // be resultSize = View.sUseZeroUnspecifiedMeasureSpec ? 0 : size; resultMode = MeasureSpec.UNSPECIFIED; } else if (childDimension == LayoutParams.WRAP_CONTENT) { // Child wants to determine its own size.... find out how // big it should be resultSize = View.sUseZeroUnspecifiedMeasureSpec ? 0 : size; resultMode = MeasureSpec.UNSPECIFIED; } break; } //noinspection ResourceType return MeasureSpec.makeMeasureSpec(resultSize, resultMode); } 以上就是转换规则，每个分支都有详细注释，我们不再赘述，将以上的代码转换为表格的形式给出 子LayoutParams\\父MeasureSpec UNSPECIFIED#0 AT_MOST#parentSize EXACTLY#parentSize MATCH_PARENT UNSPECIFIED#0（子View想要和父View一样大，那么找出来具体多大） AT_MOST#parentSize（子view表示想和父View一样大，父View不固定，只能限制子View不要超过这个尺寸） EXACTLY#parentSize（子view想要和父View一样大，父view已经确定了，那么子view就是父view大小了） WRAP_CONTENT UNSPECIFIED#0（子view想要自己决定，那么找出来具体多大 ） AT_MOST#parentSize（子View表示自己决定大小，父View表示不超过我就OK） AT_MOST#parentSize（子View表示要自己决定，父view表示，只要不超过我的自身值就OK） 固定值大小 EXACTLY#childSize（子view表明自己的大小，父view表示你开心就好） EXACTLY#childSize（子view表明自己的大小，父View表示你开心就好） EXACTLY#childSize（子view明确表示了自己的期望值，那么子View你开心就好） 注： # 用来分割 mode 和 size 其中 parentSize 就是 specSize，也就是父 View 的尺寸大小，或者准确来说，是限定父 View 的最大尺寸。因为对于 EXACTLY 来说，父 View 大小是可以确定的，而对于 AT_MOST 来说，还需要测量子 View 的大小，所以这里是最大尺寸 其中 childSize 就是 childDimens 对于上述的表格，其实也不是很直观，只是将代码的转换算法用表格的方式整理出来了。 我们来尝试用另一个角度的方式理解这个表格 UNSPECIFIED 、AT_MOST、EXACTLY 其实代表着测量的三个状态 UNSPECIFIED表示是未执行测量，一切都是初始化的状态 AT_MOST表示当前View的尺寸不确定，需要经过测量子View才能决定 EXACTLY表示当前View的尺寸不需要经过测量子View就已经决定好了 基于以上的理论，我们来重新解析刚刚的表格（横向为ABC，竖向为123） 子View 如果是固定尺寸（A3，B3，C3）：这个很好理解，直接就可以确定大小 父View 是UNSPECIFIED（A1，A2）：这一列也很好理解，都是未初始化 父View 是 AT_MOST（B1，B2）：也即父View没有确定高度，那么子View都无法确认高度，也即必须要先行测量 父View是EXACTLY（C1，C2）：子View想要适应自己大小，那么其实就必须先经过测量 后记我将这篇文章中讲到的一些关键知识点罗列如下，可以查看是否真的理解了这些内容 子 View 提供给父 View 的 LayoutParams 是用来表示子 View 自身的期望大小 每个 View 都有自己的 MeasureSpec 来代表自己测量后的状态 每个 View 的 MeasureSpec 都是由父 View 的 Measure 和自身 LayoutParams 共同确定的 View 树的测量是深度优先 每个 View 都是先确定测量模式，然后再去根据测量模式实际测量 搞明白了MeasureSpec和LayoutParams相关的内容，对于理解 Android 的测量体系，以及自定义View的测量过程，或者灵活使用View的测量结果都有很大的帮助，另外在对于布局过程中出现的一些异常布局，也能通过快速查看源码定位问题，是作为高级工程师必不可少的一项技能。","link":"/2019/07/01/android-measurespec-layoutparams/"},{"title":"快捷开关之移动数据","text":"概览移动数据开关作为快捷开关的三大金刚之一，重要性不言而喻。作为日常高频使用的开关之一，承载了及其重要的功能。在Flyme6之前，4G还未普及，流量金贵，所以切换菜单中加入了2G，3G，4G的功能，而在Flyme7的过渡中，双卡用户增加，所以将切换菜单中网络模式切换更换为主副卡切换功能。后续跟随用户反馈，可能会将这两个功能同时加入 背景知识一些需要知道的基础知识 mSubscriptionManager.getActiveSubscriptionInfoCount()指所有插入的卡，包含当前禁用的SIM卡，当前禁用的卡使用isRadioOn()来判断 mTelephonyManager.getSimCount()判断是判断当前手机是单卡还是双卡手机，而不是判断当前插入SIM卡的数量 mTelephonyManager.getSimState() == SIM_STATE_READY这个状态获取的是先识别到的那张卡，一般是卡1，所以需要改用mTelephonyManager.getSimState(int slotId)这个接口分别获取两张卡的状态 phoneId，slotId，这两个类似，对应卡槽1，卡槽2，值为0和1 subId，对应SIM卡，从0开始递增，每次插入一张新的SiM卡subid都会+1 卡的名称需要获取卡的subid之后自己去取名称 123456/** * @return the name displayed to the user that identifies this subscription */ public CharSequence getDisplayName() { return this.mDisplayName; } 软卡就是软件模拟的一个卡，跟真正插卡一样的软卡也会占用一个实体卡槽，启用软卡的卡槽在插卡就没有用了 正文开关移动数据点击设置android自身提供了接口操作移动数据 1234567891011121314151617/** * Turns mobile data on or off. * If this object has been created with {@link #createForSubscriptionId}, applies to the given * subId. Otherwise, applies to {@link SubscriptionManager#getDefaultDataSubscriptionId()} * * &lt;p&gt;Requires Permission: * {@link android.Manifest.permission#MODIFY_PHONE_STATE MODIFY_PHONE_STATE} or that the * calling app has carrier privileges. * * @param enable Whether to enable mobile data. * * @see #hasCarrierPrivileges */ @RequiresPermission(android.Manifest.permission.MODIFY_PHONE_STATE) public void setDataEnabled(boolean enable) { setDataEnabled(getDefaultDataSubscriptionId(), enable); } 响应也有对应的获取移动数据状态接口，但是比较耗时，所以Flyme使用监听数据库字段的方式来响应移动数据的变化，监听路径区分单双卡手机 单卡：Uri mobileDataUri = Settings.Global.getUriFor(Settings.Global.MOBILE_DATA); 双卡：Uri mobileDataUri = Settings.Global.getUriFor(Settings.Global.MOBILE_DATA + mDefaultDataSubscriptionId) 双卡手机的监听会涉及到defaultDataSubscriptionId的合法性，在开机或插拔SIM卡时，如果SIM卡状态没有及时准备好，获取的defaultDataSubscriptionId可能是非法的，所以需要监听ACTION_SIM_STATE_CHANGED来多次获取确保注册的数据库路径是正确的 切换卡切换设置 设置主卡：SubscriptionManager.setDefaultDataSubId() 获取主卡状态：SubscriptionManager.getDefaultDataSubscriptionId() 可以获取数据卡的subid 切换卡的业务比较复杂，需要管理的细节也比较多，我们来通过UI状态来划分这些细节UI状态，有两种：一种是整个VIew置灰，不响应用户操作，还有一种隐藏dual图标，不响应用户切换卡，我们接下来从这两个状态细说 View置灰由当前是否可以开关移动数据和底层的CallBackInfo状态决定 12final boolean enabled = mDataController.isMobileDataSupported() &amp;&amp; !cb.noSim &amp;&amp; !cb.airplaneModeEnabled &amp;&amp; cb.enabled; 隐藏Dual图标是否隐藏由3个情况判断 1234@Override public boolean supportsDualTargets() { return mDataController.canConfigSubId() &amp;&amp; mDataController.isMobileDataEnabled() &amp;&amp; mDataController.isDualEnabled(); } 移动数据开启mDataController.isMobileDataEnabled()：只有移动数据开启才支持双卡切换 硬件（或编译）是否支持双卡mDataController.canConfigSubId()：支持双卡手机、非移动入库定制版 根据当前状态动态判断是否支持双卡mDataController.isDualEnabled()： 当前插入卡数量（可能为空） 当前是否双卡都启用（可在设置中禁用启用） 是否正在通话（通话过程禁止切换卡） 是否启用软卡（阮卡默认为主卡，且不支持切换） 是否正在切换卡 状态获取以上两个节讲完了切换卡可能的UI状态以及决定状态的判断条件，下面来分析一下这些状态该从哪里获取 所有的这些状态我们主要通过广播来决定刷新的时机 双卡状态刷新时机 ACTION_SIM_STATE_CHANGED，用于监听SIM的状态变化，相当于硬件设备在开机过程中从准备到完成的状态，无法跟踪主卡的状态 ACTION_DEFAULT_DATA_SUBSCRIPTION_CHANGED，监听这个广播， 在数据卡（也即主卡）变化时可以获取通知，这个时候就可以更新主卡ID 注：数据库中有个Uri与这个广播是一样的功能：Settings.Global.MULTI_SIM_DATA_CALL_SUBSCRIPTION ACTION_SERVICE_STATE_CHANGED，监听当前服务状态，是否驻网脱网 ACTION_SUBINFO_RECORD_UPDATED，可以用于监听双卡启用停用 切换卡状态刷新时机 ACTION_MAIN_SLOT_CHANGED(高通，samsung) | ACTION_SET_RADIO_CAPABILITY_DONE（mtk），用于监听双卡切换完毕 注：ACTION_SET_RADIO_CAPABILITY_DONE是google字段，所以三个平台都有，MAIN_SLOT可能会有平台缺少的问题 电话状态刷新时机 ACTION_PHONE_STATE_CHANGED，用于电话状态变化的广播，只有在第一次来电话之后才会触发，注意初始化值 网络制式发生变化时机（目前暂未用到） ACTION_RADIO_TECHNOLOGY_CHANGED 与 ACTION_RAT_CHANGED：用于radio的类型变化 When the radio changes (ex: CDMA-&gt;GSM), refresh all options. 切换网络模式当前已经去除，后续可能增加 注意事项 解完BUG之后，记得判断处理默认状态，一定要重启去check状态是否异常 1234//FLYME:wanglong@CommSrv.Telephony.Bugfix#481606 {@ int SimMode = Settings.Global.getInt(mContext.getContentResolver(), Settings.Global.MSIM_MODE_SETTING, -1); //@} 这段代码中，MSIM_MODE_SETTINGS中，MTK在Global数据库里，三星和高通在System数据库里，使用的时候注意区分在AndroidL中，MTK也位于System数据库","link":"/2017/03/05/android-quicksettings-mobiledata/"},{"title":"快捷开关之无线网路","text":"概述无线网络作为快捷开关三大金刚之一，重要性不言而喻。为用户提供开关wifi以及切换wifi的功能。无线网络虽然只是作为一个入口，和设置中无线网络页面扮演着相同的角色，但是因为可随时访问的特性，会比设置无线网络有着更多的用户场景，实时性，交互性，稳定性都有着更高的要求。 从以上的UML类图中我们初步分析一下无线网络开关相关的模块结构： 从View的方面来说 与所有的快捷开关一致，WifiTile是无线网络开关的View层，继承自QSTile（顶部3个方法为开关必须要实现的基本功能，其他方法根据需要可选择实现，比如有些开关没有长按功能就不需要实现handleLongClick()） 除此之外还有下拉菜单功能，这部分是由接口DetailAdapter来规范的，如果要使用下拉菜单，需要自行实现以上接口，并在QSTile中的getDetailAdapter()方法中返回实例 从Controller的方面来说 NetworkController，用于开关WIFI和获取WIFI的状态变化信息，是快捷开关的基本功能 AccessPointController，用于发起扫描WIFI和获取扫描之后的WIFI列表，用于下拉菜单的展示 以上就是整个无线网络开关的模块相关结构了，重要的细节我们稍后讨论 正文开关无线网络开关网络在点击开关或者点开下拉菜单的时候，会操作网络状态，Android提供了接口操作wifi开关，因为WIFI与移动热点相关连，所以这里加入了移动热点的相关判断 1234567891011121314151617181920// com.android.systemui.statusbar.policy.NetworkControllerImpl#setWifiEnabled@Override public void setWifiEnabled(final boolean enabled) { new AsyncTask&lt;Void, Void, Void&gt;() { @Override protected Void doInBackground(Void... args) { // Disable tethering if enabling Wifi final int wifiApState = mWifiManager.getWifiApState(); if(DEBUG) Log.d(TAG, &quot;doInBackground: enabled = &quot; + enabled + &quot; wifiApState = &quot; + wifiApState); if (enabled &amp;&amp; ((wifiApState == WifiManager.WIFI_AP_STATE_ENABLING) || (wifiApState == WifiManager.WIFI_AP_STATE_ENABLED))) { mWifiManager.setWifiApEnabled(null, false); } mWifiManager.setWifiEnabled(enabled); return null; } }.execute(); } 响应状态wifi的状态响应是通过SignalCallback回调传过来的数据响应，而这个回调在NetworkController的实现类中统一通过广播处理，这个实现类除了处理wifi的信号和状态变化，还会处理移动数据的状态变化，用于更新状态栏信号，通知栏头部的运营商名称等信息，这个模块的结构我们在另一篇文章中（TODO）解析，这里我们只需要知晓状态响应的来源位置就好 开关的状态会通过handleUpdateState()方法更新，然后交由父类统一处理，这块逻辑我们会在另一篇文章中（TODO）解析，这里我们只需要在handleUpdateState()中更新正确的状态即可 切换无线网络无线网络的切换操作方式是点击开关下拉菜单，然后点击需要切换的网络，展示是在WifiTile这个View中，而数据来源是AccessPointController，对应的实现类AccessPointControllerImpl。 切换网络通过以下方法切换： 12345678910111213141516171819202122232425262728293031public boolean connect(AccessPoint ap) { if (ap == null) return false; if (ap.isFreeWifi()) { if (WifiUtils.isFreeWifiOnceConnected(mContext)) { mWifiTracker.connect(ap); } Log.d(TAG, &quot;connect: free wifi ssid = &quot; + ap.getSsidStr() + &quot; bssid = &quot; + ap.getBssid()); Intent intent = new Intent(MZ_ACTION_FREE_WIFI_ACTIVITY); Bundle args = ap.getFreeWifiApInfo().getBundle(ap); intent.putExtra(EXTRA_FREE_WIFI_BUNDLE, args); fireSettingsIntentCallback(intent); return true; } else if (ap.isSaved()) { if (DEBUG) Log.d(TAG, &quot;connect networkId=&quot; + ap.getConfig().networkId); mWifiTracker.getManager().connect(ap.getConfig().networkId, mConnectListener); } else { // Unknown network, need to add it. if (ap.getSecurity() != AccessPoint.SECURITY_NONE) { Intent intent = new Intent(/*Settings.ACTION_WIFI_SETTINGS*/MZ_ACTION_PICK_WIFI_NETWORK); intent.putExtra(EXTRA_START_CONNECT_SSID, ap.getSsidStr()); intent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK); fireSettingsIntentCallback(intent); return true; } else { ap.generateOpenNetworkConfig(); mWifiTracker.getManager().connect(ap.getConfig(), mConnectListener); } } return false; } 需要注意的是： 对于已经保存的网络或者开放网络，可以直接通过android.net.wifi.WifiManager#connect(android.net.wifi.WifiConfiguration, android.net.wifi.WifiManager.ActionListener)连接 而对于免费WIFI和加密WIFI，需要跳转到设置页面进行相应的处理，免费wifi需要设置认证，而加密wifi需要在设置输入密码 响应刷新状态响应比较简单，SettingsLib会通过WifiListening这个接口来通知下拉菜单的wifi热点的变化，另外这个回调会在下拉菜单展开时注册，收起时取消注册","link":"/2017/04/14/android-quicksettings-wifi/"},{"title":"触摸事件分析","text":"概述初始化每一个事件流，都是以ACTION_DOWN作为开始，以ACTION_UP或ACTION_CANCEL作为结束在处理开始前，需要做一个安全处理，即是否有不可见的window覆盖其上，防止有恶意软件劫持用户输入事件 如果是DOWN事件，那么表示要开始一个新的事件流，这时就需要清理原来的状态，重新开始 拦截接来下检查父View是否会拦截事件，如果父View希望拦截，也就是在onInterceptTouchEvent()中返回true ，那么后续将不再寻找有意愿接收事件的子View，而是将事件直接发给父View的onTouchEvent来处理 比如说，长按列表中某个项，子View会处理长按事件，长按然后开始滑动，父View会接管滑动事件，列表就开始滑动，同时子View就恢复状态。这个逻辑就是通过事件拦截实现的。 请求不拦截当然，子View也可以要求父View不要拦截这个事件 比如说，长按列表中某个项，然后上下拖动，改变子View的顺序，这个逻辑就需要子View告知父View不要拦截处理，交给我就可以了 子View是通过requestDisallowInterceptTouchEvent()方法来请求父View不要拦截事件 然后查看这个事件是否是取消事件，取消事件的话也不会去找VIew分发了，因为这是一个结束事件，所以要通知之前分发过的view，事件已经被其他View接管 查找想要接管的View只有事件即没有被拦截，也不是取消事件，才会找新的view接管遍历自己的view树，然后找愿意接管事件的view，（从最接近用户的那个view开始），找到之后，标记这个view为target，接下来的事件就不在找了，直接转发给这个view，这是正常的事件流 被拦截或者是取消事件那么对于拦截或者取消的情况呢：如果在这之前还没有找过view接管，那么直接传给当前view处理如果曾找过view接管，对于拦截事件，分发给子view事件被取消了，方便子view做后续处理对于取消事件，要分发给子view，告诉事件取消 简化模型以上事件的分发过程，可以使用下边的简化模型来理解 1234567891011public boolean disaptchTouchEvent(MotionEvent ev){ boolean handled = false; if (onInterceptTouchEvent(ev)) { handled = onTouchEvent(ev); }else{ handled = child.dispatchTouchEvent(ev); } return handled;} 流程分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216@Overridepublic boolean dispatchTouchEvent(MotionEvent ev) { if (mInputEventConsistencyVerifier != null) { mInputEventConsistencyVerifier.onTouchEvent(ev, 1); } // If the event targets the accessibility focused view and this is it, start // normal event dispatch. Maybe a descendant is what will handle the click. if (ev.isTargetAccessibilityFocus() &amp;&amp; isAccessibilityFocusedViewOrHost()) { ev.setTargetAccessibilityFocus(false); } boolean handled = false; if (onFilterTouchEventForSecurity(ev)) { //安全检查，防止被其他窗口劫持 final int action = ev.getAction(); final int actionMasked = action &amp; MotionEvent.ACTION_MASK; // Handle an initial down. if (actionMasked == MotionEvent.ACTION_DOWN) { // down事件为事件流开始事件，清除状态 // Throw away all previous state when starting a new touch gesture. // The framework may have dropped the up or cancel event for the previous gesture // due to an app switch, ANR, or some other state change. cancelAndClearTouchTargets(ev); resetTouchState(); } // Check for interception. final boolean intercepted; if (actionMasked == MotionEvent.ACTION_DOWN || mFirstTouchTarget != null) {// 事件流开始或者已经找到要分发的view final boolean disallowIntercept = (mGroupFlags &amp; FLAG_DISALLOW_INTERCEPT) != 0; if (!disallowIntercept) { // 是否允许父view拦截 intercepted = onInterceptTouchEvent(ev); // 父View是否拦截 ev.setAction(action); // restore action in case it was changed } else { intercepted = false; } } else { // There are no touch targets and this action is not an initial down // so this view group continues to intercept touches. intercepted = true; } // If intercepted, start normal event dispatch. Also if there is already // a view that is handling the gesture, do normal event dispatch. if (intercepted || mFirstTouchTarget != null) { ev.setTargetAccessibilityFocus(false); } // Check for cancelation. final boolean canceled = resetCancelNextUpFlag(this) // 是否是取消事件 || actionMasked == MotionEvent.ACTION_CANCEL; // Update list of touch targets for pointer down, if needed. final boolean split = (mGroupFlags &amp; FLAG_SPLIT_MOTION_EVENTS) != 0; TouchTarget newTouchTarget = null;// newTarget标识是否和原来的target有变化，来判断是否已经分发过了 boolean alreadyDispatchedToNewTouchTarget = false; if (!canceled &amp;&amp; !intercepted) { // 不是取消事件，也不是拦截事件（如果是二者，那么不找新的target，直接进行分发，cancel分发给子view，拦截分发给自己） // If the event is targeting accessibility focus we give it to the // view that has accessibility focus and if it does not handle it // we clear the flag and dispatch the event to all children as usual. // We are looking up the accessibility focused host to avoid keeping // state since these events are very rare. View childWithAccessibilityFocus = ev.isTargetAccessibilityFocus() ? findChildWithAccessibilityFocus() : null; if (actionMasked == MotionEvent.ACTION_DOWN || (split &amp;&amp; actionMasked == MotionEvent.ACTION_POINTER_DOWN) || actionMasked == MotionEvent.ACTION_HOVER_MOVE) { final int actionIndex = ev.getActionIndex(); // always 0 for down final int idBitsToAssign = split ? 1 &lt;&lt; ev.getPointerId(actionIndex) : TouchTarget.ALL_POINTER_IDS; // Clean up earlier touch targets for this pointer id in case they // have become out of sync. removePointersFromTouchTargets(idBitsToAssign); final int childrenCount = mChildrenCount; if (newTouchTarget == null &amp;&amp; childrenCount != 0) {//viewgroup是不是空的 final float x = ev.getX(actionIndex); final float y = ev.getY(actionIndex); // Find a child that can receive the event. // Scan children from front to back. final ArrayList&lt;View&gt; preorderedList = buildTouchDispatchChildList();// 获取直接子View，而不是子孙View final boolean customOrder = preorderedList == null &amp;&amp; isChildrenDrawingOrderEnabled(); final View[] children = mChildren; for (int i = childrenCount - 1; i &gt;= 0; i--) { final int childIndex = getAndVerifyPreorderedIndex( childrenCount, i, customOrder); final View child = getAndVerifyPreorderedView( preorderedList, children, childIndex); // If there is a view that has accessibility focus we want it // to get the event first and if not handled we will perform a // normal dispatch. We may do a double iteration but this is // safer given the timeframe. if (childWithAccessibilityFocus != null) {// 如果有辅助View，那么我们就要确保先找到这个辅助View，然后从头开始正常分发 if (childWithAccessibilityFocus != child) { continue; } childWithAccessibilityFocus = null; i = childrenCount - 1; } if (!canViewReceivePointerEvents(child) //如果view不可以接收触摸事件 且 事件坐标范围不在view内，那么跳过继续寻找 || !isTransformedTouchPointInView(x, y, child, null)) { ev.setTargetAccessibilityFocus(false); continue; } newTouchTarget = getTouchTarget(child); if (newTouchTarget != null) { // Child is already receiving touch within its bounds. // Give it the new pointer in addition to the ones it is handling. newTouchTarget.pointerIdBits |= idBitsToAssign; break;// 找到了有意愿处理触摸事件的view，不再继续往下找 } resetCancelNextUpFlag(child); if (dispatchTransformedTouchEvent(ev, false, child, idBitsToAssign)) {// 找到可以分发的，跳出循环 // Child wants to receive touch within its bounds. // 找到了，（注意，只有ACTION_DOWN才能进行到这一步，MOVE等事件在上一步就已经找好了 mLastTouchDownTime = ev.getDownTime(); if (preorderedList != null) { // childIndex points into presorted list, find original index for (int j = 0; j &lt; childrenCount; j++) { if (children[childIndex] == mChildren[j]) { mLastTouchDownIndex = j; break; } } } else { mLastTouchDownIndex = childIndex; } mLastTouchDownX = ev.getX(); mLastTouchDownY = ev.getY(); newTouchTarget = addTouchTarget(child, idBitsToAssign);// 新加入的touchTarget加入列表头 alreadyDispatchedToNewTouchTarget = true; break; } // The accessibility focus didn't handle the event, so clear // the flag and do a normal dispatch to all children. ev.setTargetAccessibilityFocus(false); } if (preorderedList != null) preorderedList.clear(); } if (newTouchTarget == null &amp;&amp; mFirstTouchTarget != null) {// 没有找到新的，那就用上一次 // Did not find a child to receive the event. // Assign the pointer to the least recently added target. newTouchTarget = mFirstTouchTarget; while (newTouchTarget.next != null) { newTouchTarget = newTouchTarget.next; } newTouchTarget.pointerIdBits |= idBitsToAssign; } } } // Dispatch to touch targets. if (mFirstTouchTarget == null) {// 如果没有找到，分发给自己 // No touch targets so treat this as an ordinary view. handled = dispatchTransformedTouchEvent(ev, canceled, null, TouchTarget.ALL_POINTER_IDS); } else { // Dispatch to touch targets, excluding the new touch target if we already // dispatched to it. Cancel touch targets if necessary. TouchTarget predecessor = null; TouchTarget target = mFirstTouchTarget;// 表明事件之前已经分发过了。所以有target记录 while (target != null) { final TouchTarget next = target.next; if (alreadyDispatchedToNewTouchTarget &amp;&amp; target == newTouchTarget) { handled = true; } else { final boolean cancelChild = resetCancelNextUpFlag(target.child) || intercepted;// 如果被拦截，那么就发送取消事件 if (dispatchTransformedTouchEvent(ev, cancelChild, target.child, target.pointerIdBits)) { handled = true; } if (cancelChild) { if (predecessor == null) { mFirstTouchTarget = next; } else { predecessor.next = next; } target.recycle(); target = next; continue; } } predecessor = target; target = next; } } // Update list of touch targets for pointer up or cancel, if needed. if (canceled || actionMasked == MotionEvent.ACTION_UP || actionMasked == MotionEvent.ACTION_HOVER_MOVE) { resetTouchState(); } else if (split &amp;&amp; actionMasked == MotionEvent.ACTION_POINTER_UP) { final int actionIndex = ev.getActionIndex(); final int idBitsToRemove = 1 &lt;&lt; ev.getPointerId(actionIndex); removePointersFromTouchTargets(idBitsToRemove); } } if (!handled &amp;&amp; mInputEventConsistencyVerifier != null) { mInputEventConsistencyVerifier.onUnhandledEvent(ev, 1); } return handled;}","link":"/2018/01/09/android-touch-event-dispatch/"},{"title":"从代码设计看 Glide 之写在开头","text":"为什么要写这篇文章？你日常中一定遇到过，想要设计一个模块，但是力不从心，不知道如何下手，更别说随手撸一个图片加载器，网络，埋点通信，这种级别的库了。 那有没有一些什么好的方法可以帮助我们建立这样的能力呢，当然是有的，那就是从开源库中学习，一个好的开源库一定是大众认可才被广泛传播。所以，找到一个有代表性的库，深入浅出剖析这个库的代码设计和编程思想，就是我们这个系列要做的事情。 为什么是 Glide？当然，你也从标题就看出来了，我们选的这个库就是 Glide。 说实话，Glide 是一个比较老的库了。第一行代码提交于 2012 年，至今已有 10 多个年头了。称之为一个老库不为过。那既然是老库，还有研究的必要吗？尤其是在最近几年 Jetpack，Flutter 蓬勃发展的时候，我们重新去解析一个老库还有必要吗？ 当然是有必要的，而且是非常有必要的。 虽然 Glide 出来的时间很久了，但却鲜有人去深入解析 Glide 的代码设计和编程思想。大多数只是从某个切入点来学习 Glide 的实现细节，研究某个场景下的解决方案。 其次，Glide 除了为我们提供高效，稳定的图片加载功能外，还为我们提供了一个如何打造易用，可拓展且优雅的开源库的典型范例。它其中蕴含的设计模式和编程思想完全可以运用到我们日常的代码编写中，提升我们的代码质量。 所以，这个系列的文章会立足于此，深入解析 Glide 中的设计模式和编程思想。另外这个系列也会包含我个人对如何进行模块设计的一些思考。 需要做哪些阅读准备？本系列基于 Glide v4.14.0 版本。 你可以从 github 获取对应的源代码，然后切换到指定的 tag 即可。当然大多数情况下使用 master 也不会影响阅读，因为整个 v4 的版本基本已经趋于稳定，已不在做一些结构上大的变更。 源码地址：https://github.com/bumptech/glide 阅读顺序是什么？这个系列会从 Glide 的主体框架出发，随着调用链一点点深入，并且辅以类图和模块图，来帮大家从宏观的角度理解 Glide 的代码设计。我也不会贴大量的实现细节和代码调用链，而是会从概念上解释这么设计的必要性，从而避免陷入到过多细节中。 同时，我也会尽可能的保持每个篇章内容不会过多，方便大家在上班路上或者工作间隙阅读。 思考一下？那么在即将进入我们的第一个章节之前，我们先思考这么一个问题：一个图片加载器的核心功能应该由哪几个类或者模块组成呢？ TIPS：这个系列是一边读源码一边写出来的，所以可能有理解不够深入的地方，欢迎大家随时指正。","link":"/2023/07/02/begging_of_glide_code_design/"},{"title":"从代码设计看 Glide 之核心功能","text":"接上文。这篇我们主要关注于 Glide 的核心能力，来看一看构建出 Glide 核心的能力的模块或者类是哪些。 示例如果用过 Glide 肯定记得通过 Glide 加载一个图片最简单的写法是什么。 1Glide.with(applicationContext).load(&quot;https://xx.image/test&quot;).into(view) 加载某张图片到某个 View。 这就是 Glide 最核心的代码。 Glide 中其他的代码和模块都是围绕在这个核心链路周围的。比如通过 load 可以拓展出不同的数据来源，通过 Target 拓展出不同的展示目标。还比如说给 load 的所要加载的数据增加缓存，给 load 本身增加生命周期等等。 所有的这一切都是在加载图片到 View 上这个核心功能基础之上的。 所以，我们这篇文章就从这个核心代码开始。 正文Glide 的 with 传入的是 Android 的 Context，Glide 主要用 Context 来做生命周期管理。所以本文我们先不考虑 Context 的实例究竟是 Activity 还是 Fragment，我们就默认他只能为全局的 Application（反正本章也不会讲到^_^），关于 Activity 和 Fragment 相关的内容，我们会在后续的生命周期篇章中详述。 从简单的图片加载功能开始我们先抛开文章开头的 Glide 示例，来思考：如果让你实现一个最简单的图片加载功能，将网络图片加载到 View 上，你会怎么写？ 我们的思路肯定是： 下载网络图片 下载完成后，通过回调将图片设置到 View 上 实现方案就是将下载封装到一个类中，然后给出一个回调就行了。如果我们再考虑多一些：要同时加载的链接可能会有多个，要同时加载的 View 也可能会有多个的情况下，一个类可能就有点放不下了。 我们适当拆点职责出来，将每个下载过程都封装成独立的请求（Request），然后使用一个类（RequestManager）统一管理 那么新的图片加载功能就包含有这几个职责了 Glide：统一对外的类 Request：封装单个下载请求的类，会通过 into 关联到我们要加载的 Target RequestManager：管理多个请求的类，我们通过 With 来获取 RequestManager Target：图片要加载到哪个 View 的抽象类（例如 View 可能是 TextView 也可能是 ImageView） 我们来画一个简单的类图描述一下这几个类的关系 其中 RequestManager 和 Request 是聚合的关系（注意聚合关系和组合关系的区别） 框架核心逻辑尽量内聚如果这个时候我们想对 Request 请求做一些参数修改和定制的话，这个调用链有个地方就不合适了。 Request 是我们框架内的原始的请求抽象，是不能随意对外暴漏出去，因为这样会影响到我们框架的稳定性。即使使用者有修改定制 Request 的需求，我们也要让使用者按照我们约束的参数来使用，而设计模式中有一个模式非常适合做这个事情。 Builder : 你是在说我吗？你一定是在说我。 （由于 Glide 中太多 Builder 和他的兄弟 Factory 了，所以后边有一期会专门讲 Glide 中 Factory 和 Buidler 的范例，大家可以多多关注点赞一下） 那么我们在这里增加新的一个角色，RequestBuilder，代替 Request 放到调用链中，方便我们对 Request 参数做一些定制。当前，他只有一个功能就是接管了 Request 的构建过程，通过 into 将 Target 传递进来 现在，我们的类图变成这样了 这个时候，如果我们去看示例中 Glide 每一段调用链所返回的对象，你会发现，和我们上图中所展示的一模一样。 我们已经有了一个初步可以使用的图片加载功能版本了。 Request 表示我很难但实际我们在写的时候，不会将图片下载的全部过程都要交给 Request 来做，因为这个职责太重了，会导致 Request 类变得特别大，后边如果要做缓存，网络库解耦，本地加载等功能的时候，也会频繁修改到这个类，不符合设计原则中的开闭原则 因此我们把图片下载和加载的这部分职责从 Request 拆出来，等我们图片下载和加载准备就绪了再通知 Request 就好，让 Request 专一和 Target（View） 打交道。 对于下载和加载的部分我们这里就简单设计一个任务管理类，内部包含一个线程池，可以支持多任务调度下载加载，并且在每个任务的图片加载结束后通过回调通知 Request。 根据这个需求我们再新增加 2 个角色和 1 个回调： Engine：负责管理下载任务的运行和调度 EngineJob：是下载图片和加载图片的任务抽象 ResourceCallback：EngineJob 加载资源完成后，通过这个回调通知 Request。 好了，我们在类图中再加几员大将，类图现在如下： 但… 图片尺寸怎么办？如果你直接就开始按照我们上边设计的去实现，你会发现有一个问题： 我们应该在什么时候去调用框架去做图片加载呢，之所以考虑调用的时机是因为这会关系到两个问题： View 是不是准备好要展示了？（比如 Visibility.GONE 的时候加载图片干什么？嫌电量掉的不够快吗？） 图片应该加载多大尺寸呢？ 也就是说，最好有个回调 SizeReadyCallback 可以告诉我们开始加载的时机，让我们可以触发我们真实的资源加载，而不至于在 view 原本不打算展示的场景下，还会继续触发加载。 对于 Android 来说，要感知到这个时机，有一个名为 OnPreDrawListener 的回调可以帮到我们 一者，在 onPreDraw 触发的时候，预示着 view 即将要被展示出来了。 二者，可以通过 onPreDraw 不断检测当前 view 的尺寸是否合法了。 这样等我们可以获取到合法的尺寸之后，就通过 SizeReadyCallback 回调给 Request，推动 Request 开始做真正的请求。 那这个 ResourceCallback 谁来调用呢？当然是我们的 Target 了（view），因为他可以知道自己什么时候能真的准备好。 好了，那我们再这个回调补充到我们的类图中 额外补充 如果你直接去看 Glide 主流程的调用链路，盯着 request 一直往下走，会发现在 request 启动之后，没有后续了。那么真正的 load 在哪里开始的，request 并没有体现。 我们会在 Request 的实现 SingleRequest 中看到一个不起眼的代码 1target.getSize(this); SingleRquest 将自己注册给 Target，而 Target 则监听了 Android 的 ViewObserver 1ViewTreeObserver observer = view.getViewTreeObserver(); layoutListener = new SizeDeterminerLayoutListener(this); observer.addOnPreDrawListener(layoutListener); 在 PreDraw 的时候，Target 就会不断检测当前 View 的尺寸是否合法了。这样等尺寸准备好之后，就通过 SizeReadyCallback 回调通知 Request，推动 Request 开始做真正的请求。 最后检查看到这里，我们已经完成了自己设计的一个简易图片加载库的核心功能了（其实是Glide的），我们最后以面向对象的思想来看一下每个类的职责： Glide： 是我们作为图片加载库的总入口，触发图片加载和其他一些功能。同时单例实现。使用 Facade Pattern 设计模式，将内部复杂的使用逻辑封装为简易的使用接口，降低使用者的接入成本。 RequestManager：请求管理者，RequestManager 根据 load 的具体内容创建 RequestBuilder，来让用户进一步定制 Request 的细节。同时，RequestManager 也负责多个 Request 的管理，例如启动暂停等。 RequestBuilder： 将用户传入的参数（例如 Target）和其他 options 一起构建出 Request Request： 是链接加载到图片的这一行为的抽象。方便我们把控这个过程。而每个 Request 实现 SizeReadyCallback 接口：这个标识真实应该触发 load 的时机 ResourceCallback 接口：这个标识资源加载完成，可以设置到 View 的时机 Engine：下载图片和加载图片任务的管理类，提供线程池的能力，方便异步加载和调度系统资源。 EngineJob：下载图片和加载图片的任务抽象。 SizeReadyCallback 接口：只有 target 才知道的自身尺寸准备好的时机（比如 view 要在 onPreDraw 才知道自己的尺寸大小），所以这个 Callback 需要 target 回调 ResourceCallback 接口：图片下载 job 可以知道图片资源什么时候就绪，这个 Callback 需要 Job 回调 最后的最后，我们将其所有的功能简单分为三个模块： 结束语至此，我们第一个章节内容就结束了。 我们从 Glide 最基础的图片库的核心能力开始，打造出了一个简易的图片框架。包含了基本的图片加载主流程。 当然，这个图片框架拓展性不够，加载的数据很单一，另外缓存能力也缺失，也没法做生命周期管理，可能会造成内存泄漏等等之类的。当然我们后边的系列文章会逐步完善这个框架。 下一期，我们将为这个框架增加生命周期的能力，让这个框架可以实现自我管理。","link":"/2023/08/11/core_of_glide_code_design/"},{"title":"【译】如何书写 Gentoo Ebuilds 的基本规则","text":"原文：https://wiki.gentoo.org/wiki/Basic_guide_to_write_Gentoo_Ebuilds 这篇文章包含了 Ebuilds 开发的一些介绍。 Portage， Gentoo的核心，使用 ebuild 脚本搭建为了能够进行包管理，你必须定义包（packages）是什么，他们怎么下载，解压，打补丁（patch），编译，安装以及合并（从一个临时的文件夹拷贝到你在用的文件系统）源文件和（或）二进制文件，为了使他更好用，我们还需要添加一些有用的元数据（metadata），例如 USE Flags， 补丁（patches）以及其他，这些工作可以让我们更好的维护这个这个过程，这些中的大部分都在一个 ebuild 文件中定义（一个 bash 脚本文件） Ebuilds，他们存在哪里，我怎么样创建一个如果你已经安装安装过 Gentoo，你或许记得下载并解压过一个 Portage 树的镜像，这个镜像（当你运行emere --sync升级到的最近的更新）内容中包含了大部分的 ebuilds，这就是 portage 树，它解包之后通常在 /usr/portage 位置 首先，你不能直接创建一个 /usr/portage/hello-wolrd.ebuild 文件，并且完成它，这有几个原因： 这儿（/usr/portage）是你的一个远程Portage树的本地拷贝的存放位置：如果在这儿放一个 ebuild 文件，或者更新一个 ebuild，当你运行emerge-sync的时候，你的更新将会丢失，因此你可以在/usr/local/portage，home 目录下的一个子目录，或者使用一个本地overlay来代替 ebuild 文件不在正确的文件夹：ebuild 文件必须位于分类（category）文件下的以包命名的子文件夹下，因此如果你想使这个 ebuild 生效，你必须放置它在类似/usr/local/portage/app-misc/hello-world/这样的位置 ebuild 文件没有版本说明：软件包有版本，他们必须在文件名称中指明，因此我们可能会创建这样的文件/usr/local/portage/app-misc/hello-world/hello-worl-1.0.ebuild因此，让我们建一个最小的 ebuild，为了让这个过程更简单，我允许你在 root 用户下运行，如果你喜欢，你也可以使用 sudo 123root# mkdir -p /usr/local/portage/app-misc/hello-worldroot# cd $!root# cp /usr/portage/header.txt ./hello/world-1.0.ebuild 我们递归创建文件夹，然后进入（$! 将会调用上一条命令的最后一个参数），然后我们添加了一个 ebuild 头声明，如果你想将软件添加到 portage 树中的话，这是必须的 这也不会运行，这是我们定义最小数量的变量的要求，因此我们将以下代码添加到 ebuild 中 CODE: 你至少得在ebuild中添加如下代码 12DESCRIPTION=&quot;A classical example to use when starting on something new&quot;SLOT=&quot;0&quot; 仅仅只是两个变量? 没错，这要求我们要有自己的包的描述信息，以及我们能够确定自己不使用 SLOT，这就是”0”的意思 到这里，我们就可以运行以下命令将我们的包安装到系统里了 1root# ebuild hello-world-1.0.ebuild manifest clean merge 这条命令将会显示（manifest）（创建 hash，取消显示），清除工作目录的任何的临时文件，并且安装（emerge）ebuild非常好，你已经创建并测试了你的第一个 ebuild，虽然没有做多少，这确实是一个好的开始 让我们创建一个运行时显示”hello world”的文件添加更多有用的变量如果你看过 /usr/portage/skel.ebuild 文件，你将会发现一个 skeleton 有大量的文档，我们将会添加这些中的一些变量，将 ebuild 变成我们想要的样子，因此如果能够在我们继续之前能够读完这个文件就再好不过了，将下边的代码添加到我们的 hello-world.1.0.ebuild 文件中CODE 官方（council）建议使用最新的ebuild的API 1EAPI=&quot;5&quot; 重要提示!! 以上的变量必须在头说明之后首先被列出，因此我们一般都是将它添加到变量的上边 更多关于 EAPI 的信息，看 这里 CODE 以下代码添加对于开发者来说软件可以被找到的主页（homepage）HOMEPAGE=&quot;http://wiki.gentoo.org/index.php?title=Basic_guide_to_write_Gentoo_Ebuilds&quot; CODE 以下代码添加我们将从哪里下载软件，由这个文档的作者添加SRC_URI=&quot;http://dev.gentoo.org/~tomwij/files/wiki/hello-world-1.0.tar.gz&quot; 这是一个简单的包含可以输出”Hello world!”的hello-world脚本的压缩包（tarball） 接下来，我们需要指定一个证书（license），我特别声明我正在使用MIT证书，因此让我们加入它CODE 以下代码表示我们在MIT证书下 1LICENSE=&quot;MIT&quot; 我们已经完成了 SLOT，现在我们可以来看看 KEYWORDS，KEYWORDS 变量将会告诉你的安装包工作在哪个平台上（arches），也会指明是否被屏蔽（masked）（没有被列出或者被确切的使用-列出），还会指明是否是未测试untested（），或者是稳定版（列出的，但是没有符号在前边），我们现在能做的就是列出所有平台，并且指明是未测试的，对，是所有的平台，因为他们都可以运行 shell 脚本 CODE 我们可能很确信我们的包可以运行在所有的平台上，但是可能还没有稳定 1KEYWORDS=&quot;~alpha ~amd64 ~arm ~hppa ~ia64 ~ppc ~ppc64 ~s390 ~sh ~sparc ~x86&quot; 其他的变量定义一些更多的东西（在 skel.ebuild 中检查他们），但是我们现在不需要这些，你也可以看到还有一些函数，但不要着急，让我们先来看看直到现在 ebuild 已经做了哪些工作CODE ebuild文件看起来就像这样 12345678910111213# Copyright 1999-2015 Gentoo Foundation# Distributed under the terms of the GNU General Public License v2# $Header: $ EAPI=&quot;5&quot; DESCRIPTION=&quot;A classical example to use when starting on something new&quot;HOMEPAGE=&quot;http://wiki.gentoo.org/index.php?title=Basic_guide_to_write_Gentoo_Ebuilds&quot;SRC_URI=&quot;http://dev.gentoo.org/~tomwij/files/wiki/hello-world-1.0.tar.gz&quot; LICENSE=&quot;MIT&quot;SLOT=&quot;0&quot;KEYWORDS=&quot;~alpha ~amd64 ~arm ~hppa ~ia64 ~ppc ~ppc64 ~s390 ~sh ~sparc ~x86&quot; 1root# ebuild hello-world-1.0.ebuild manifest clean merge 我们可以看到，这是它第一次尝试从一个镜像下载我们的文件，但是不是 gentoo 的镜像，而是我们所指定的 SRC_URI 变量的值 当它有了一个文件之后，他就能够创建一个 manifest，这包含了我们的 ebuild 和已下载文件的 hash 值，来确保数据完整，传输没有发生错误然后，emerge 系统开始介入，数据完整性是第一次需要检查的，然后我们可以看到我们下载的压缩包已经自动解压了，这一点很有用，我们没有必要再去实现，我们可以改变这个行为通过覆盖它的函数（src_unpack），设置一些变量，或者使用定义了这些行为的 eclasses，当然这个例子中我们不需要这么干当我们看到更多的内容之后，我们能看到它试着准备，配置，编译和安装，在准备阶段，通常会执行打补丁操作，在配置和编译阶段，通常会执行build操作，默认我们运行econf（./configure 的一个封装），以及emake（make 的一个封装），但是如果我们使用一个 shell 脚本，我们不需要调整这些阶段 现在，最后一步看起来不是很正确，还没有安装我们的文件呢 告诉我们的ebuild哪里安装我们的shell脚本在我们的开发者文档中，我们可以发现阶段功能的一些说明，src_install 看起来对我们现在想要做的很有帮助，如果你点击 src_install 链接，你可以看到对于每个 EAPI 中，这个函数所作的一些操作以及一些例子，默认的看起来并不是很合适，我们需要定义自己的 src_intall，在这个函数中，我们将会调用另外的函数执行安装的工作，这些函数的概览，我们可以在安装函数中找到因此我们可以将以下代码添加到我们的ebuild中 CODE 让我们将我们的shell脚本放到/usr/bin中，并且使他可以运行 123funtion src_install（） { dobin hello-world} dobin这个函数可以拷贝 hello-world 文件到临时的build文件夹（${D}/usr/bin/），并且是它可运行，后边portage将会检查，并且拷贝到运行的系统中 让我们再试试… 1root# ebuild hello-world-1.0.ebuild manifest clean merge 现在我们可以看 “&gt;&gt;&gt; /usr/bin/hello-world” 输出，看起来很不错！ 让我们试试这个函数运行怎么样 1user$ hello-world 现在我们完成了安装一个输出”Hello world!” 的包","link":"/2015/11/24/gentoo-basic-guide-ebuilds/"},{"title":"【译】Gentoo Local Overlay","text":"原文：https://wiki.gentoo.org/wiki/Custom_repository Overlay/Local Overlay有人给你了一个ebuild文件，你不知道该用它干什么？不要担心，接下来我们会介绍到 创建一个本地overlay你只需要很简单的几步就可以创建一个本地overlay 1234root# mkdir -p /usr/local/portage/{metadata,profiles} root# echo 'NameOfYourOverlay' &gt; /usr/local/portage/profiles/repo_name root# echo 'masters = gentoo' &gt; /usr/local/portage/metadata/layout.conf root# chown -R portage:portage /usr/local/portage 接下来，让portage知道我们建了一个overlay root# mkdir -p /etc/portage/repos.conf FILE /etc/portage/repos.conf/local.conf 1234[NameOfYourOverlay]location = /usr/local/portagemasters = gentooauto-sync = no 注意“NameOfYourOverlay” 只是一个示例，你应该将他改为一个有意义的名称 注意之前的方式是在make.conf中设置 ‘PORTDIR_OVERLAY’ 变量，现在已经被废弃掉了，不应该再被使用 添加一个ebuild到overlay中现在，基本的框架已经搭建好了，你可以在overlay中添加ebuild了．在这个例子中就是app-dicts/artha-1.0.2. 我们首先确认这个ebuild文件在用户myuser 的home目录下，并且文件名称是artha-1.0.2.ebuild. 123456root# mkdir -p /usr/local/portage/app-dicts/artha root# cp ~myuser/artha-1.0.2.ebuild /usr/local/portage/app-dicts/artha/artha-1.0.2.ebuild root# chown -R portage:portage /usr/local/portage root# pushd /usr/local/portage/app-dicts/artha root# repoman manifest root# popd 现在你可以使用emerge来安装ebuild所表示的包 1root# emerge -av1 app-dicts/artha Crossdevcrossdev 将会自动将它生成的ebuils/categories放到在/etc/portage/repos.conf/中找到的优先级最好的overlay中，因此你必须设置overlay的优先级(priority)，绝大多数用户将不愿意crossdev访问发行版layman的overlay或者用户个人每个机器上的overlay（通常位于/usr/local/portage).创建一个crossdev专用的overlay应该这样做： 1234root# mkdir -p /usr/local/portage-crossdev/{profiles,metadata} root# echo 'local-crossdev' &gt; /usr/local/portage-crossdev/profiles/repo_name root# echo 'masters = gentoo' &gt; /usr/local/portage-crossdev/metadata/layout.conf root# chown -R portage:portage /usr/local/portage-crossdev 如果主Portage树使用Git同步，或者任何其他不校验ebuils文件的方法，使用如下方法来屏蔽&quot;mastked by: corruption&quot;的错误 FILE /usr/local/portage-crossdev/metadata/layout.conf 12masters = gentoothin-manifests = true 然后指明Portage和crossdev使用这个overlay FILE /etc/portage/repos.conf/crossdev.conf 12345[local-crossdev]location = /usr/local/portage-crossdevpriority = 10masters = gentooauto-sync = no 参考链接：[0]: https://bugs.gentoo.org/show_bug.cgi?id=312313[1]: https://wiki.gentoo.org/index.php?title=Crossdev&amp;action=edit&amp;redlink=1[2]: https://wiki.gentoo.org/wiki/Layman","link":"/2015/11/25/gentoo-local-overlay/"},{"title":"Git 与 Gerrit","text":"为什么需要版本控制系统，我想点进这篇文章的读者应该都已经对这个问题了然于胸，所以不再废话。我们会从版本是控制系统的历史发展开始着眼，到分布式系统仓库的概念，以及从仓库之间的数据传输协议，到最后的仓库的权限控制系统 Gerrit 一一讲过，来理解这些系统的使用方式和设计理念。 分布式 Git我们都听过 Git 是完全分布式的，那么所谓的分布式怎么理解呢？ 要理解 Git 的的分布式，就需要来看一下版本控制系统的发展历程，从发展中看事物产生的必然性 本地版本控制系统在互联网还未出来或者还在萌芽的时候，版本控制系统大多以本地为主，因为没有太多协作的必要性，软件规模也不是很大，所以版本控制系统还比较简单。 本地代码控制系统优缺点明显：简单的版本控制，数据容易丢失，无法和其他人协作，但胜在简单，有简单的数据库管理版本历史 集中式版本控制系统 为了应对多人远程协作而发展出来的版本控制系统，以版本控制服务器为中心提供代码仓库，多个开发人员和服务器交互，服务器针对开发人员开放版本快照，而且强依赖网络，如果没有好的备份策略，无法很好地应对数据丢失的问题 分布式版本控制系统 不同于集中式版本控制系统，分布式版本控制系统的每台主机都可以成为服务器，他们之间是对等的关系，对应的上边的示意图中，Computer A 和 Computer B 不需要 Server 也可以交换数据，交互数据使用统一的协议，这协议有我们熟悉的 HTTP 协议，也有相对陌生的 SSH 协议，还有 Git 基于 SSH 封装过的 Git 协议，每个协议都有自己擅长的方向，我们在后边会细细讲到。 从另一方面来说，分布式的这种概念，就是每台主机都包含全部的历史记录，这样可以避免我们上边讲到的集中式版本控制系统的两个缺陷，数据备份和离线开发。当服务器代码丢失之后，可以从任何一个开发人员的本地仓库中恢复，“鸡蛋” 不会放到一个篮子里。 注意：各个 Git 仓库之间同步的是一种叫做”元数据“的内容，属于 Git 版本控制系统中的数据库内容，不涉及直接操作原始的项目代码 既然在分布式下，每个仓库都是平等的，都可以提供源代码，那么 Git 是如何区分每个仓库呢？又如何在不同的仓库之间传输信息呢？ Git Remote在 Git 中，我们通过 remote 这个关键字标识想要与之同步的其他仓库，每个 remote 都由 name 和 url 组成 name 表示仓库的名称，方便后续引用，也方便区分多个不同的仓库 url 表示仓库的地址，标识了这个仓库唯一性，后续具体数据同步实际都是通过这个地址来进行 我们可以通过 git remote 指令来获取这部分信息 123$ git remote -vorigin https://github.com/bumptech/glide.git (fetch)origin https://github.com/bumptech/glide.git (push) 以上示例是 glide 在 Github 上的仓库 clone 到本地，我们可以看到有一个名称为 origin 的远程仓库，协议为 https，后边括号中说明了当前地址是被用来 fetch 还是 push，我们也可以据此推出 fetch 和 push 支持分别指定不同的地址 注：origin 是 git 默认指派的 remote 名字，我们可以通过git remote rename origin xxxx换成自己喜欢的名字 我们在这个工程下增加追踪一个使用 ssh 协议的远程仓库，如下： 1234567$ git remote add back ssh://gitlab.com/bumptech/glide_back.git$ git remote -vorigin https://github.com/bumptech/glide.git (fetch)origin https://github.com/bumptech/glide.git (push)back ssh://gitlab.com/bumptech/glide_back.git (fetch)back ssh://gitlab.com/bumptech/glide_back.git (push) 增加完成这个仓库，我们就可以使用 fetch 和 push 来分别从 back 这个远程仓库拉取和推送代码，如果完全去中心化，那么对于多人协作来说，每个人都可以通过这样的方式处理多个远程仓库的代码合并，完成协作。 接下来我们来详细了解每台主机之间是如何通信的，也就是 Git 的通信协议。 传输协议（HTTP or SSH）Git 使用四种主要的协议来传输资料：本地协议（Local），HTTP 协议，SSH（Secure Shell）协议及 Git 协议。 可以看到 Git 其实并没有自己创建新的协议信息，而是使用了已有的互联网主流的传输协议，避免了重复造轮子，也降低了使用成本。 本地协议只适用与本地备份，Git 协议缺少授权机制和加密机制，使用成本较高，所以我们这里只来简单看两个最常见的协议： HTTP 协议 和 SSH（Secure Shell）协议 HTTPGit 通过 HTTP 通信有两种模式。 在 Git 1.6.6 版本之前只有一个方式可用，十分简单并且通常是只读模式的。 Git 1.6.6 版本引入了一种新的、更智能的协议，让 Git 可以像通过 SSH 那样智能的协商和传输数据。 HTTP 协议因为其广泛的使用，所以大多数的防火墙都不会禁止 HTTP/S 的端口，所以使用较为方便另外一个好处时，可以直接通过 HTTP 的授权来使用 Git 仓库，方便快捷。 但缺点同样明显，HTTP 每次推送改动都会需要校验用户名和密码，虽然各个平台有管理认证凭证的工具，但是用起来相对复杂 SSHSSH 协议的优缺点也是简单明显： 通过 SSH 访问是安全的 —— 所有传输数据都要经过授权和加密。 但是 SSH 协议无法匿名 通常，我们在 clone 代码的时候，服务器会提供给我们可选的协议，作为项目的主要开发者，我们日常使用的都是 SSH 协议，因为免去了每次都要认证的烦恼，而且也很高效，而对于很多公开代码的仓库来说，因为 HTTP 支持匿名访问，所以大多都使用 HTTP 协议提供下载。 解决完对仓库的权限认证之后，我们还有一个问题需要处理：代码合入权限 Gerrit如果你之前用过 github 或者自己搭建过版本控制服务器，你就会发现，我们之前的代码都是直接推送到仓库中的，并没有经过审核，这对于个人开发者或者小团队来说，效率很高，但是对于大的项目来说，代码审核是控制版本质量，控制代码质量必须有的一步。Git 自身其实没有提供代码审查的功能，任何的改动，只要有权限，都是可以直接操作源码仓库的，对仓库的权限力度来说，要么有合入权限，要么没有合入权限，这对于团队开发来说是不合理的。 所以，基于代码审核的需求，gerrit 应用而生。 以下是 Git Server 和 Gerrit Server 的演进图 很明显的可以看到，gerrit 提供了一个开发者和代码仓库服务器之间的屏障，开发者是没有权限直接合并到代码服务器的版本控制系统的，只能推送到 gerrit 提供的一个叫做 “Pending Changes” 的区域，这个区域内的代码会交由 Reviewer （通常是团队的负责人）审核并合入。这种方式限定了开发者直接操作源码服务器的能力，而是经由代码审查之后合并到主分支，大大提升了项目质量和版本质量。 拓展：这个屏障是怎么做到的，提示：通过 refs/for/xxx 的命名空间，每次 push 代码，都是类似于 git push origin HEAD:refs/for/master 通过 gerrit 这样的一个中转平台，就可以很大的扩展 git 的功能，综合来说，Gerrit 有以下的优点： 代码 review 历史合并记录查询 某个提交的流动记录查询 权限控制 可视化窗口管理 简易的代码编辑工具 知会相关开发者代码变动 和其他网站联动进行自动化 有些人会对第三点有疑问：什么是某个提交的流动记录？这里就不得不提 Gerrit 创建出来的一个概念：Change-Id 多数人第一次见到这个词是比较懵的，因为在 git 的官方文档中并没有这个词的说明。没错，这个关键字 git 并不使用，也不会识别。真正用到它的是 gerrit，我们的代码审查服务器。 理解 Change-Id 之前，有一个容易混淆的概念我们一并讲一下，那就是 Commit-Id Commit-Id通常，我们会将一些工作内容的变更打包成一个 commit 对象，然后放到 Git 的数据库中存起来，打包的每个 commit 对象都带有一个 id，称之为 commit-Id，这个 id 唯一标示了本次打包这一操作，一旦因为重新打包或者移动了这个 commit 对象，那么 id 就会随之发生变化。 我们可以通过一下方式更改 commit-Id： 重新打包可以使用 git commit –amend，git rebase 修改历史提交，或者使用git reset 撤销再次提交做到重新打包 移动 commit 对象，可以用 git cherry-pick 或者 git rebase 使用git push 和 git pull/fetch 只是同步数据库并不会更改 commit 对象 那么 Change-Id 是用来做什么的呢？ Change-Id Gerrit needs to identify commits that belong to the same review. For instance, when a change needs to be modified, a second commit can be uploaded to address the reported issues. Gerrit allows attaching those 2 commits to the same change, and relies upon a Change-Id line at the bottom of a commit message to do so. With this Change-Id, Gerrit can automatically associate a new version of a change back to its original review, even across cherry-picks and rebases. 以上官方内容，简单用一句话来说：为了识别一个提交的多次更改 什么情形下会用到这个呢，我们来想象这么一个场景：我们提交一笔 Commit-Id 为 A 的提交到 Gerrit 服务器，然后突然想到需要追加一个文件，我们使用git commit --amend 追加到前一个提交，然后提交到 Gerrit 服务器，按照我们的预期，这应该是一笔提交，但是服务器确会出现两笔提交，因为追加的第二笔提交 Commit-Id 会被更改，所以会被认为这是两笔提交，解决这个问题的方法是引入 Change-Id 标示这两笔改动都属于一个 Change-Id，这样在推送前后两笔提交的时候，Gerrit 会关联两笔提交作为提交的不同版本，而不是不同的提交。 对于上文中提到的可以更改 Commit-id 的 cherry-pick 和 rebase 方式，Gerrit 也可以使用这种方式追踪，这也就是前文提到的 Gerrit 可以追踪同一个提交在不同分支的流动记录，就是通过 Change-id 方式实现的。 我们在 gerrit 网站上会看到 patch-set update 的提示，并且这多个 patch set 之间的变更记录也可以通过 diff 的方式追踪在 gerrit 可以通过 change-id 来搜索同一个提交的不同分支的流动记录。 文章的最后，我们来讲一下为什么要使用命令行，而不是 GUI 工具。 为什么要使用命令行 所见即所得GUI 工具大多呈现给我们的是他们想给我们呈现的，内部是黑盒的，而命令行工具，执行到哪一步，遇到什么错都可以一目了然。 你可以用在 GUI 工具中使用的命令，在命令行中都可以使用，反之则不然。 最重要的一点，你可以从命令行中获取帮助 123456789$ git remote -husage: git remote [-v | --verbose] or: git remote add [-t &lt;branch&gt;] [-m &lt;master&gt;] [-f] [--tags | --no-tags] [--mirror=&lt;fetch|push&gt;] &lt;name&gt; &lt;url&gt; or: git remote rename &lt;old&gt; &lt;new&gt; or: git remote remove &lt;name&gt; or: git remote set-head &lt;name&gt; (-a | --auto | -d | --delete | &lt;branch&gt;) or: git remote [-v | --verbose] show [-n] &lt;name&gt; or: git remote prune [-n | --dry-run] &lt;name&gt;...... 写在最后Git 和 Gerrit 一样，产生都有其历史必然性，Git 是在 “Linux 之父” Linus 在无法忍受集中式版本控制系统缺点的背景下被开发出来的，而 Gerrit 是 Google 为了合适的管理 Android 代码中来自世界成千上万开发者补丁合并而开发的权限控制系统，所以每个软件或者系统的开发都有其相应的背景，理解这些背景，可以让我们清晰的看到这些系统的设计者的用心良苦和深谋远虑，从而在认识或者使用这些系统或工具时，能够从更深的层次去看待问题。","link":"/2019/08/31/git_and_gerrit/"},{"title":"从零开始搭建Android源码调试环境","text":"写在开头最近在公司遇到的很多问题都是通过翻看 Android 源码来解决的，例如 竖向 ListView 和内嵌的横向 RecyclerView 的滑动冲突事件处理 弹框内嵌 ListView 之后，弹框定向高度的计算 处理 TextView 换行之后的文本所剩余的空白区域仍然可以点击的问题 …… 实际解决这些问题的过程中，单纯依靠看源码很难定位到问题，那么断点调试就成了最有效的方法。然而，在现实环境中，还面临着一个不可跨越的鸿沟，国内手机大多数都是基于 Android 源码进行了定制，这部分代码是不开源的，而我们日常调试都是基于 Android 的标准源码，那么，代码行数无法准确匹配就成了最大的问题，这就是我要做这件事情的初衷。 正文要解决这个问题，我们就需要一个运行开源 Android 系统的手机。毫无疑问，Nexus 和 Pixel 系列就是我们最好的选择 调试手机选择Android 源码截止发文之前已更新到 Android10 预览版，为了不至于太过时，我们就以最低可运行 Android8.1.0 作为基本条件 我们将目光限定在这几款机型上支持到 8.1.0 的手机有 Nexus 5X Nexus 6P Pixel C 支持到9.0的手机有（最新支持 10.0 系统） Pixel Pixel XL Pixel 2 Pixel 2 XL Pixel 3 Pixel 3 XL 毫无疑问，Pixel，是最具性价比的选择（可以去咸鱼淘一淘） 准备好手机之后，我们就需要开始搭建编译 Android 源码的环境 操作系统操作系统也是我们的考虑之一（当然这里说的操作系统是类 Unix 系统），毕竟我们主要的目的是翻看源码，调试源码，一个稳定好用美观简洁的操作系统会减少我们在前期准备上和后期使用上的成本。 一开始我选择了 Manjaro，后来放弃的原因是因为搜狗输入法的最新版总是安装不上去，不断崩溃，导致输入中文的体验极差，广搜无果，另外 Manjaro 的系统的美观度又不是很满足我的要求，自己定制又要花不少时间，实在折腾不动了。 后来又想到了黑苹果，Macos 在 Android 源码编译的支持上还不错，系统美观和软件适配程度也不在话下， 于是花了两天时间搞定了大多数的驱动，终于可以跑起来了，却因为贫穷再次放弃了，因为 Macos 只有在高分屏下显示效果才能最大发挥，家里台式机只有一个 1080p 的屏幕，安装完成之后字体发虚，长时间盯着屏幕会眼花，所以只能再次格掉硬盘 兜了这么一大圈，最终将目光投向 Ubuntu，上一次使用还是大学时代，在软件依赖处理上吃过不少苦头，不过我们这次的要求很简单，不会有乱七八糟的定制，只将目标聚焦于 Android 源码编译和日常软件。 时隔几年没想到 Ubuntu 变化挺快，流畅度和美观度都有所改观，以下是 Ubuntu 18.10 版本的截图 备注：各个平台制作镜像工具Windows 使用 UlrtraISO 制作镜像Mac 使用 Ethcer 制作镜像Linux 使用 Woeusb 制作 Windows 镜像，使用 dd 命令直接制作 Linux 镜像 基本软件 Jdk8：重要性不言而喻 搜狗输入法：必不可少，中文输入体验提升一大截 AndroidStudio：查看 Android 源码利器（只限于 Framework 层，Native 层推荐 SourceInsight） Visual Studio Code：查看一些非 Android 代码，全局搜索还是很给力的，管理工程目录也很方便 小书匠 Markdown 编辑器：很良心的一款软件，支持三平台，支持和印象笔记同步，我都是在这里写完文章同步到印象笔记中的，算是 Linux 下印象笔记的替代品吧 Terminator： 多分屏的终端，不同打开多个终端后找不到刚开始的任务在哪里了 StarUML：画类图和流程图的工具，也是三平台支持 搞定操作系统，搞定基本软件安装，接下来我们就开始下载 Android 源码和搭建源码编译环境 下载源代码我们先来下载源码，因为源码比较庞大，所以预先准备一下，整个过程可以参考 清华大学镜像站 提供的帮助文档。 整体来说，推荐使用压缩包的方式，下载过程异常会更少，速度也会更快 下载 repo1234mkdir ~/binPATH=~/bin:$PATHcurl https://storage.googleapis.com/git-repo-downloads/repo &gt; ~/bin/repochmod a+x ~/bin/repo 没有梯子时可以使用清华大学提供的 repo 12curl https://mirrors.tuna.tsinghua.edu.cn/git/git-repo &gt; ~/bin/repochmod a+x ~/bin/repo 备注：repo 必须运行在 python-2.7 的环境，可以使用 python virtual 的技术组建当前环境，实现 python-3 和 python-2 的自由切换 下载源码包1234567axel -n 10 https://mirrors.tuna.tsinghua.edu.cn/aosp-monthly/aosp-latest.tar # 下载初始化包tar xf aosp-latest.tarcd AOSP # 解压得到的 AOSP 工程目录# 这时 ls 的话什么也看不到，因为只有一个隐藏的 .repo 目录repo sync # 正常同步一遍即可得到完整目录# 或 repo sync -l 仅checkout代码 注意，以上代码会同步到 Android 源码的主分支的最新代码，如果想要单独切换到某个版本（或某个tag），执行以下操作 123cd AOSPrepo init -b android-8.1.0_r1 # 切换到 android-8.1.0_r1repo sync -c # 仅同步当前分支，减少占用硬盘空间 当然，也可以直接切换分支 1234cd AOSPcd .repo/manifestsgit checkout -b android-8.1.0_r1 origin/android-8.1.0_r1repo sync -c 备注：直接使用repo下载时，推荐使用北京大学开源镜像站下载，速度会快一点，下载过程会多次停止，可以使用脚本来处理继续下载，下载预计耗时 2 天 搭建 Android 源码编译环境我们这次安装的是 Ubuntu 18.10，所以直接安装以下软件即可： 1sudo apt-get install git-core gnupg flex bison gperf build-essential zip curl zlib1g-dev gcc-multilib g++-multilib libc6-dev-i386 lib32ncurses5-dev x11proto-core-dev libx11-dev lib32z-dev libgl1-mesa-dev libxml2-utils xsltproc unzip 也可以直接参考以下链接：Android 官方网站-搭建编译环境 准备编译因为 Android 源码中未携带相关设备的厂商私有代码（通常是二进制，不开源的），所以还需要在编译之前下载好指定机型，指定 Android 版本的厂商二进制文件。 在厂商二进制文件中找到对应机型，对应 Android 版本，下载完成后，在源码目录解压，然后运行每个压缩包中的可执行文件即可。 我们以 Pixel 手机，Android8.1.0 版本举例 打开厂商二进制文件，找到如下位置 下载完成拿到两个压缩文件之后，全部解压会得到两个可执行文件 然后打开源码根目录，分别执行可执行文件，会在 vendor 目录看到以下两个目录，表示执行完成 接下来就是熟悉的三连发，预计两小时，坐等编译完成 1234cd AOSPsource build/envsetup.shlunch aosp_sailfish-userdebugmake -j4 也可以参考以下链接Android 官方网站-准备编译 备注：https://developers.google.cn/android/blobs-preview 指向的是最新的厂商二进制文件，对应于 AOSP 上的 master 分支，如果直接使用这些文件编译旧 Android 版本，可能会导致无法开机 刷入自制 Rom如果你的手机之前没有刷过机，那么手机首先要 oem 解锁，才能使用 fastboot 命令，同样，使用 Pixel 为例 oem 解锁1234adb reboot bootloaderfastboot devicesfastboot oem unlockfastboot oem device-infos #(检查当前锁定状态） 刷机然后在编译完成的out目录下，使用 fastboot flashall 刷机即可，也可以单独刷某个系统镜像 调试系统源码要调试系统源码，我们需要将 aosp 源码导入 AndroidStudio 中，有一些技巧可以分享 生成索引首先，Android 源码提供了直接生成 ide 可识别的文件的工具，在编译完成 Android 源码之后 1234cd AOSPsource build/envsetup.shlunch aosp_sailfish-userdebugmmm ./development/tools/idegen 运行完成后就会在源码根目录生成一个 android.ipr ，这个文件是可以直接被 AndroidStudio 识别的，我们用 AndroidStudio 打开它，这个时候 AndroidStudio 会根据这个文件所生成的目录结构对所有文件做一个索引，这个索引会比较慢，请耐心等候 备注：固态硬盘相比普通的机械硬盘在生成索引上有巨大性能差异，可以择优而取 调整系统依赖项在生成完索引之后，我们要调整一下 AndroidStudio 监视源代码的目录，像如 out 这样的目录，每次编译完成都会产生变化，而我们又基本不会用到这个目录，所以直接去掉索引即可，当然你也可以选择其他不需要的目录做处理。以 out 目录为例，打开 File -&gt; Project Structure，将 out 目录 Excluded 掉即可 同样，为了减少 Android SDK中附带的源码和其他模块对我们自身源码的干扰 将 ModuleSDK 配置为 jdk1.8 而不是某个 sdk 版本，不然后续源码跳转，会很奇怪的跳到 sdk 源码中去然后将除 jdk 和 Module source 这两个模块以外的其他的模块都删除，我们统一使用 Android 自带源码索引跳转即可 备注：墙内如何愉快的下载 Android SDK 工具包谷歌在国内有服务器，用 ping.chinaz.com 解析出 dl.google.com 最快的 ip，加入到 hosts 中，即可直接满速下载 编译单独模块编译单独模块主要使用以下两个命令 mm 在当前模块目录下编译生效 mmm 指定某个模块的目录编译生效 例如之前的 1mmm ./development/tools/idegen 等效于 12cd ./development/tools/idegenmm 同理对于 framework 与 service 等模块，我们可以编译想要的 framework.jar，services.jar，ext.jar等核心包，然后 push 到手机的对应位置皆可实现源码调试。 写在后边从开始搭建到最后的搭建完成还是很耗时间的，大概花费了三周的时间，期间一直在加班，只能抽空周末搞一搞。在这三周的时间中，在各个系统切换花费了一大半时间，最后还是选择了 Ubuntu，不论是从 Android 官方还有 Sogou 官方支持来看，还是从开箱即用的理念上来讲，Ubuntu 确实是一个不错的选择。如果你还是学生，有大把的时间用来学习研究，那么类似 ArchLinux，Gentoo 都是很好的选择，安装的过程中都可以学到很多新的东西，如果你是一个上班族，那么 Ubuntu 是你最好的选择，可以省却很多系统配置的时间，将大部分精力用在学习专业的知识上，Android 已经不像当年那么火热，市场上缺少的是真正高精尖的人才，在某个方向上纵深发展，才是更好的选择。","link":"/2019/04/22/how-to-build-android-source-code/"},{"title":"如何通过 Mapping 文件反混淆","text":"写在前边做过 Android 开发的应该或多或少都知道“混淆”这个技术点，它不仅可以帮助我们增加三方逆向的难度，还可以有效减少包体积，瘦身 APK 其实这些能力都来自于 Proguard 这个程序，Proguard 能利用字典文件，在编译时将我们的类名，方法名，字段名都替换掉，最后生成一份非常反人类的编译产物。Proguard 在每次运行时都会创建一个 mapping.txt 文件，其中列出了经过混淆处理的类、方法和字段名称与原始名称的映射关系。此映射文件还包含用于将行号映射回原始源文件行号的信息 这篇文章的目的就是要解析生成的 Mapping 文件 正文Mapping 文件的来源与用途以下就是 Mapping 文件的生成过程 这个 Mapping 文件是由 Proguard 程序自动生成的，会存放在 output 目录下，与 release 包放在一起。需要谨记的是，Mapping 文件可能在每次 Proguard 运行后都会不同，所以发布给用户的包一定要留存好 Mapping 文件，方便后续跟踪解决问题 了解 Mapping 文件的好处了解 Mapping 文件最直观的好处在于我们跟踪线上的经过混淆之后的 Crash 信息时，可以从 Mapping 文件逆向推出原始的堆栈信息，更快更方便的定位问题，但不只这些，我们还可以通过 Mapping 文件处理内存快照文件 Hprof 的反混淆，处理 Systrace 的文件的反混淆，还有 Nanoscope 文件的反混淆等 如何解析 Mapping 文件 注意：Android 在新版中启用了 R8 编译器，没有使用 Proguard 工具，虽然兼容 Proguard 的配置和字典等，但是编译出来的 Mapping 文件格式还是有一点不同。我们会在最后一个小节讲一下其中的不同 下面我们详细来看 Mapping 文件的格式 123classline fieldline * methodline * Mapping 文件的正式部分由多个 Class 块组成，每个 Class 块中包含混淆前后的类信息，字段信息，方法信息。每个 Class 块由顶格的类信息开头，后边跟着开头带有4个空格的字段信息与方法信息每个 Class 块中详细格式如下： 类信息： 1originalclassname -&gt; obfuscatedclassname: 混淆之前的全限定类名与混淆后的全限定类名通过 -&gt; 分隔符分割，以 : 标识当前类信息的结束，标识类内字段，方法信息的开始 备注：全限定类名，是指带有包名限定的类名，可以完全定位一个类 字段信息： 1originalfieldtype originalfieldname -&gt; obfuscatedfieldname 混淆之前的字段信息与混淆之后的字段信息同样通过 -&gt; 分隔符分割，值得注意的是，混淆前的字段包含了字段类型和字段名称，而混淆之后只有字段名称 方法信息： 1[startline:endline:]originalreturntype [originalclassname.]originalmethodname(originalargumenttype,...)[:originalstartline[:originalendline]] -&gt; obfuscatedmethodname 备注：标识着 * 的行，意味着可能出现任意多次;[] 表示内容是可选的;… 表示可能会出现任意多个前边指定的item;:与，与-&gt;都是分隔符 方法信息同样通过 -&gt; 分隔符分割，但是方法信息比类信息和字段信息更复杂一点，因为方法还额外包含了行号表，参数，返回类型等信息 originalreturntype：原始返回类型，全限定类名，或者基本类型，或者无类型 void originalmethodname：原始方法名称 originalclassname：可选，当方法不属于所在的类块时，需要特别通过全限定类名引用 originalargumenttype：原始参数类型，全限定类名或者基本类型，多个参数按顺序通过 , 分割 obfuscatedmethodname：混淆后的名称 剩下的行号信息，稍微复杂一点要根据方法有没有做内联优化分成两种情况： 无内联优化： [startline:endline:]：和 Jvm 字节码中的 LineNumberTable 对应，表示原始代码的行号范围 [:originalstartline[:originalendline]]：无内联优化，这个字段不存在 有内联优化 [startline:endline:]：是一个编译器给出的一个类似于源码中的行号，为什么说类似于源码行号，我们后边通过示例来说明 [:originalstartline[:originalendline]]：这个字段中 originalendline 又是可选的，所以也分两种情况 [:originalstartline]：只有起始行号，表示这是异常的某个中间调用（？？？大问号？后边通过示例来说明吧，这里不好理解) [:originalstartline:originalendline]：有行号范围，表示在源码中的真实行号范围，对应源码的方法范围 有一些要注意的点： 方法的行号唯一标识了这个方法，这个在我们从堆栈中反推原始信息时特别有用 如果方法的行号没有存在，那么我们只能通过方法的签名（或者描述符）来反混淆代码，但是这种匹配不是绝对准确的，可能会出现匹配到多个相同的方法或字段 Mapping 示例分析简单示例123456com example.application.ArgumentWordReader -&gt; com.example.a.a: java.lang.String[] arguments -&gt; a int index -&gt; a 36:57:void &lt;init&gt;(java.lang.String[],java.io.File) -&gt; &lt;init&gt; 64:64:java.lang.String nextLine() -&gt; a 72:72:java.lang.String lineLocationDescription() -&gt; b com example.application.ArgumentWordReader 被混淆为 com.example.a.a ，其中字符 a 来源于混淆文件中所配置的字典文件字段 arguments 和 index 会在混淆中丢掉类型信息，同时转换为混淆字符 a 如果多个方法或者字段的签名（或者说描述符）不同，那么混淆之后的名称可能是相同的 方法的实例构造函数 &lt;init&gt; 和静态类构造函数 &lt;clinit&gt; ，名称不会被混淆，只会丢弃其参数列表和返回类型 方法 nextLine 和 lineLocationDescription 都有自己的源码行号范围，但是返回类型和参数列表是相同的，如果在混淆的配置文件中配置保留了 LineNumberTable，那么在报错堆栈中就可以看到行号，也就可以通过行号定位到具体的方法，而如果没有在混淆的配置文件中配置保留 LineNumberTable，那么报错堆栈中也就不会打印出行号，仅仅通过返回类型和参数列表是无法区分二者的，所以这就是为什么这两个方法的混淆之后的名称是不同的 以上的示例比较简单，我们来看一下复杂的示例 复杂示例12345678910111213com.example.application.Main -&gt; com.example.application.Main: com.example.application.Configuration configuration -&gt; a 50:66:void &lt;init&gt;(com.example.application.Configuration) -&gt; &lt;init&gt; 74:228:void execute() -&gt; a 2039:2056:void com.example.application.GPL.check():39:56 -&gt; a 2039:2056:void execute():76 -&gt; a 2236:2252:void printConfiguration():236:252 -&gt; a 2236:2252:void execute():80 -&gt; a 3040:3042:java.io.PrintWriter com.example.application.util.PrintWriterUtil.createPrintWriterOut(java.io.File):40:42 -&gt; a 3040:3042:void printConfiguration():243 -&gt; a 3040:3042:void execute():80 -&gt; a 3260:3268:void readInput():260:268 -&gt; a 3260:3268:void execute():97 -&gt; a com.example.application.Main 类配置了 keep 属性，所以类信息没有被混淆掉，一般我们会把可能需要被反射使用的类保留，防止在 release 包中类名变化导致混淆使用出错 configuration 字段信息同上，混淆后丢弃类型实例构造函数 &lt;init&gt; 和方法 execute 同上解析方式 剩下的方法都比较奇怪，开头的行号都是特别大的数字，且有几个方法行号是相同的，明显不是正常的行号，这是因为经过了方法内联处理，在混淆处理的过程中，可能会内联方法到其他方法中，甚至进行递归的内联 方法内联简单来说，就是将互相调用的多个方法合并为一个方法，这样减少程序方法调用的次数，从而减少程序调用过程中的栈帧的创建销毁等额外的消耗，提升性能例如 123456789class A: def a(): print(&quot;a&quot;) B.b()class B: def b(): print(&quot;from B&quot;) print(&quot;b&quot;) 做方法内联优化之后： 12345class A: def a(): print(&quot;a&quot;) print(&quot;from B&quot;) print(&quot;b&quot;) // inner line from B() 了解了方法内联之后，我们再来看方法内联对混淆的影响，方法内联之后，堆栈中原来 B.b() 方法已经被内联到 A.a() 方法中，混淆之后的方法信息也自然指向了 A.a()，那么堆栈中出现的错误信息也是指向 A.a()，但是我们源码中的调用是来自方法 B.b() 的，所以内联前后的优化信息我们是需要知道的，方便在后续堆栈信息追踪时反推源码信息。 下边我们就看一下具体的解析方法 122039:2056:void com.example.application.GPL.check():39:56 -&gt; a2039:2056:void execute():76 -&gt; a 方法最前边的行号范围如果相同，就代表一个内联链中的方法调用链，比如以上两句表示，方法 check 被内联到了 execute 方法中，内联的位置是原 execute 方法的第76行，如果末尾是行号范围，那么对应的就是最终的内联方法体 开头的行号是内联函数调用链最底层的行号范围和编译器给予的一定的偏移量加和的结果，偏移量是1000的倍数，偏移量的目的是避免与其他的正常的代码范围产生冲突，所以2039：2056是来自 check 方法的源码行号范围 39:56 与 2000 的偏移量相加得出的结果 另外，因为 check 方法因为不属于类 com.example.application.Main，所以使用了类全限定符标识，标明 check 所处的类 123452236:2252:void printConfiguration():236:252 -&gt; a2236:2252:void execute():80 -&gt; a3040:3042:java.io.PrintWriter com.example.application.util.PrintWriterUtil.createPrintWriterOut(java.io.File):40:42 -&gt; a3040:3042:void printConfiguration():243 -&gt; a3040:3042:void execute():80 -&gt; a 以上 Mapping 文件的分析方法和之前的一致，唯一需要说明的是这其中的关联execute 方法在80行内联了方法 printConfiguration，后者的行号范围是 236:252，其中，printConfiguration 又在 243 行内联了方法 createPrintWriterOut，后者的行号范围是 40:42。 至此，我们分析完了 Mapping 文件的所有情况的格式，最后的两行交由读者自己尝试分析一下。 R8 编译器当使用 Android Gradle 插件 3.4.0 或更高版本构建项目时，该插件不再使用 ProGuard 来执行编译时代码优化，而是与 R8 编译器协同工作来处理编译时任务，所以可以通过 Gradle 插件版本来查看具体使用了 Proguard 还是 R8 编译器。 R8 编译器一定程度上兼容 Proguard 规则，但是还是略有不同。 详情可以参看官网：https://developer.android.com/studio/build/shrink-code?hl=zh-cn 注释Mapping 文件以 # 开头的行作为注释，标识 R8 程序的格式，日期等信息，但是在 Proguard 中还未发现这样的规范 例如以下： 12345# compiler: R8# compiler_version: 1.6.82# min_api: 19# pg_map_id: 6af58cc# common_typos_disable 与 Proguard 区别R8 中的行号的表示方式和 Proguard 还不太一样，以下的解析方式是基于 Proguard 新版的规范和源码相印证的结果，在 R8 的官方文档中，是直接导向 Proguard 官网的，并没有自己的格式的说明（这点在 Hprof 格式也是），所以有谁找到对应的官方文档，可以帮忙附到评论中，感谢。 12345678910androidx.appcompat.app.AppCompatActivity -&gt; androidx.appcompat.app.AppCompatActivity: 1:1:void &lt;init&gt;():77:77 -&gt; &lt;init&gt; 2:2:void &lt;init&gt;(int):92:92 -&gt; &lt;init&gt; 1:1:void addContentView(android.view.View,android.view.ViewGroup$LayoutParams):176:176 -&gt; addContentView 1:2:void attachBaseContext(android.content.Context):97:98 -&gt; attachBaseContext 1:4:void closeOptionsMenu():609:612 -&gt; closeOptionsMenu 1:2:boolean dispatchKeyEvent(android.view.KeyEvent):552:553 -&gt; dispatchKeyEvent 3:3:boolean dispatchKeyEvent(android.view.KeyEvent):555:555 -&gt; dispatchKeyEvent 4:4:boolean dispatchKeyEvent(android.view.KeyEvent):558:558 -&gt; dispatchKeyEvent 1:1:android.view.View findViewById(int):214:214 -&gt; findViewById 这是一个 R8 编译完成的 Mapping 文件示例，因为都使用了 keep 属性，所以没有被混淆之后名称没有被字典中的字符替换掉，但这点对于分析 Mapping 格式没有什么影响。 和 Proguard 规范有所不同的是： 许多方法并没有用一个连续的行号范围标识，而是被拆分成了不同的子块，每个子块都有自身对应的行号范围，方法前边的是虚拟行号，对应后边的真实行号范围 例如： 123456781:1:void &lt;init&gt;():77:77 -&gt; &lt;init&gt;2:2:void &lt;init&gt;(int):92:92 -&gt; &lt;init&gt;......1:2:boolean dispatchKeyEvent(android.view.KeyEvent):552:553 -&gt; dispatchKeyEvent3:3:boolean dispatchKeyEvent(android.view.KeyEvent):555:555 -&gt; dispatchKeyEvent4:4:boolean dispatchKeyEvent(android.view.KeyEvent):558:558 -&gt; dispatchKeyEvent 各个方法的虚拟行号的范围是有所重叠的，但是所对应的混淆之后的名称是不同的，所以在区分不同方法上来说是没有歧义的 例如： 121:2:void attachBaseContext(android.content.Context):97:98 -&gt; attachBaseContext1:4:void closeOptionsMenu():609:612 -&gt; closeOptionsMenu 虚拟行号范围重叠了，但实际的行号范围是不一样的，而且混淆后的名称也是不同的 R8 编译出的文件中并未找到内联方法相关的编译优化，不确定是没有开对应的优化项还是说根本就没有这项优化，所以不会出现 Proguard 之前的内联相关的调用栈的 Mapping 信息 后记基于以上的 Mapping 文件的解析规则，我们可以做很多事情，比如反混淆 Trace 文件，反混淆 Nanoscope 文件，反混淆 Hprof 文件等等，我基于这个规则，开发了一个 ReProguard 的程序，可以供大家参考，欢迎交流提意见 项目地址：https://github.com/0xforee/ReProguard 如果后续有时间，我会基于收集的资料写一个 Hprof 文件格式的解析教程，欢迎评论交流。^_^","link":"/2020/06/07/how-to-reproguard-by-mapping/"},{"title":"一文帮你快速理解协程使用模型","text":"A coroutine is an instance of suspendable computation. It is conceptually similar to a thread, in the sense that it takes a block of code to run that works concurrently with the rest of the code. However, a coroutine is not bound to any particular thread. It may suspend its execution in one thread and resume in another one. 以上这段话出自官网。介绍协程的基本概念和一些特性。 其中提到了可挂起，计算实例，线程相似性，代码块，并行，不绑定特定线程，在一个线程挂起在另一个线程恢复等关键字。 我们今天就围绕这些基本概念和关键字来探索一下协程的使用模型 请放心，本文没有晦涩难懂的源码解析，也没有深奥的概念，只有大量的类比帮你快速理解协程。 正文简单示例这大概是最简单的协程示例了。 123GlobalScope.launch{ print(&quot;hello coroutine&quot;) } 案例 1 你可以将它加入到任意的 kotlin 代码中运行看看。 这段代码将 print 传递给了 Scope 的 launch 方法，标志着启动了一个协程来运行。那为什么使用协程要通过这样的调用方式呢？ 要解答以上这个问题，就涉及到我们要讲的第一个概念 Scope 什么是 Scope？Scope 是用来区分协程和非协程的作用域。 那为什么要加 Scope 呢？不加不行吗？就像我们平常写代码那样，就不需要加任何东西呀。 那是因为我们平常写的代码，都是跑在线程上的，不用加任何作用域限定，也会跑在一个特殊的线程（主线程）中。线程是操作系统层级的概念，任意的代码函数都会运行在线程上，所以我们可以不用加任何限定作用域。 而协程不行，协程是语言层级的概念，无法做到像线程那样成为所有函数的运行基础，所以我们需要在语言层面标识哪些是跑在协程的，哪些不是。 而 Scope 的作用就是用来标识和限定哪些代码跑在协程中。 协程框架提供了一些方式，可以快速的帮我们创建好 Scope，来包裹我们要跑在协程上的那些代码块。官方称之为 Scope Builder。 常用的 Scope Builder 有这些 1234runBlocking{} GlobalScope{} coroutineScope{} withContext{} 如果你在代码遇到这些关键字，就可以知道这里有一个协程了。 注意，默认情况下，定义好一个 Scope 后，协程框架会启动协程来执行代码块，你可以通过参数控制这种默认行为。 另外，IDE 也会在有 Scope 的地方提示你： 图中的那个灰色的提示： this:CoroutineScope 标识了当前有个 Scope 存在。 上边我们也提到，协程并没有突破线程这一束缚，还是运行在线程上的，但同时协程却又被称为轻量级线程，这又是为什么呢？ 我们先来看看操作系统是怎么定义和描述线程的。 内核线程 or 用户线程操作系统为了系统安全，将程序运行的位置简单的分为了内核空间和用户空间，内核程序在内核空间中运行，用户程序在用户空间中运行，二者互不影响，通过系统调用来切换空间。 内核线程：指的是内核空间内的线程实体，是内核可以感知，操作系统调度的基本单位用户线程：指的是用户空间内对应内核线程的实体，内核无法感知，用户程序可以通过这些实体来间接控制内核线程。 操作系统关于线程实现历史中，涌现了三种模型： 1:1（一个用户线程对应一个内核线程） M:1（多个用户线程对应一个内核线程） M:N（多个用户线程对应多个内核线程） 线程实现模型 1:1 示意图（来源网络） 线程实现模型 M:N 示意图（来源网络） 之所以出现这几种调度模型，是因为内核线程的使用是有一定成本的，每次切换线程都要切换线程上下文和保存寄存器状态，切换 CPU 上下文等。如果我们实现了在用户空间切换线程，可以省略和缩短 CPU 和内核空间切换上下文的开销。 既然有这种好处，为什么我们不使用这种模型呢？因为越是灵活的调度对应的是越复杂的实现。Linux 线程的实现模型已经踩过这个坑了，从最开始的 1:1 模型切换到 M:N 模型，最后又切换到 1:1 模型，就是因为实现太过复杂，导致效率反而下降。 有兴趣的可以参考这些文章： https://www.linuxidc.com/Linux/2016-01/127559.htm https://zh.wikipedia.org/wiki/Native_POSIX_Thread_Library 回过头来，协程其实和这种用户线程的实现理念是一样的。目的就是为了减少内核级上下文的切换导致的开销，提升效率。当然，协程还是跑在线程上的，完全不需要系统内核的参与调度，所以它比用户级线程还要更轻量一点，这也是它被称作轻量级线程的原因。 接下来我们就来看看协程是如何运行在线程上的。 协程运行在线程上协程跑在线程上，我们可以类比为 Runnable 运行在线程上。 我们之前说过，协程类似于线程用户态模型， 代码块的调度都是发生在用户态的，是通过程序实现的。在 Android 中有一个很著名的线程通信框架，也是通过程序实现代码块的调度的。 Handler 没错，就是我们耳熟能详的 Handler Handler 内部实现了一个消息队列 MessageQueue，Handler 会不断的从这个 MessageQueue 中获取消息，然后在对应的线程上执行。 而协程执行的过程，其实和消息队列差不多。 比如以下的协程执行 123GlobalScope.launch{ print(&quot;hello coroutine&quot;) } 可以类比到 Handler 中 1234// 发送普通 Handler 消息 handler.post{ print(&quot;hello coroutine&quot;)} 案例 2 所以我们也可以将协程称之为一个任务调度框架。 但协程和 Handler 的不同点就在于协程底层并不是运行在某个线程上的，而是可能在多个线程上。既然可能是多个线程，那么协程怎么知道我哪些代码要运行在 A 线程，哪些代码要运行在 B 线程呢？换句话说，他是怎么调度的呢？什么时候会调度呢？ 这就涉及到协程的另一个关键字 suspend Suspend 做了什么？我们将案例 2 扩展一下，思考这么一段代码 123456789// 发送普通Handler 的延迟消息handler.post{ print(&quot;hello coroutine&quot;)}handler.postDelayed( { print(&quot;hello world&quot;) },300) 然后我们看看协程的实现： 123456// 等价于协程GlobalScope.launch{ print(&quot;hello coroutine&quot;) delay(300) print(&quot;hello world&quot;)} 案例 3 其中的 delay 是一个 suspend 函数。源码如下： 其中 suspend 是表示挂起的意思。那么这个挂起函数起到了什么作用呢？ 我们知道，指定某个线程执行一段代码块，会有两个结果： 代码块中包含普通的代码，代码内容被全部执行完成，线程结束。 代码块中包含阻塞线程的代码，线程在这个阻塞点上挂起，直到线程被重新唤醒继续执行，线程结束。在线程阻塞期间，线程无法再执行其他代码。 而协程中并没有提供阻塞能力，取而代之的是挂起。挂起是指在某个线程上执行的协程被停止调度，协程框架转而去调度其他协程到这个线程上执行，这样就避免了线程的切换，从而提升当前线程的使用率。 那么，有 suspend 就一定会被挂起吗？当然不是，带 suspend 关键字的函数被称为挂起函数。挂起函数仅仅标识当前函数内可能有挂起点，协程真正会挂起的位置被称为挂起点。 我们将协程可以执行的代码块分为两种：普通函数（普通代码块）和挂起函数（有挂起点的代码块）普通函数：就是指一段串行的代码，如果开始执行，就一定会被在当前线程上顺序执行完毕。挂起函数：包含了普通代码块和可能穿插的挂起点。普通代码块如上规则，而挂起点就是指以下关键字 1delay(time), await 等 遇到挂起点，协程就会在这个点上挂起，这时其他满足条件的协程就会被调度到这个协程底层的线程上继续执行。直到当前协程恢复的条件满足，才会被继续调度执行。 我们用一个实际的例子来看看，协程和线程中阻塞和挂起的区别 线程： 1234567Thread{ println(&quot;${Date().time}: ${Thread.currentThread().name} hello&quot;) Thread.sleep(1400) println(&quot;${Date().time}: ${Thread.currentThread().name} world&quot;) println(&quot;${Date().time}: ${Thread.currentThread().name} an &quot;) println(&quot;${Date().time}: ${Thread.currentThread().name} another&quot;)}.start() 协程： 这段代码是启动了三个协程，并让他们都在同一个线程上调度 注意：这里将调度器指向了一个单线程池。 12345678910111213141516val dispatcher = Executors.newSingleThreadExecutor().asCoroutineDispatcher()runBlocking { CoroutineScope(dispatcher).launch{ println(&quot;${Date().time}: ${Thread.currentThread().name} hello&quot;) delay(1400) println(&quot;${Date().time}: ${Thread.currentThread().name} world&quot;) } CoroutineScope(dispatcher).launch{ println(&quot;${Date().time}: ${Thread.currentThread().name} an &quot;) } CoroutineScope(dispatcher).launch{ println(&quot;${Date().time}: ${Thread.currentThread().name} another&quot;) }} 我们停下来先思考一下他们的输出分别是什么？ 线程输出结果： 12341690337539395: Thread-0 hello1690337540800: Thread-0 world1690337540800: Thread-0 an 1690337540800: Thread-0 another 协程的输出结果： VM options 设置-Dkotlinx.coroutines.debug=on 即可开启协程名称 12341690337474719: pool-1-thread-1 @coroutine#2 hello1690337474725: pool-1-thread-1 @coroutine#3 an 1690337474725: pool-1-thread-1 @coroutine#4 another1690337476132: pool-1-thread-1 @coroutine#2 world 从线程的输出结果中，我们可以看到，整个线程 Thread-0 被 Thread.sleep() 这行代码阻塞，无法继续往下执行，直到1.4s 后被唤醒了才继续往下执行 而协程就不一样了，2 号协程因为 delay 而挂起，但是并没有阻塞他所在的 Thread-1，协程框架会继续调度其他可执行的协程跑在 Thread-1 上，所以我们可以看到紧接着 3，4 号协程被调度执行。delay 1.4s 后，2 号协程被唤醒，继续往下执行。 动图展示 有些人可能还会有一个疑问，挂起操作会导致协程先执行到后边的代码吗？比如上边的代码中，协程 2 号挂起之后，“world”的输出会被调度到其他线程上，从而比 “an” 或者 ”another” 先输出吗？ 答案是不会的。 同一个协程内会遵循 先行发生原则 学过线程（Thread）的肯定了解这个概念。其中有一条： 程序次序规则（Program Order Rule）：在一个线程内，按照控制流顺序，书写在前面的操作先行发生于书写在后面的操作。 简单来说就是单个线程内部代码是串行的，控制流前边的代码会先行发生于后边的代码。而协程也有这样的规则，同一个协程内会遵循先行发生原则，即输出 world 之前，协程 2 号会被 delay 挂起暂停执行。上边的例子我们解释了协程挂起这个特性究竟是怎么回事，下边我们再看看协程在面对多线程调度时的另一个特性。 我们将协程代码稍微修改一下，并且让他调度在多线程池上呢？代码执行结果会有什么不同吗？ 1234567891011121314val dispatcher = Dispatchers.IO // 替换为多线程调度器runBlocking { CoroutineScope(dispatcher).launch{ println(&quot;${Date().time}: ${Thread.currentThread().name} hello&quot;) delay(1400) println(&quot;${Date().time}: ${Thread.currentThread().name} world&quot;) } CoroutineScope(dispatcher).launch{ delay(300) // 注意这里也有一个 delay 挂起 println(&quot;${Date().time}: ${Thread.currentThread().name} an&quot;) println(&quot;${Date().time}: ${Thread.currentThread().name} another&quot;) }} 我们运行以上代码，输出 1： 12341690338849816: DefaultDispatcher-worker-2 @coroutine#2 hello1690338850124: DefaultDispatcher-worker-1 @coroutine#3 an1690338850124: DefaultDispatcher-worker-1 @coroutine#3 another1690338851224: DefaultDispatcher-worker-1 @coroutine#2 world 我们再运行一遍呢 输出 2： 12341690338877016: DefaultDispatcher-worker-1 @coroutine#2 hello1690338877327: DefaultDispatcher-worker-1 @coroutine#3 an1690338877327: DefaultDispatcher-worker-1 @coroutine#3 another1690338878425: DefaultDispatcher-worker-1 @coroutine#2 world 我们会发现字符串输出顺序一致，但是指向的线程却不一样了。 输出 1：2 号协程在 2 号线程上输出 hello 之后挂起，然后在 1 号线程恢复执行，输出 world输出 2：2 号协程在 1 号线程上输出 hello 之后挂起，然后在 1 号线程恢复执行，输出 world 这说明：同一个协程并不一定总是会被调度在同一个线程上的。但它依然会保证协程内部的先行发生原则。 那么官网中提到的协程可能会在一个线程上挂起，在另一个线上上恢复的特性我们也就清楚了。了解了挂起这个神奇的操作之后，我们再来拓展一下，看看挂起函数和普通函数的一些使用说明。 挂起函数不能被普通函数调用挂起函数是指包含挂起点，拥有挂起能力的函数。但是挂起这个特性属于是 kt 新增的黑魔法，普通的函数无法正确被协程框架所识别和使用挂起能力。所以挂起函数不能被普通函数调用，不然遇到挂起点，就无能无力了。 所以挂起函数只能在协程作用域中使用，也就是我们上边提到的 Scope 中。在这个 Scope 中，可以识别和理解协程的挂起能力，挂起函数就可以按照我们预期的正常工作。 挂起函数只能被挂起函数调用上边我们说过，挂起函数只能在协程作用域中使用，因为函数嵌套的特点，自然可以推导出挂起函数只能被挂起函数调用了。 我们如果误在普通函数中调用挂起函数的话，AndroidStudio 会贴心的提示我们以上内容。 挂起函数可以调用普通函数这个也很好理解，因为我们上边说了，挂起函数其实是包含了普通代码块和一些穿插的挂起点。普通函数就是包裹普通代码块的函数，挂起函数自然是可以调用普通函数了。 挂起函数可以只包含普通代码，不包含挂起点可以，但没必要，编辑器会提示我们 suspend 是多余的。 123suspend fun test(){ print(&quot;hello coroutine&quot;)} 如上，编辑器会提示我们 总结一下，suspend（挂起） 是一个协程的机制，同时也是一个关键字。作为机制来说，它指明的是和线程阻塞相区别的挂起能力。作为关键字来说，它用来标识那些可以被挂起的函数，那些有挂起点的函数。换句话说，是标识那些只能在协程作用域内调用的函数。 这个 suspend 关键字以方便提示我们这些是协程的作用域，一方面也是告诉框架这些代码是要被运行在协程上的。这就是 suspend 的作用。 接下来我们看下协程另一个之前已经在示例代码中出现过的关键字 Dispatcher。 DispatcherDispatcher 中文翻译过来就是调度器， 它是协程框架提供的让我们指定协程运行在哪个（或者哪些）线程上的指示类。 我们上边已经用到过两个调度器。其中 Dispatcher.IO 就是线程框架默认提供给我们的四个调度器之一。协程框架总共提供了四个默认的调度器给我们使用： Default：协程框架默认使用的调度器。如果调用协程时未指定任何调度器就会使用这个。内部使用一个公共共享的线程池，官方推荐我们可以用这个调度器来做一些耗费 CPU 的，计算密集的任务。IO：从名称我们就能看出来，这是是用来处理 IO（例如文件 IO 和阻塞式 socketIO）的一个调度器。内部使用一个按需创建的线程池。Main：主线程，在不同平台上都会指代主线程，用来操作一些 UI 相关的内容UnConfined：这个调度器和上边的不太一样，它启动执行的线程和 suspend 回来之后的线程是不一样的。这个调度器会在当前的线程启动执行，直到遇到第一个挂起点。，然后这个挂起会在任意的不会特别指定的（UnConfined）线程上恢复。官方不推荐我们用在正常的场景中，除非你真的明白你需要这个特性。 除此之外呢，当然也可以自定义调度器，比如我们上边案例中使用到的单线程调度器，就是 Executor 转过来的。你可以使用 ExecutorService 中的 asCoroutineDispathcer 这个拓展函数来将任意的 Executor 转义过来，非常方便 当然官方也非常贴心的提供了两个默认的从 Executor 转来的调度器，你可以通过 newSingleThreadContext 和 newFixedThreadPoolContext 这两个关键字来调用。 接下来，我们来看协程最后的一个关键特性，结构化协程 Structured Coroutine协程内是可以启动无数个协程的，就像线程内可以启动无数个线程一样。不同点在与，线程内启动的线程和原有的线程并没有什么关联关系，他们是平级的。而协程多了一个结构化的概念（structured coroutine)，协程内启动的协程被称为子协程。 区分了父子关系后，可以有以下好处： 父协程会等所有的子协程结束才会结束。 父协程可以管理所有的子协程，可以启动和取消子协程 （这么看，更像一个任务调度器了） 结束语探索完以上的内容，我们对协程的关键特性都已经有了一个初步的概念。我们发现，各种特性其实并不陌生，都和我们其他的概念有或多多少的关联，我们也会发现其实： 协程就是一个有语言关键字支持的运行在线程池上的任务调度框架。 这个调度框架可以让你更加便捷的进行多线程编程，避免进行复杂的线程切换和调度管理，从而专注于业务开发。仅此而已。 当然，如果你想要使用好协程，仅仅了解这些基础的概念还是不够的，我们还需要更多的练习，协程的使用才能游刃有余。","link":"/2023/08/01/how-to-use-kotlin-coroutine/"},{"title":"invalidate 三部曲之历经 Choreographer","text":"Choreographer，编舞者。 Choreographyer 三部曲 invalidate 三部曲序 invalidate 三部曲之始于 invalidate invalidate 三部曲之历经 Choreographer 12345678910111213void scheduleTraversals() { if (!mTraversalScheduled) { mTraversalScheduled = true; mTraversalBarrier = mHandler.getLooper().getQueue().postSyncBarrier(); mChoreographer.postCallback( Choreographer.CALLBACK_TRAVERSAL, mTraversalRunnable, null); if (!mUnbufferedInputDispatch) { scheduleConsumeBatchedInput(); } notifyRendererOfFramePending(); pokeDrawLockIfNeeded(); }} 上一期讲到了这里，也就是scheduleTraversals()真正核心的内容，只是加入了 Choreographer 的回调队列。那么这个回调队列是怎么一回事？invalidate()之后不是触发 View 刷新了吗？加入回调队列和这个有什么关系？ 这一篇文章，我们就来深入了解 Choreographer 这个类。 写在前边Choreographer 负责连接 VSYNC 信号和 framework 层绘制。 从这篇文章为什么是 VSYNC 我们知道， VSYNC 信号是一种刷新机制，会根据显示器的频率定时触发，通知CPU处理下一帧的绘制准备工作。 另一方面，Android 显示系统是由 Window 及其内部的 View 构成，显示的内容需要各个 Window 控件自己定义绘制，那么显示系统什么时候该去处理绘制的工作呢？当然最合适的时机是 VSYNC 信号触发，而 Choreographer 就是这二者之间的中介。显示系统想要更新内容的时候，就通过 Choreographer 注册一个回调，等 VSYNC 信号来临时，就做一次更新，然后继续注册回调监听下一次，直到没有需要更新的内容。 另外，Android 为了系统的流畅度，又对绘制的内容分类，优先响应输入事件，然后是动画，接下来才是绘制，最后做一些收尾工作，这个绘制内容的分类就体现在内部维护的 4 个回调队列中，等 VSYNC 事件来临，按序响应。 整个 Choreographer 就做了这么多事情，接下来我们按事件流顺序讨论 全部流程请参考序中的时序图：invalidate 三部曲序 从 scheduleTraversals() 开始讲起scheduleTraversals() 会调用 postCallBack() 1234567891011121314151617181920212223242526272829303132333435363738394041/** * Posts a callback to run on the next frame. * &lt;p&gt; * The callback runs once then is automatically removed. * &lt;/p&gt; * * @param callbackType The callback type. * @param action The callback action to run during the next frame. * @param token The callback token, or null if none. * * @see #removeCallbacks * @hide */public void postCallback(int callbackType, Runnable action, Object token) { postCallbackDelayed(callbackType, action, token, 0);}public void postCallbackDelayed(int callbackType, Runnable action, Object token, long delayMillis) { ...... postCallbackDelayedInternal(callbackType, action, token, delayMillis);}private void postCallbackDelayedInternal(int callbackType, Object action, Object token, long delayMillis) { ...... synchronized (mLock) { final long now = SystemClock.uptimeMillis(); final long dueTime = now + delayMillis; mCallbackQueues[callbackType].addCallbackLocked(dueTime, action, token); if (dueTime &lt;= now) { scheduleFrameLocked(now); } else { Message msg = mHandler.obtainMessage(MSG_DO_SCHEDULE_CALLBACK, action); msg.arg1 = callbackType; msg.setAsynchronous(true); mHandler.sendMessageAtTime(msg, dueTime); } }} 这里最后会将 Runnable 类型的 action 加入到 callbackType 所属队列，callbackType 的值为 CALLBACK_TRAVERSAL。 Choreographer 总共定义了四个类型的回调队列 CallbackQueue，单向列表，在 Choreographer 初始化的时候就构造好了，然后会根据优先级来处理这四个回调队列中的内容，我们后续详解。 然后如果请求执行时间超过当前系统时间，会立即触发，否则通过 hanlder 延时触发 注册回调123456789101112131415161718192021222324252627282930313233343536373839404142434445private void scheduleFrameLocked(long now) { if (!mFrameScheduled) { mFrameScheduled = true; if (USE_VSYNC) { // 如果使用vsync if (DEBUG_FRAMES) { Log.d(TAG, &quot;Scheduling next frame on vsync.&quot;); } // If running on the Looper thread, then schedule the vsync immediately, // otherwise post a message to schedule the vsync from the UI thread // as soon as possible. if (isRunningOnLooperThreadLocked()) { scheduleVsyncLocked(); } else { Message msg = mHandler.obtainMessage(MSG_DO_SCHEDULE_VSYNC); msg.setAsynchronous(true); mHandler.sendMessageAtFrontOfQueue(msg); } } else { // 不使用VSYNC，那么用自定义的定时操作触发，可用于调试 final long nextFrameTime = Math.max( mLastFrameTimeNanos / TimeUtils.NANOS_PER_MS + sFrameDelay, now); if (DEBUG_FRAMES) { Log.d(TAG, &quot;Scheduling next frame in &quot; + (nextFrameTime - now) + &quot; ms.&quot;); } Message msg = mHandler.obtainMessage(MSG_DO_FRAME); msg.setAsynchronous(true); mHandler.sendMessageAtTime(msg, nextFrameTime); } }}private void scheduleVsyncLocked() { mDisplayEventReceiver.scheduleVsync(); // 注册一个VSYNC监听者}/** * Schedules a single vertical sync pulse to be delivered when the next * display frame begins. */public void scheduleVsync() { ...... nativeScheduleVsync(mReceiverPtr); } 立即触发的内容主要是使用本地方法去注册了一个回调，当然如果之前注册过了，这里什么都不会做。另外这里也提供了 USE_VSYNC 变量决定是通过 VSYNC 触发，还是使用 Handler 定时触发，方便调试 有注册当然就有回调，在 DisplayEventReceiver 这个类中，我们找到了从 native 回调回来的方法 12345// Called from native code.@SuppressWarnings(&quot;unused&quot;)private void dispatchVsync(long timestampNanos, int builtInDisplayId, int frame) { onVsync(timestampNanos, builtInDisplayId, frame);} onVsync 方法的具体实现是在子类中，传说中的模板方法设计模式，DisplayEventReceiver 只有一个实现类 FrameDisplayEventReceiver 接收回调1234567891011121314151617181920212223242526272829303132333435private final class FrameDisplayEventReceiver extends DisplayEventReceiver implements Runnable { private boolean mHavePendingVsync; private long mTimestampNanos; private int mFrame; public FrameDisplayEventReceiver(Looper looper, int vsyncSource) { super(looper, vsyncSource); } @Override public void onVsync(long timestampNanos, int builtInDisplayId, int frame) { // vsync信号发生时回调 ...... // Post the vsync event to the Handler. // The idea is to prevent incoming vsync events from completely starving // the message queue. If there are no messages in the queue with timestamps // earlier than the frame time, then the vsync event will be processed immediately. // Otherwise, messages that predate the vsync event will be handled first. // 使用Handler来保证vsync信号依次按序执行，防止因为vsync信号，导致整个队列饿死， // 两个问题：1. 为啥要用Handler？而不是直接调用执行 // 2. prevent这句是什么意思？ ...... Message msg = Message.obtain(mHandler, this); msg.setAsynchronous(true); mHandler.sendMessageAtTime(msg, timestampNanos / TimeUtils.NANOS_PER_MS); } @Override public void run() { mHavePendingVsync = false; doFrame(mTimestampNanos, mFrame); }} 这里通过 Handler 的方式将自己发送出去执行 doFrame()，而不是通过直接调用的方式，主要是为了解决不同线程中的同步问题，这里是通过 Message 的 setAsynchronous() 方法实现。有时间会通过解析 Handler 机制来分析这个方法。 doFrame兜兜转转，终于来到我们今天的主角。如果你使用 systrace 分析过 Android 性能问题，那么你一定不会对这个函数感到陌生，这就是整个 input, animation, measure, layout, draw 的源头。 12345678910111213141516171819202122232425262728void doFrame(long frameTimeNanos, int frame) { ...... doCallbacks(Choreographer.CALLBACK_INPUT, frameTimeNanos); ...... doCallbacks(Choreographer.CALLBACK_ANIMATION, frameTimeNanos); ...... doCallbacks(Choreographer.CALLBACK_TRAVERSAL, frameTimeNanos); doCallbacks(Choreographer.CALLBACK_COMMIT, frameTimeNanos); ......}void doCallbacks(int callbackType, long frameTimeNanos) { CallbackRecord callbacks; ...... for (CallbackRecord c = callbacks; c != null; c = c.next) { if (DEBUG_FRAMES) { Log.d(TAG, &quot;RunCallback: type=&quot; + callbackType + &quot;, action=&quot; + c.action + &quot;, token=&quot; + c.token + &quot;, latencyMillis=&quot; + (SystemClock.uptimeMillis() - c.dueTime)); } c.run(frameTimeNanos); } ......} 这四个 doCallbacks 所做的就是处理之前我们通过 postCallback() 传入的回调，这里会根据不同的类型，按序处理，通过这段代码，我们可以看到执行的优先级是 CALLBACK_INPUT，输入事件 CALLBACK_ANIMATION，动画 CALLBACK_TRAVERSAL，绘制 CALLBACK_COMMIT，收尾处理 也就是我们文章开头所说的绘制类型。 结束还记得我们调用 invalidate() 加入的回调吗？在这里 1234567final TraversalRunnable mTraversalRunnable = new TraversalRunnable();final class TraversalRunnable implements Runnable { @Override public void run() { doTraversal(); }} 这个回调是 ViewRootImpl 自己定义的，也就是说 Choreographyer 只是帮忙居中协调，规范了 ViewRootImpl 的执行时间罢了，具体的内容还需要靠 ViewRootImpl 自己，好，这一篇我们就分析到这里，已经将 Choreographyer 摸了个透，之前神神秘秘的类，其实内容就是这么简单很多时候，恐惧来源于未知，知道了，也就没有那么可怕了。 预知 view 树真实调度发生了什么？所谓的硬件加速到底是什么？ 请看下回分解","link":"/2018/12/18/invalidate-of-choreographer/"},{"title":"你要知道的 ListView 5种滑动模式全在这里了","text":"前段时间在使用 ListView 的过程中，需要对一个子 Item 优化横向 Bannar 的滑动体验，于是借此机会，深入了解了一下 ListView 滑动的一些知识，来探究一下，一个 View 滑动，究竟需要做哪些事情。 滑动模式基本介绍ListView 的滑动模式使用变量 mTouchMode 来表示，分为以下几种模式： mTouchMode 注释 解析 备注 TOUCH_MODE_REST Indicates that we are not in the middle of a touch gesture 标识当前未处于滑动手势中 用于重置当前滑动状态 TOUCH_MODE_DOWN Indicates we just received the touch event and we are waiting to see if the it is a tap or a scroll gesture 标识仅仅是接到了触摸事件，还需要进一步判断是点按事件还是滑动手势 TOUCH_MODE_TAP Indicates the touch has been recognized as a tap and we are now waiting to see if the touch is a longpress 标识触摸事件已经被识别为点按事件，还需要进一步判断是不是长按事件 TOUCH_MODE_DONE_WAITING Indicates we have waited for everything we can wait for, but the user’s finger is still down 标识我们已经等了很久，但是用户的手势还是处于down状态 TOUCH_MODE_SCROLL Indicates the touch gesture is a scroll 标识触摸手势是滑动事件 TOUCH_MODE_FLING Indicates the view is in the process of being flung 标识当前View是在“甩”的过程中 TOUCH_MODE_OVERSCROLL Indicates the touch gesture is an overscroll - a scroll beyond the beginning or end. 标识手势是一个越界滑动越界滑动是指滑动超出了内容区域的首尾 这种状态下，AbsListView 会在 DOWN 事件时拦掉事件，交给自己的 onTouchEvent 处理，事件不会继续往子 View 传递 TOUCH_MODE_OVERFLING Indicates the view is being flung outside of normal content bounds and will spring back. 标识当前View被“甩”出了正常滑动区域，即将会弹回来 这种状态下，AbsListView 会在 DOWN 事件时拦掉事件，交给自己的 onTouchEvent 处理，事件不会继续往子 View 传递 ListView 滑动模式有这么多，其实都是基于控件自身设计和交互上的考虑。我们会发现上表中出现的滑动模式，前四个模式，标识 ListView 当前处于的状态，并没有”滑“起来，而后四个模式，却在实际中有对应的场景： TOUCH_MODE_SCROLL：最简单的场景，对应于 ListView 跟随我们的手指上下滑动 TOUCH_MODE_FLING：列表太长时，我们想要快速浏览，手指快速向下（上）滑动，手机离开屏幕伴有一定的加速度 TOUCH_MODE_OVERSCROLL：手机滑动列表已经超出内容的可滑动区域后，还继续滑动，表示 ListView 没有更多的内容了 TOUCH_MODE_OVERFLING：Fling 之后，滑动还没停下来的时候超出内容的滑动区域，继续滑动的状态，原生默认的效果是波纹动画，也是标示 ListView 没有更多可以滑动的内容了 FAST_SCROLL：除了以上的模式之外，还有一个模式 ，对应的场景是，我们拖动滑动标识器（scroll thumb）快速定位到 ListView 的某个位置，FAST_SCROLL 模式的事件处理在整个以上模式的最前边，是独立于这些模式的，我们后边单独分析 以上就是我们这次要讲得 5 种滑动模式 这里有个模式变化表，仅供参考，单次滑动屏幕，（中间不抬手指） 模式变化 说明 TOUCH_MODE_REST -&gt; TOUCH_MODE_DOWN -&gt; TOUCH_MODE_OVERSCROLL （不可能，无法直接从 DOWN-&gt;OVERSCROLL，因为 mScrollY 必须经过 onOverScrolled 之后才能有值） TOUCH_MODE_REST -&gt; TOUCH_MODE_DOWN -&gt; 按下，长按，TAP 普通点击，长按 TOUCH_MODE_REST -&gt; TOUCH_MODE_DOWN -&gt; TOUCH_MODE_SCROLL -&gt; TOUCH_MODE_REST 普通的滑动模式 TOUCH_MODE_REST -&gt; TOUCH_MODE_DOWN -&gt; TOUCH_MODE_SCROLL -&gt; TOUCH_MODE_OVERSCROLL-&gt; TOUCH_MODE_OVERFLING -&gt; TOUCH_MODE_FLING -&gt; TOUCH_MODE_REST 初始化 -&gt; 触摸屏幕 -&gt; 接触滑动 -&gt; 越界 -&gt; 越界FLING -&gt; FLING -&gt; 重置 TOUCH_MODE_REST -&gt; TOUCH_MODE_DOWN -&gt; TOUCH_MODE_SCROLL -&gt; TOUCH_MODE_OVERSCROLL -&gt; TOUCH_MODE_REST 初始化 -&gt; 触摸屏幕 -&gt; 接触滑动 -&gt; 越界 -&gt; 松手 -&gt; 弹回重置 TOUCH_MODE_REST -&gt; TOUCH_MODE_DOWN -&gt; TOUCH_MODE_SCROLL -&gt; TOUCH_MODE_OVERSCROLL -&gt; TOUCH_MODE_SCROLL -&gt; TOUCH_MODE_REST 初始化 -&gt; 触摸屏幕 -&gt; 接触滑动 -&gt; 越界 -&gt; 往回滑动 -&gt; 松手 TOUCH_MODE_REST -&gt; TOUCH_MODE_DOWN -&gt; TOUCH_MODE_FLING （不可能，无法直接从 DOWN-&gt;FLING，因为 fling 需要加速度，必须要经过 move） TOUCH_MODE_REST -&gt; TOUCH_MODE_DOWN -&gt; TOUCH_MODE_SCROLL -&gt; TOUCH_MODE_FLING -&gt; TOUCH_MODE_OVERFLING -&gt; TOUCH_MODE_REST 初始化 -&gt; 触摸屏幕 -&gt; 接触滑动 -&gt; 松手FLING -&gt; 越界FLING -&gt; 停止 TOUCH_MODE_REST -&gt; TOUCH_MODE_DOWN -&gt; TOUCH_MODE_SCROLL -&gt; TOUCH_MODE_FLING -&gt; TOUCH_MODE_OVERFLING -&gt; TOUCH_MODE_FLING -&gt; TOUCH_MODE_REST 初始化 -&gt; 触摸屏幕 -&gt; 接触滑动 -&gt; 松手FLING -&gt; 越界FLING -&gt; FLING -&gt; 停止 TOUCH_MODE_REST -&gt; TOUCH_MODE_DOWN -&gt; TOUCH_MODE_SCROLL -&gt; TOUCH_MODE_FLING -&gt; TOUCH_MODE_REST 初始化 -&gt; 触摸屏幕 -&gt; 接触滑动 -&gt; FLING -&gt; 到达边缘（当前 overScrollMode 被禁用） 从哪里开始滑动是与用户连接非常密切的交互方式，而感知用户屏幕行为最重要的一个途径就是 MotionEvent 事件，所以要了解 ListView 的滑动模式，我们首先就需要把目光放到 ListView 处理屏幕触摸事件的两个方法 12android.widget.AbsListView#onInterceptTouchEvent()android.widget.AbsListView#onTouchEvent() ListView 继承自 ViewGroup，所以事件分发的过程会经历以下三个方法（并不是每次事件流都必走，顺序也不是从上到下的） 123android.view.ViewGroup#dispatchTouchEvent()android.widget.AbsListView#onInterceptTouchEvent()android.widget.AbsListView#onTouchEvent() dispatchTouchEvent() 是 ViewGroup 专属，负责把控整个 View 树的整体事件分发，我们不再细说，具体可以看之前的一篇文章 触摸事件分析 触屏事件从底层传上来之后，会先经过父控件的 onInterceptTouchEvent() 方法，让父控件判断是否要拦截事件自用，要拦截的滑交给父控件自身的 onTouchEvent()，不拦截，那就向下传递，我们以这个为基本原则，详细来看 onInterceptTouchEvent12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273@Overridepublic boolean onInterceptTouchEvent(MotionEvent ev) { final int actionMasked = ev.getActionMasked(); View v; ...... if (mFastScroll != null &amp;&amp; mFastScroll.onInterceptTouchEvent(ev)) { return true; } switch (actionMasked) { case MotionEvent.ACTION_DOWN: { int touchMode = mTouchMode; if (touchMode == TOUCH_MODE_OVERFLING || touchMode == TOUCH_MODE_OVERSCROLL) { // 如果在 overfling 或者 overScroll 中，那么直接拦截事件，交给自己的 onTouchEvent 处理 mMotionCorrection = 0; return true; } ...... mLastY = Integer.MIN_VALUE; initOrResetVelocityTracker(); mVelocityTracker.addMovement(ev); //加速度追踪者 ...... if (touchMode == TOUCH_MODE_FLING) { return true; } break; } case MotionEvent.ACTION_MOVE: { switch (mTouchMode) { case TOUCH_MODE_DOWN: ...... final int y = (int) ev.getY(pointerIndex); initVelocityTrackerIfNotExists(); mVelocityTracker.addMovement(ev); if (startScrollIfNeeded((int) ev.getX(pointerIndex), y, null)) { // 是否要开始 overScrollBy 的滑动 return true; } break; } break; } case MotionEvent.ACTION_CANCEL: case MotionEvent.ACTION_UP: { mTouchMode = TOUCH_MODE_REST; mActivePointerId = INVALID_POINTER; recycleVelocityTracker(); ...... break; } case MotionEvent.ACTION_POINTER_UP: { ...... break; } } return false;} 快速滑动的判定更早于其他模式，在 onInterceptTouchEvent() 一开始就处理过了，具体细节我们后续再说 在 ACTION_DOWN 中，OVERFLING，OVERFLING，OVERFLING 这三种情况下，会将接下来的事件直接转交给 ListView 自身，而其他情况下，对是否抵达这三种情况的判定其实是在 ACTION_MOVE 中，也就是说 ListView 并没有在事件一开始就接管，而是通过一段时间的滑动之后才做出了进入滑动模式的判定，从而基于这个判定来接管后续的事件 从 ACTION_DOWN 的代码中，我们可以总结两点： 在已经进入 OVERFLING，OVERFLING，OVERFLING 三个模式后，后续发生的事件流，都会先被 ListView 自身所接管处理，也就是说在 ListView 还在滑动的过程中的时候，轻点一下屏幕，并不会触发子 View 的点击事件，而是 ListView 自己去处理，这个并不难理解，触发滚动之后，后续的第一个事件自然应该是先停止滚动，然后在静止的情况下让用户准确的选中要处理的子 Item 在将要触发滑动的第一个事件流来的时候，ListView 并没有立刻接管这个事件流，而是“观察”了一段 ACTION_MOVE 事件之后，才开始接管，所以对于进入滑动的时机，是在 ACTION_MOVE 中判定的。 每组事件的开头 ACTION_DOWN 被父控件拦截之后，这个事件流的后续事件都会被父控件接管吗？子控件还有机会获得使用吗？答：有机会，调用 requestDisallowInterceptTouchEvent() 就可以，但是因为 touch 事件已经被父 View 接管了，所以在触屏事件流的过程中，是没有机会的，只能通过其他时机触发 onTouchEvent12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Overridepublic boolean onTouchEvent(MotionEvent ev) { ...... if (mFastScroll != null &amp;&amp; mFastScroll.onTouchEvent(ev)) { return true; } initVelocityTrackerIfNotExists(); final MotionEvent vtev = MotionEvent.obtain(ev); final int actionMasked = ev.getActionMasked(); ...... switch (actionMasked) { case MotionEvent.ACTION_DOWN: { onTouchDown(ev); break; } case MotionEvent.ACTION_MOVE: { onTouchMove(ev, vtev); break; } case MotionEvent.ACTION_UP: { onTouchUp(ev); break; } case MotionEvent.ACTION_CANCEL: { onTouchCancel(); break; } ...... } if (mVelocityTracker != null) { mVelocityTracker.addMovement(vtev); } vtev.recycle(); return true;} 好了，定位到滑动的入口，接下来我们就简单介绍下这几个滑动模式的整体流程事件首先会到达 android.widget.AbsListView#onInterceptTouchEvent，我们先看拦截的机制 手指放到屏幕上，ACTION_DOWN ，mTouchMode 被初始化为 TOUCH_MODE_REST，标志着 touchMode 的重新计算，并重置了上次滑动的位置 mLastY 手指开始移动，ACTION_MOVE 事件到达，这里会时刻监控 startScrollIfNeeded() 的返回值，来决定要不要拦截事件，转交给自身的 onTouchEvent() 处理， 拦截的触发条件有两个： 是否超出 View 的边缘（mScrollY !=0），超过表示 overScroll() 模式 有没有超过 android 设定的误触值 mTouchSlop，超过并且不是 overScoll 模式，那么就是滑动模式 scroll 了，如果判定了滑动模式，要清除一些子 Item 的按下状态，还要阻止父控件拦截事件，全部交给自己来处理了（有点霸道。。），最后就根据滑动的值来改变 ListView 自身的状态了 我们假定，已经触发了滑动或者越界滑动的条件，实际滚动的过程需要区分这二者 所谓的超过 View 的边缘是什么意思？答：View 的滚动可以分为两个部分，一个是内容的滚动，一个是 View 自身的滚动，ListView 中 item 的滚动就是属于内容的滚动，而越界的滚动属于 ListView 自身的滚动。 进入各个模式之前，我们需要明确一点，ListView 在每次滑动的时候，都会记录手指按下时候的位置 mMotionY，手指从上次按下位置开始到当前点滑动的距离 deltaY，以及手指自上次之后滑动的距离 incrementalDeltaY，以及当前 View 所滑动的距离 mScrollY（整个 View 滑动的距离，而不是 View 的内容） 这四个变量会在下边的四个滑动模式中被反复使用。 5种模式SCROLL 滑动模式我们需要让 ListView 的内容滚动起来，这里 Android 是在 trackMotionScroll() 中处理的，这个处理的过程区分是否到达 ListView 的开头和末尾，如果满足条件的话，那么马上就要切换到越界滚动模式，反之，就要保证让 ListView 的内容滚动起来，因为 ListView 有 View 复用的逻辑，所以在旧的 View 滑出屏幕之后要加入回收池，新的 View 进入屏幕时要立刻绑定数据或者重新创建，子 item 的滚动是通过对每个 item 使用 offsetChildrenTopAndBottom() 来实现的，这个函数之后会调用 invalidate() 来刷新 ListView 内容 那么问题又来了，屏幕滚动，一部分子 item 向上（下）滚动，那么 ListView 空出来的地方怎么把新的 View 填充上去，答案是 fillGap()，这个函数会根据向上还是向下滚动，来决定 fillUp() 还是 fillDown()，这里会根据一定的条件决定新建还是复用子 Item，如果是创建的话，还需要使用 setupChild() 初始化这个新的子 Item，来将 item 放到合适的位置上 SCROLL 模式的滑动模型是手指移动的距离就是 ListView 内容滚动的区域，所以在进入滑动模式之后，手指每次移动的距离 incrementalDeltaY 就是本次 listView 需要“消费”的距离，消费完成，ListView 就停止滚动 OVERSCOLL 越界滚动是在 ListView 滑动子 Item 到达顶部或者底部的时候触发，在之前的滚动模式中我们在判定 ListView 到达上下边缘时就看到了触发的条件，我们接着上边的分支看 判定满足了越界滚动模式的条件，那么就会通过 overScrollBy() 来梳理计算出越界滚动的一些数据（注意，这个 overScrollBy() 是 View 的能力），将数据通过交给使用者自己处理，我们可以在 onOverScrolled() 中拿到这些数据决定如何处理，ListView 这里只是设定了 mScrollY 的值，并通过回调通知使用者越界的具体参数，如果想实现弹性效果，就可以在复写 onOverScrolled() 来处理 这里插一句闲话，据说在 IOS 出现越界弹性效果之后，Android 也跟进了提供 onOverScrolled() 方式，但是却没有提供具体实现，可能是因为担心承担法律责任 最后，Android 默认会根据设定的 overScrollMode 来决定如何提示滚动越界了，android5.0 之后的越界会有波纹效果，就是从这里显示出来的，这里通过一个 EdgeEffect 的类来处理越界滚动的效果 至于 overScroll 模式如何停下来，我们在 fling 模式的后边细说，因为 overScroll 模式和 fling 模式的停止都使用了动画。 什么是未被消费的滚动距离答：我们手指离开屏幕之后的加速度所计算得出的距离就是总的滚动距离，后续 View 自动滚动需要消费这些距离，直到消费完成 overScrollMode先说明一下，overScroll 也有三种模式，用户可以设置的模式，根据这三种模式，越界滚动的效果也不一样 scrollMode 注释 解析 备注 OVER_SCROLL_ALWAYS Always allow a user to over-scroll this view, provided it is a view that can scroll. 总是允许越界滚动 OVER_SCROLL_IF_CONTENT_SCROLLS Allow a user to over-scroll this view only if the content is large enough to meaningfully scroll, provided it is a view that can scroll. 只有在内容足够大时，来清晰的表示滑动状态时，才允许滑动 OVER_SCROLL_NEVER Never allow a user to over-scroll this view. 总是禁止 看到这里不要忘记我们是在 onInterceptTouchEvent() 方法中，事件在这里拦截后，会转交给 onTouchEvent() 处理 所以在上文3的触发条件满足之后，我们后续的事件要接受 onTouchEvent() 的进一步处理从我们在上边的分析中，在 ListView 从静止到触发滑动之前，事件并没有被 ListView 拦截掉，那么这些事件会被派发给子 Item，这时候子 Item 可以根据这个 Down 事件来处理按下的状态， 如果子 Item 这个时候在自己的事件处理中返回 true，接管了这个事件流的后续，那么后边是什么样的流程了？答：那么事件将会直接交给子 item 处理，这个事件流周期内，ListView 自身是无法再接受到事件。 如果子 item 没有拦截这个事件，那么 listView 会在 onTouchDown() 中简单处理一下状态，并发送延迟消息来判定是否要触发长按事件。我们接着来看滑动事件触发之后，事件会交给 ListView 自身处理，这时候 MOVE 事件会在 onTouchMove() 中处理，同样，这里也使用 scrollIfNeed() 来处理滚动和越界滚动的效果 这里为啥要多加一层，在onInterceptTouchEvent 中处理的不够吗？答：因为 intercept 只是起到第一次拦截的作用，intercept 拦截之后，后续事件不会再次经过 intercept，只会直接交给 touchEvent，所以这里需要继续后边滑动的处理 FLING &amp; OVER_FLING 在 ACTION_DOWN 和 ACTION_MOVE 方法处理中这两种模式并没有什么不同，不同之处在于松手之后，也就是 ACTION_UP 事件传过来，ACTION_UP 事件传过来之后，我们会使用之前在 ACTION_DOWN 和 ACTION_MOVE 中监控的 velocityTracker 事件来分析手指离开屏幕的加速度，如果分析得到加速度大于 mMinimumVelocity ，那么会触发进入 TOUCH_MODE_FLING 模式，这个模式下的处理交给了 FlingRunnable，这个 Runnable 内置了一个 OverScroller 会按需处理 FLING，OverFling，SpringBack（回弹）这三种状态 举例来说，在列表足够长时，Fling 一段距离之后会停下来，而列表短时，可能会触发 OverFling，然后再触发 SpringBack 效果，这里不再细谈，只需要知道 Fling 和 OverFling 是在这个 FlingRunnable 中处理就 OK，后续需要的时候再回头细看即可 注：FlingRunnable 的运行模式FlingRunnable 通过 postOnAnimation 把自身加入到 Choreographer 的回调队列中，在每次 VSYNC 事件的时候都会回调FlingRunnable 的 run 方法，在 run 方法中决定是否要继续监听下一次 Choreographer 的回调，来实现持续滑动的效果 VSYNC 相关内容可以参考以下文章：为什么是VSYNC Choreographer 可以参考以下文章：invalidate 三部曲序invalidate 三部曲之始于 invalidateinvalidate 三部曲之历经 Choreographer FAST_SCROLL说完 scroll，overScrol，fling，overFling，这四种模式之后，我们最后看一下 fastScroll 的一些内容顾名思义，fastScroll，快速滚动，这个滚动不是通过滑动 listView 的内容区域来触发的，而是通过 fast scroll thumb 这个控件来触发的，事件处理也是独立于 ListView 的，单独放到了 FastScroller 中处理，我们可以通过设置来开关这个属性，很多人应该都用过，拖动 scrollbar，然后下拉，就可以达到这种效果 因为这个事件是在一个单独的控件中触发的，所以事件处理也是完全独立 ListView 的，感兴趣的翻看 FastScroller 代码 至此，我们对 ListView 的5个滑动模式就分析到这里，理清楚了大部分的流程之后，我们遇到 ListView 相关的问题，就可以迅速从某个入口介入。","link":"/2019/08/12/listview-scrollmode-parse/"},{"title":"invalidate 三部曲之始于 invalidate","text":"invalidate - to make invalid. Choreographyer 三部曲 invalidate 三部曲序 invalidate 三部曲之始于 invalidate invalidate 三部曲之历经 Choreographer invalidate() 方法可谓是自定义View的常客，不管是自己覆写onDraw()方法还是触发动画效果，以及其他种种需要更新界面元素的情况，都只需要调用一句invalidate()，剩下的交给系统即可，可谓省时又省力如果说我们在一些简单的View中是可以这样直接使用而不加思索，那么当我们的view足够复杂时，在面对庞大的逻辑运算，不规范的系统调用等等所带来的性能开销面前，我们就不能熟视无睹。 因此深入系统内部，可以让我们规避很多不必要的麻烦，要知道系统代码也是人写出来的，不会为你考虑所有的复杂情况而优化，而了解内部实现机制，了解实现者的意图，就可以做针对性的优化，进而提升性能和稳定性。 invalidate，直译，使失效。使什么失效？使当前的状态失效为什么要失效？因为只有标记为失效之后，系统才会在下一次屏幕刷新时执行重绘什么时候失效？在例如点击效果，背景颜色，高度，长度等等当前屏幕元素需要更新的时候。那么失效做了什么？为什么等下一次屏幕刷新？而不是直接触发重新绘制？这样做的好处是什么？ 写在前边这篇文章是第一部分，主要讲View发起绘制 View发起绘制主要涉及三个类： 1234android.view.Viewandroid.view.ViewGroupandroid.view.ViewParentandroid.view.ViewRootImpl 类图三个类的结构大概是这样的： ViewParent指明了父View要实现的职责，我们熟知的ViewGroup就实现了这个接口，那么ViewGroup是包裹View的对象，ViewRootImpl是做什么的？ 我们知道Android中Window是View的载体，每个Window下都挂着一棵View树，那与window直接相关的View是谁？没错，就是ViewRootImpl，不过这不是一个View，因为没有继承自View，而只是实现了ViewParent标明的父View职责，可以理解为他是所有View的顶辈儿，要对View树做什么，都会经过这个实体的居中调停 View和ViewParent的关系就不用多说了，ViewParent只是一个可以容纳子View的特殊View 流程这个流程并不复杂，只涉及10个函数，那么复杂的是什么，复杂的是其中类的关系，以及要处理的各种情况，我们分开来看 全部流程请参考序中的时序图：invalidate 三部曲序 123456789101112131415161718192021222324252627282930/** * Invalidate the whole view. If the view is visible, * {@link #onDraw(android.graphics.Canvas)} will be called at some point in * the future. * &lt;p&gt; * This must be called from a UI thread. To call from a non-UI thread, call * {@link #postInvalidate()}. */// android.view.View#invalidate()public void invalidate() { invalidate(true);}/** * This is where the invalidate() work actually happens. A full invalidate() * causes the drawing cache to be invalidated, but this function can be * called with invalidateCache set to false to skip that invalidation step * for cases that do not need it (for example, a component that remains at * the same dimensions with the same content). * * @param invalidateCache Whether the drawing cache for this view should be * invalidated as well. This is usually true for a full * invalidate, but may be set to false if the View's contents or * dimensions have not changed. * @hide */// android.view.View#invalidate(boolean)public void invalidate(boolean invalidateCache) { invalidateInternal(0, 0, mRight - mLeft, mBottom - mTop, invalidateCache, true);} 标记View失效，然后会在接下来某个时间点调用onDraw()来重绘，且这个函数只能在主线程调用，要在非主线程调用，请使用postInvalidate()，这个我们会在最后讲述两个的区别。 另外，参数invalidateCache很重要，用来标记缓存是否失效。像如位移，alpha变换等这种大小和内容没有改变的情况，是不需要重新绘制内容的，系统会将view缓存到layer（层）中，通过对整个层进行变换来避免再次绘制。 这对于提高很多动画的性能是很有帮忙的，例如位移动画或者alpha动画。 1234567891011121314151617181920212223242526272829303132// android.view.View#invalidateInternalvoid invalidateInternal(int l, int t, int r, int b, boolean invalidateCache, boolean fullInvalidate) { ...... if ((mPrivateFlags &amp; (PFLAG_DRAWN | PFLAG_HAS_BOUNDS)) == (PFLAG_DRAWN | PFLAG_HAS_BOUNDS) || (invalidateCache &amp;&amp; (mPrivateFlags &amp; PFLAG_DRAWING_CACHE_VALID) == PFLAG_DRAWING_CACHE_VALID) || (mPrivateFlags &amp; PFLAG_INVALIDATED) != PFLAG_INVALIDATED || (fullInvalidate &amp;&amp; isOpaque() != mLastIsOpaque)) { if (fullInvalidate) { mLastIsOpaque = isOpaque(); mPrivateFlags &amp;= ~PFLAG_DRAWN; } mPrivateFlags |= PFLAG_DIRTY; // 增加脏区标记位 if (invalidateCache) { // 如果缓存失效 mPrivateFlags |= PFLAG_INVALIDATED; // 标记失效 mPrivateFlags &amp;= ~PFLAG_DRAWING_CACHE_VALID; // 清除正在绘制缓存标记位 } // Propagate the damage rectangle to the parent view. final AttachInfo ai = mAttachInfo; final ViewParent p = mParent; if (p != null &amp;&amp; ai != null &amp;&amp; l &lt; r &amp;&amp; t &lt; b) { final Rect damage = ai.mTmpInvalRect; damage.set(l, t, r, b); p.invalidateChild(this, damage); // 向父View报告脏区位置 } ...... }} invalidateInternal()为内部实现，包括增加脏区标记，失效标记，并向父View报告脏区位置 1234567891011/** * All or part of a child is dirty and needs to be redrawn. * * @param child The child which is dirty * @param r The area within the child that is invalid * * @deprecated Use {@link #onDescendantInvalidated(View, View)} instead. */ // android.view.ViewParent#invalidateChild@Deprecatedpublic void invalidateChild(View child, Rect r); ViewParent的接口，对于ViewGroup和ViewRootImple有各自的实现，用于触发child的r标志的脏区重绘 123456789101112131415161718192021222324252627282930313233343536373839/** * Don't call or override this method. It is used for the implementation of * the view hierarchy. * * @deprecated Use {@link #onDescendantInvalidated(View, View)} instead to observe updates to * draw state in descendants. */// android.view.ViewGroup#invalidateChild@Deprecated@Overridepublic final void invalidateChild(View child, final Rect dirty) { ...... ViewParent parent = this; if (attachInfo != null) { ...... do { View view = null; if (parent instanceof View) { view = (View) parent; } ...... parent = parent.invalidateChildInParent(location, dirty); ...... } while (parent != null); }}// android.view.ViewRootImpl#invalidateChild@Overridepublic void invalidateChild(View child, Rect dirty) { invalidateChildInParent(null, dirty);} 上下两个方法分别是：ViewGroup的invalidateChild的实现 和 ViewRootImpl的invalidateChild实现 我们知道view的父控件肯定是ViewGroup，但ViewGroup的父控件除了ViewGroup，还有ViewRootImpl 所以在触发invalidateChild后，会递归向上依次调用父控件的invalidateChildInParent，然后返回父控件的父控件，一直到顶层，也就是ViewRootImpl，最终调用ViewRootImpl的invalidateChildInParent，结束递归 12345678910111213141516171819202122232425262728293031323334/** * Don't call or override this method. It is used for the implementation of * the view hierarchy. * * This implementation returns null if this ViewGroup does not have a parent, * if this ViewGroup is already fully invalidated or if the dirty rectangle * does not intersect with this ViewGroup's bounds. * * @deprecated Use {@link #onDescendantInvalidated(View, View)} instead to observe updates to * draw state in descendants. */// android.view.ViewGroup#invalidateChildInParent@Deprecated@Overridepublic ViewParent invalidateChildInParent(final int[] location, final Rect dirty) { if ((mPrivateFlags &amp; (PFLAG_DRAWN | PFLAG_DRAWING_CACHE_VALID)) != 0) { ...... return mParent; } return null;}// android.view.ViewRootImpl#invalidateChildInParent@Overridepublic ViewParent invalidateChildInParent(int[] location, Rect dirty) { ..... invalidateRectOnScreen(dirty); return null;} 二者实现，不再多说。 1234567private void invalidateRectOnScreen(Rect dirty) { ...... if (!mWillDrawSoon &amp;&amp; (intersected || mIsAnimating)) { scheduleTraversals(); }} 结束递归的最后，触发了view树的刷新，也就是我们的终极大bossscheduleTraversals。 sechduleTraversals，拆开来分别是调度，递归 什么递归？view树的递归，为什么是调度，因为不是立刻执行，还需要时机触发。 12345678910111213void scheduleTraversals() { if (!mTraversalScheduled) { mTraversalScheduled = true; // 标记已经触发过调度了，所以如果有多次invalidate，其实并没有实际产生调度 mTraversalBarrier = mHandler.getLooper().getQueue().postSyncBarrier(); mChoreographer.postCallback( Choreographer.CALLBACK_TRAVERSAL, mTraversalRunnable, null); // 加入回调队列 if (!mUnbufferedInputDispatch) { scheduleConsumeBatchedInput(); } notifyRendererOfFramePending(); pokeDrawLockIfNeeded(); }} 终于来到最后一步，并没看到所谓的触发刷新逻辑，只是将一个Runnable任务加入了一个任务队列中？？说好的触发刷新呢？一切的一切，都在这里的新面孔Choreographer Choreographer直译：编舞者 结束语欲知 编舞者Choreographer怎样接管后续工作？刷新逻辑何时才能执行？ 请听下回分解。","link":"/2018/10/13/invalidate-of-invalidate/"},{"title":"invalidate 三部曲序","text":"由于整个invalidate()周期较长，继续深入会涉及屏幕刷新等底层知识，所以我们会分为三个部分来讲，分别为View发起绘制、系统处理绘制请求的逻辑、View执行真实绘制。 时序图 以scheduleTraversals()为第一个分割点，以doFrame()为第二个分割点，对应时序图的序列分别为： View 发起绘制： 1 - 8 系统处理绘制请求的逻辑： 9 - 20 View 执行真实绘制： 21 - 41 目录 invalidate 三部曲序 invalidate 三部曲之始于 invalidate invalidate 三部曲之历经 Choreographer","link":"/2018/10/12/trilogy-of-invalidate/"},{"title":"【公告】站点升级&amp;域名切换","text":"为了提升阅读体验，抽空将站点做了一些升级。 并将域名从 0xfree.top 切换到 0xforee.top。 期间使用 3 个月时间过渡。 过渡期间新旧域名会同时启用，访问旧域名将自动重定向到新域名，如果有收藏旧域名的，请尽快切换。过渡期结束将会下线旧域名。","link":"/2023/08/15/upgrade-my-site-config/"},{"title":"为什么是VSYNC","text":"单缓冲区显示器刷新的频率决定了人肉眼可感受的流畅度，刷新频率太低会导致出现PPT效果，刷新频率太高又没有太高的必要，所以显示器一般的刷新频率为60Hz，人眼可感知的最低限度，即1秒刷新60帧，也就是显示器会1秒从显卡中读取66帧的数据显示到屏幕上，那么这些数据是从哪里来的呢？ 答案是CPU/GPU产生的，也就是CPU/GPU作为帧的生产者，显示器作为帧的消费者 CPU/GPU除了要承载显示帧的绘制工作，还需要承担其他的任务，所以频率都要比显示器高很多。那么这就产生了一个问题，CPU/GPU和显示器的频率不一致，导致刷新不同步 以上的描述，都是在单缓冲区的情况下，也就是CPU/GPU和显示器公用一个缓冲区，可想而知，因为刷新不一致，显示器在从缓冲区读数据的时候，可能CPU/GPU刚刚写了一半数据，导致显示器显示一个割裂的页面。 双缓冲区为了解决这个问题，引入双缓冲区，一个用于CPU/GPU产生数据，一个用于显示器读取数据，在合适的时机，交换两个缓冲区，这样就不会造成显示画面的割裂了，那么什么时间是最合适的呢？ 我们知道显卡扫描屏幕是从第一行到最后一行的，扫描完毕又会回到第一行开始下一个周期，那么结束一个扫描周期到下一个扫描周期开始的这段空闲时间就是最佳的交换时间。 在这种情况下，画面割裂的问题得到了有效的解决，但是还会有一种问题：我们知道在一帧显示之前，CPU会处理应用程序的数据，然后将结果交给GPU（为什么要用到GPU，在另一篇文章中讲到）继续处理，最后合成帧（真实情况还会有HardwareComposer）而我们之前提到过，人眼可感知的最低帧率为60Hz，也就是16ms要显示一帧，而CPU又是一个大忙人，如果CPU忙于其他事情没有来得及处理数据，那么就会造成下一帧合成缓慢，显示器迫不得已继续使用之前的帧，这样就会导致画面卡顿 VSYNC为了解决上面的问题，我们又引入一个新的概念，VSync中断，Vsync是VerticalSynchronization的缩写，简单的可以理解为屏幕的一个刷新周期，也就是说我们进行了一个屏幕刷新周期之后，立马通知CPU该去绘制下一帧的数据了，这样才能在下一个中断来临之前确保有新的数据可以用 如果只是了解VSYNC我们到这里就可以了，但是是google还在此基础上做了更深的优化 拓展阅读：google的trriple buffer","link":"/2018/06/02/why-it-is-vsync/"}],"tags":[{"name":"lunch","slug":"lunch","link":"/tags/lunch/"},{"name":"android","slug":"android","link":"/tags/android/"},{"name":"compile","slug":"compile","link":"/tags/compile/"},{"name":"envsetup","slug":"envsetup","link":"/tags/envsetup/"},{"name":"build","slug":"build","link":"/tags/build/"},{"name":"makefile","slug":"makefile","link":"/tags/makefile/"},{"name":"make","slug":"make","link":"/tags/make/"},{"name":"PRODUCT_COPY_FILES","slug":"PRODUCT-COPY-FILES","link":"/tags/PRODUCT-COPY-FILES/"},{"name":"PRODUCT_PROPERTY_OVERRIDES","slug":"PRODUCT-PROPERTY-OVERRIDES","link":"/tags/PRODUCT-PROPERTY-OVERRIDES/"},{"name":"jsbridge","slug":"jsbridge","link":"/tags/jsbridge/"},{"name":"html","slug":"html","link":"/tags/html/"},{"name":"PowerUI","slug":"PowerUI","link":"/tags/PowerUI/"},{"name":"SystemUI","slug":"SystemUI","link":"/tags/SystemUI/"},{"name":"view","slug":"view","link":"/tags/view/"},{"name":"measureSpec","slug":"measureSpec","link":"/tags/measureSpec/"},{"name":"layoutParams","slug":"layoutParams","link":"/tags/layoutParams/"},{"name":"quickSettings","slug":"quickSettings","link":"/tags/quickSettings/"},{"name":"mobileDataTile","slug":"mobileDataTile","link":"/tags/mobileDataTile/"},{"name":"mobileData","slug":"mobileData","link":"/tags/mobileData/"},{"name":"wifiTIle","slug":"wifiTIle","link":"/tags/wifiTIle/"},{"name":"wifi","slug":"wifi","link":"/tags/wifi/"},{"name":"touchevent","slug":"touchevent","link":"/tags/touchevent/"},{"name":"glide","slug":"glide","link":"/tags/glide/"},{"name":"gentoo","slug":"gentoo","link":"/tags/gentoo/"},{"name":"ebuild","slug":"ebuild","link":"/tags/ebuild/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"overlay","slug":"overlay","link":"/tags/overlay/"},{"name":"local","slug":"local","link":"/tags/local/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"Gerrit","slug":"Gerrit","link":"/tags/Gerrit/"},{"name":"ubuntu","slug":"ubuntu","link":"/tags/ubuntu/"},{"name":"kotlin","slug":"kotlin","link":"/tags/kotlin/"},{"name":"coroutine","slug":"coroutine","link":"/tags/coroutine/"},{"name":"invalidate","slug":"invalidate","link":"/tags/invalidate/"},{"name":"listView","slug":"listView","link":"/tags/listView/"},{"name":"scrollMode","slug":"scrollMode","link":"/tags/scrollMode/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"performance","slug":"performance","link":"/tags/performance/"},{"name":"vsync","slug":"vsync","link":"/tags/vsync/"}],"categories":[{"name":"Android编译系统解析","slug":"Android编译系统解析","link":"/categories/Android%E7%BC%96%E8%AF%91%E7%B3%BB%E7%BB%9F%E8%A7%A3%E6%9E%90/"},{"name":"Android","slug":"Android","link":"/categories/Android/"},{"name":"SystemUI解析","slug":"SystemUI解析","link":"/categories/SystemUI%E8%A7%A3%E6%9E%90/"},{"name":"View解析","slug":"View解析","link":"/categories/View%E8%A7%A3%E6%9E%90/"},{"name":"Glide","slug":"Glide","link":"/categories/Glide/"},{"name":"Gentoo","slug":"Gentoo","link":"/categories/Gentoo/"},{"name":"效率工具","slug":"效率工具","link":"/categories/%E6%95%88%E7%8E%87%E5%B7%A5%E5%85%B7/"},{"name":"kotlin","slug":"kotlin","link":"/categories/kotlin/"},{"name":"Other","slug":"Other","link":"/categories/Other/"},{"name":"Android性能调优","slug":"Android性能调优","link":"/categories/Android%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"}],"pages":[{"title":"About Me","text":"Mr.Nobody","link":"/about/index.html"}]}